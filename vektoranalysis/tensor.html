
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>3.2. Tensoren und Tensorprodukte &#8212; Mathematik für Physikstudierende C</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"Z": "\\mathbb{Z}", "V": "V", "N": "\\mathbb{N}", "C": "\\mathbb{C}", "Q": "\\mathbb{Q}", "K": "\\mathbb{K}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"], "R": ["\\mathbb{R}"], "norm": ["{\\Vert#1\\Vert}", 1], "abs": ["{|#1|}", 1], "coloneqq": ["{:=}"], "eqqcolon": ["{=:}"], "emph": ["\\pmb#1", 1], "tr": "\\operatorname{Spur}", "lin": "\\operatorname{lin}", "dv": "\\mathrm{div}~", "rot": "\\mathrm{rot}~", "Dim": "\\operatorname{dim}", "diag": "\\operatorname{diag}", "Kern": "\\operatorname{Kern}", "Bild": "\\operatorname{Bild}", "Rang": "\\operatorname{Rang}", "GL": "\\operatorname{GL}", "Eig": "\\operatorname{Eig}", "End": "\\operatorname{End}", "Hau": "\\operatorname{Haupt}", "mymathbb": ["\\boldsymbol{#1}", 1], "idx": "\\mathrm{d}x", "d": "\\mathrm{d}", "i": "\\mathrm{i}", "x": "\\mathbf{x}", "sign": "\\mathrm{sign}", "vec": ["\\mathbf{#1}", 1], "veczwei": ["\\begin{pmatrix} #1 \\\\ #2 \\end{pmatrix}", 2]}}, "tex2jax": {"processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/cropped-fau_solo_aufblau_192x192_rgb-180x180.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3.3. Differentialformen" href="diffformen.html" />
    <link rel="prev" title="3.1. Multilinearformen" href="multilinear.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/FAU-DMM-Logo-rgb-10cm.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Mathematik für Physikstudierende C</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Mathematik für Physikstudierende C
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ode/ode.html">
   1. Gewöhnliche Differentialgleichungen für dynamische Systeme
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ode/dynamicSystems.html">
     1.1. Einführung in dynamische Systeme
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ode/repetition.html">
     1.2. Wiederholung: Gewöhnliche Differentialgleichungen
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ode/fluesse.html">
     1.3. Phasenflüsse und Phasenportraits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ode/hamilton.html">
     1.4. Hamiltonsche Differentialgleichungen
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ode/ex.html">
     1.5. Aufgaben
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../odestability/stabilitaetsanalyse.html">
   2. Stabilitätsanalyse für dynamische Systeme
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../odestability/stabilitaetsbegriffe.html">
     2.1. Stabilitätsbegriffe
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../odestability/ruhelagen.html">
     2.2. Stabilität von Ruhelagen
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="vektoranalysis.html">
   3. Vektoranalysis
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="multilinear.html">
     3.1. Multilinearformen
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     3.2. Tensoren und Tensorprodukte
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="diffformen.html">
     3.3. Differentialformen
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../references.html">
   4. Bibliography
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/vektoranalysis/tensor.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/FAU-AMMN/MathPhysicsC"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivation">
   3.2.1. Motivation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#der-cauchy-spannungstensor">
     3.2.1.1. Der Cauchy Spannungstensor
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#quantenverschrankung">
     3.2.1.2. Quantenverschränkung
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#das-tensorprodukt">
   3.2.2. Das Tensorprodukt
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#existenz-und-konstruktion">
   3.2.3. Existenz und Konstruktion
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tensoren-als-linearformen">
   3.2.4. Tensoren als Linearformen
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#auszere-formen">
   3.2.5. Äußere Formen
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="tensoren-und-tensorprodukte">
<h1><span class="section-number">3.2. </span>Tensoren und Tensorprodukte<a class="headerlink" href="#tensoren-und-tensorprodukte" title="Permalink to this headline">¶</a></h1>
<p>In diesem Kapitel widmen wir uns einem wichtigen aber komplizierten Thema der Vektoranalysis, nämlich Tensoren und Tensorprodukten.
Der Begriff hat sehr viele verschiedene Anschauungsmöglichkeiten (siehe <a class="reference external" href="https://de.wikipedia.org/wiki/Tensorprodukt">Wikipedia</a>) weshalb es nicht leicht ist eine Einführung zu geben die gleichzeitig allgemein, aber auch verständlich ist. Da Tensoren aber eine wichtige Rolle in der Physik spielen werden wir uns hier damit beschäftigen.</p>
<div class="section" id="motivation">
<h2><span class="section-number">3.2.1. </span>Motivation<a class="headerlink" href="#motivation" title="Permalink to this headline">¶</a></h2>
<p>Wir betrachten zwei Beispiele aus der Physik, welche auf Tensoren zurückgreifen.</p>
<div class="proof remark admonition" id="remark-0">
<p class="admonition-title"><span class="caption-number">Remark 3.5 </span></p>
<div class="remark-content section" id="proof-content">
<p>Der Begriff Tensor wurde von Hamilton in der Mitte des 19. Jahrhunderts eingeführt. Er leitete die Bezeichnung vom latinischen <em>tendere</em> (spannen) ab, da die ursprüngliche Anwendung derartiger Objekte in der Elastizitätstheorie Anwendung fand.</p>
</div>
</div><div class="section" id="der-cauchy-spannungstensor">
<h3><span class="section-number">3.2.1.1. </span>Der Cauchy Spannungstensor<a class="headerlink" href="#der-cauchy-spannungstensor" title="Permalink to this headline">¶</a></h3>
<div class="margin sidebar">
<p class="sidebar-title">Augustin Cauchy</p>
<p><a class="reference external" href="https://de.wikipedia.org/wiki/Augustin-Louis_Cauchy">Augustin-Louis Cauchy</a> (Geboren 21. August 1789 in Paris; Gestorben 23. Mai 1857 in Sceaux) war ein französischer Mathematiker.</p>
</div>
<p>Mechanische Spannung beschreibt die innere Beanspruchung und Kräfte in einem Volumen <span class="math notranslate nohighlight">\(V\subset\R^3\)</span> die aufgrund einer äußeren Belastungen auftreten. Die grundlegende Idee ist das <strong>Euler-Cauchy Stress Prinzip</strong>, welches beschreibt, dass auf jede Schnittfläche <span class="math notranslate nohighlight">\(A\subset\R^2\)</span> welche ein Volumen in zwei Teile trennt, von diesen zwei Komponenten eine Spannung auf <span class="math notranslate nohighlight">\(A\)</span> ausgewirkt wird, welche durch den <strong>Spannungsvektor</strong> <span class="math notranslate nohighlight">\(\mathbf{T}^n\)</span> beschrieben wird. Der Spannungsvektor ist hierbei von der Dimension “Kraft pro Fläche”.</p>
<div class="figure align-default" id="fig-stress">
<a class="reference internal image-reference" href="../_images/stress_vector.png"><img alt="../_images/stress_vector.png" src="../_images/stress_vector.png" style="height: 250px;" /></a>
<p class="caption"><span class="caption-number">Fig. 3.1 </span><span class="caption-text">Visualisierung für Normal- und Scherspannung an einer Schnittfläche. Quelle: <a class="reference external" href="https://en.wikipedia.org/wiki/Cauchy_stress_tensor">Wikipedia; Cauchy Stress Tensor</a>.</span><a class="headerlink" href="#fig-stress" title="Permalink to this image">¶</a></p>
</div>
<p>Wie in <a class="reference internal" href="#fig-stress"><span class="std std-numref">Fig. 3.1</span></a> visualisiert teilt sich die Spannung in zwei Komponenten auf:</p>
<p><strong>Normalspannung:</strong></p>
<p>Dieser Teil des Spannungsvektor zeigt in Richtung der normalen <span class="math notranslate nohighlight">\(\mathbf{n}\)</span> welche orthogonal auf der Schnittfläche stehen.</p>
<p><strong>Scherspannung:</strong></p>
<p>Dieser Teil des Spannungstensors ist parallel zur Schnittfläche.</p>
<p>Man erkennt nun, dass die Spannung in <span class="math notranslate nohighlight">\(V\)</span> nicht durch einen einzigen Vektor ausgedrückt werden kann. Einerseits hängt sie vom betrachteten Punkt <span class="math notranslate nohighlight">\(P\in V\)</span> ab und zudem von der Orientierung der Schnittfläche. Allerdings hat Cauchy gezeigt, dass ein Tensorfeld <span class="math notranslate nohighlight">\(\mathbf{\sigma}(x)\)</span> existiert, s.d.,</p>
<div class="math notranslate nohighlight">
\[T^{\mathbf{n}}(x) = \mathbf{n}\cdot \mathbf{\sigma}(x),\]</div>
<p>d.h. in jedem Punkt <span class="math notranslate nohighlight">\(x\in V\)</span> ist der Stressvektor linear im Normalenvektor <span class="math notranslate nohighlight">\(\mathbf{n}\)</span>.</p>
<div class="figure align-default" id="fig-stress-comp">
<a class="reference internal image-reference" href="../_images/stress_tensor_comp.png"><img alt="../_images/stress_tensor_comp.png" src="../_images/stress_tensor_comp.png" style="height: 250px;" /></a>
<p class="caption"><span class="caption-number">Fig. 3.2 </span><span class="caption-text">Quelle: <a class="reference external" href="https://de.wikipedia.org/wiki/Spannungstensor">Wikipedia; Spannungstensor</a>.</span><a class="headerlink" href="#fig-stress-comp" title="Permalink to this image">¶</a></p>
</div>
<p>Hierfür betrachtet man einen freigeschnittenen Würfel wie in <a class="reference internal" href="#fig-stress-comp"><span class="std std-numref">Fig. 3.2</span></a> und definiert für die drei verschiedenen Flächen (orthogonal zu den Einheitsvektoren) den Stresstensor</p>
<div class="math notranslate nohighlight">
\[\mathbf{T}^{e_i}:= \sum_{j=1}^3 \sigma_{ij} e_j.\]</div>
<p>So haben wir z.B. für <span class="math notranslate nohighlight">\(\mathbf{T}^{e_1}\)</span> die Normalspannung gegeben durch <span class="math notranslate nohighlight">\(\sigma_{11} e_1\)</span> und die zwei Scherspannungskomponenten <span class="math notranslate nohighlight">\(\sigma_{12} e_2, \sigma_{13} e_3\)</span>. Insgesamt erhält man neun Komponenten <span class="math notranslate nohighlight">\(\sigma_{ij}\)</span> welche über die Definition</p>
<div class="math notranslate nohighlight">
\[\mathbf{\sigma} := \sum_{i=1}^3 e_i \otimes \mathbf{T}^{e_i} = \sum_{i=1}^3\sum_{j=1}^3 \sigma_{ij} (e_i\otimes e_j)\]</div>
<p>den Cauchy Stresstensor <span class="math notranslate nohighlight">\(\mathbf{\sigma}\)</span> ergebene. Hierbei bezeichnet <span class="math notranslate nohighlight">\(\otimes\)</span> das <strong>dyadische Produkt</strong> zweier Vektoren. Für <span class="math notranslate nohighlight">\(x\in\R^n,y\in\R^m\)</span> definieren wir</p>
<div class="math notranslate nohighlight">
\[\begin{split}x \otimes y := 
\begin{pmatrix}
x_1y_1 &amp;\ldots &amp;x_1 y_m\\
\vdots &amp;\ddots &amp; \vdots\\
x_n y_1&amp;\ldots&amp; x_n y_m
\end{pmatrix}.\end{split}\]</div>
<p>Wir werden später sehen, dass man die Idee <span class="math notranslate nohighlight">\(\sigma\)</span> über das dyadische Produkt zu definieren abstrahieren kann, was auf den allgemeinen Tensorbegriff führt.</p>
</div>
<div class="section" id="quantenverschrankung">
<h3><span class="section-number">3.2.1.2. </span>Quantenverschränkung<a class="headerlink" href="#quantenverschrankung" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<div class="section" id="das-tensorprodukt">
<h2><span class="section-number">3.2.2. </span>Das Tensorprodukt<a class="headerlink" href="#das-tensorprodukt" title="Permalink to this headline">¶</a></h2>
<p>Wir wollen nun das Tensorprodukt von Vektorräumen abstrakt einführen und es später konkret realisieren.</p>
<div class="proof definition admonition" id="definition-1">
<p class="admonition-title"><span class="caption-number">Definition 3.4 </span> (Tensorprodukt)</p>
<div class="definition-content section" id="proof-content">
<p>Es seien <span class="math notranslate nohighlight">\(V,W\)</span> zwei reelle Vektorräume. Ein reeler Vektorraum <span class="math notranslate nohighlight">\(X\)</span> heißt <strong>Tensorproduktraum</strong> falls eine bilineare Abbildung <span class="math notranslate nohighlight">\(\otimes:V\times W\rightarrow X\)</span> existiert, s.d., die folgende <strong>universelle Eigenschaft</strong> gilt:</p>
<p>Für jede Bilinearform <span class="math notranslate nohighlight">\(\phi\in L^2(V\times W, Y)\)</span> in einen beliebigen reellen Vektorraum <span class="math notranslate nohighlight">\(Y\)</span>, existiert eine eindeutige lineare Abbildung
<span class="math notranslate nohighlight">\(p \in L^1(X, Y)\)</span>, s.d. gilt</p>
<div class="math notranslate nohighlight">
\[\phi(v,w) = p((v\otimes w)) = p(\otimes(v,w))\quad\forall (v,w)\in V\times W.\]</div>
<p>In diesem Fall schreibt man auch <span class="math notranslate nohighlight">\(X = V\otimes X\)</span>, <span class="math notranslate nohighlight">\(\otimes\)</span> heißt Tensorprodukt und zusätzlich ist die Schreibweise <span class="math notranslate nohighlight">\(\otimes(v,w)=:v\otimes w\)</span> üblich.</p>
</div>
</div><p><strong>Was bedeutet das?</strong></p>
<p>Diese Definition erscheint auf den ersten Blick abstrakt und unverständlich. Was ist jetzt also ein Tensorprodukt?</p>
<p><strong>Das Tensorprodukt ist universell:</strong></p>
<p>Wir haben benutzten in der Definition oben das kartesische Produkt <span class="math notranslate nohighlight">\(\times\)</span> welches eindeutig definiert ist. Im Gegensatz dazu gibt es nicht <em>ein</em> Tensorprodukt <span class="math notranslate nohighlight">\(\otimes\)</span> oder <em>einen</em> Tensorproduktraum <span class="math notranslate nohighlight">\(V\otimes W\)</span>. Wir haben die Freiheit <span class="math notranslate nohighlight">\(\otimes\)</span> zu wählen und wann immer die universelle Eigenschaft erfüllt ist, heißt dann <span class="math notranslate nohighlight">\(V\otimes W\)</span> Tensorproduktraum. Derartige Konzepte nennt man in der Algebra <em>universell</em>.</p>
<p><strong>Was bedeutet die universelle Eigenschaft?</strong></p>
<p>Wie wir weiter unten noch genauer beschreiben werden, stellt die universelle Eigenschaft eine wichtige Beziehung zwischen dem Raum der bilinearen Abbildungen auf <span class="math notranslate nohighlight">\(V\times W\)</span> und dem Dualraum von <span class="math notranslate nohighlight">\(V\otimes W\)</span> her. Sofern wir das Tensorprodukt gegeben haben erhalten wir alle Bilinearformen schon über einfache Linearformen auf <span class="math notranslate nohighlight">\(V\otimes W\)</span>.</p>
</div>
<div class="section" id="existenz-und-konstruktion">
<h2><span class="section-number">3.2.3. </span>Existenz und Konstruktion<a class="headerlink" href="#existenz-und-konstruktion" title="Permalink to this headline">¶</a></h2>
<p>Wir können ein Tensorprodukt konkret konstruieren indem wir uns auf die Basis der Vektorräume <span class="math notranslate nohighlight">\(V\)</span> und <span class="math notranslate nohighlight">\(W\)</span> zurückziehen. Diese Tatsache formulieren wir in der folgenden Aussage.</p>
<div class="proof theorem admonition" id="theorem-2">
<p class="admonition-title"><span class="caption-number">Theorem 3.1 </span></p>
<div class="theorem-content section" id="proof-content">
<p>Für zwei reelle Vektorräume <span class="math notranslate nohighlight">\(V, W\)</span> existiert stets mindestens ein Tensorprodukt <span class="math notranslate nohighlight">\(\otimes\in L^2(V\times W, V\otimes W)\)</span>.</p>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. Der folgende Beweis ist ein sogenannter konstruktiver Beweis, d.h., wir zeigen die Existenz eines Objekts indem wir es explizit angeben. Es gibt auch nicht-konstruktive Existenzbeweise.</p>
<p>Es sei <span class="math notranslate nohighlight">\(B^V = \{b_i^V: i\in I^V\}\)</span> eine Basis von <span class="math notranslate nohighlight">\(V\)</span> und analog <span class="math notranslate nohighlight">\(B^W = \{b_i^W: i\in I^W\}\)</span>  eine Basis von <span class="math notranslate nohighlight">\(W\)</span> für Indexmengen <span class="math notranslate nohighlight">\(I^V, I^W\)</span>. Wir betrachten das kartesische Produkt</p>
<div class="math notranslate nohighlight">
\[J := I^V \times I^W = \{(i,j): i\in I^V, j\in I^W\}.\]</div>
<p>Es sei nun <span class="math notranslate nohighlight">\(X\)</span> ein Vektorraum dessen Basis sich durch <span class="math notranslate nohighlight">\(J\)</span> indizieren lässt, d.h., es existiert eine Menge</p>
<div class="math notranslate nohighlight">
\[B^X = \{b_{ij}^X: (i,j)\in J\}\]</div>
<p>s.d. <span class="math notranslate nohighlight">\(B^X\)</span> eine Basis von <span class="math notranslate nohighlight">\(X\)</span> ist. Ein solcher Vektorraum existiert, da z.B. das kartesische Produkt <span class="math notranslate nohighlight">\(V\times W\)</span> diese Eigenschaft erfüllt.</p>
<p>Wir definieren nun eine bilineare Abbildung <span class="math notranslate nohighlight">\(\otimes: V\times W\to X\)</span> über</p>
<div class="math notranslate nohighlight">
\[b_i^V \otimes b_j^W := b_{ij}^X\quad\forall (i,j)\in J.\]</div>
<p>Beachte, <span class="math notranslate nohighlight">\(\otimes\)</span> ist durch die Definition auf <span class="math notranslate nohighlight">\(J\)</span> eindeutig festgelegt, da für beliebige <span class="math notranslate nohighlight">\((v,w)\in V\times W\)</span> endlich viele Faktoren
<span class="math notranslate nohighlight">\(\alpha_{i_1},\ldots,\alpha_{i_m}\)</span> und <span class="math notranslate nohighlight">\(\beta_{j_1},\ldots, \beta_{j_n}\)</span> existieren s.d.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\otimes(v,w) 
&amp;= 
\otimes\big(\sum_{k=1}^n \alpha_{i_k} b_{i_k}^V, \sum_{l=1}^m \beta_{j_l} b_{j_l}^W\big) 
\\&amp;= 
\sum_{k=1}^n \sum_{l=1}^m \otimes\left(b_{i_k}^V, b_{j_l}^W\right)
\\&amp;=
\sum_{k=1}^n \sum_{l=1}^m b_{i_kj_l}^X.\end{split}\]</div>
<p>Wir müssen nun die universelle Eigenschaft zeigen, sei dazu <span class="math notranslate nohighlight">\(\phi\in L^2(V\times W, Y)\)</span> eine Bilinearform auf einen reellen Vektorraum <span class="math notranslate nohighlight">\(Y\)</span>, dann können wir eine Linearform auf <span class="math notranslate nohighlight">\(p:X\to Y\)</span> definieren durch (analog reicht es die Definition auf den Basiselementen anzugeben)</p>
<div class="math notranslate nohighlight">
\[p(b_{ij}^X) := \phi(b_i^V, b_j^W).\]</div>
<p>Dann gilt nämlich, unter Ausnutzung der Linearität von <span class="math notranslate nohighlight">\(p\)</span> und obiger Rechnung, dass</p>
<div class="math notranslate nohighlight">
\[\begin{split}p(\otimes(v,w)) 
&amp;=
\sum_{k=1}^n \sum_{l=1}^m p(b_{i_kj_l}^X)
\\&amp;=
\sum_{k=1}^n \sum_{l=1}^m \phi\left(b_{i_k}^V, b_{j_l}^W\right)
\\&amp;
\phi\big(\sum_{k=1}^n  b_{i_k}^V,\sum_{l=1}^m b_{j_l}^W\big)
\\&amp;
\phi(v,w)\end{split}\]</div>
<p>und somit gilt die universelle Eigenschaft. Insbesondere, da <span class="math notranslate nohighlight">\(p\)</span> durch die obige Definition eindeutig festgelegt ist.</p>
</div>
<p>Als Korollar erhalten wir somit, dass eine Basis des Tensorproduktraums durch das kartesische Produkt der ursprünglichen Basen konstruiert werden kann. Hieran sieht man qualitativ den Unterschied zwischen <span class="math notranslate nohighlight">\(V\otimes W\)</span> und <span class="math notranslate nohighlight">\(V\otimes W\)</span>.</p>
<div class="proof corollary admonition" id="corollary-3">
<p class="admonition-title"><span class="caption-number">Corollary 3.1 </span></p>
<div class="corollary-content section" id="proof-content">
<p>Für zwei reelle Vektorräume <span class="math notranslate nohighlight">\(V,W\)</span> mit Basen <span class="math notranslate nohighlight">\(B^V = \{b_i^V: i\in I^V\}, B^W = \{b_i^W: i\in I^W\}\)</span> und ein Tensorprodukt <span class="math notranslate nohighlight">\(\otimes:V\times W\to V\otimes W\)</span> ist</p>
<div class="math notranslate nohighlight">
\[\{b_i^V\otimes b_j^W: i\in I^V, j\in I^W\}\]</div>
<p>eine Basis von <span class="math notranslate nohighlight">\(V\otimes W\)</span>.</p>
</div>
</div><p>Wir wissen nun, dass mindestens ein Tensorprodukt existiert, es stellt sich also die Frage inwiefern sich verschiedene derartige Abbildungen auf den gleichen Vektorräumen <span class="math notranslate nohighlight">\(V,W\)</span> unterschieden. Seien dazu <span class="math notranslate nohighlight">\(\otimes_1, \otimes_2\)</span> je zwei Tensorprodukte auf <span class="math notranslate nohighlight">\(V\times W\)</span>. Wegen der universellen Eigenschaft gibt es lineare Abbildungen <span class="math notranslate nohighlight">\(p_1: V\otimes_1 W\to W\otimes_2 V\)</span> und <span class="math notranslate nohighlight">\(p_2: V\otimes_2 W\to W\otimes_1 V\)</span>, s.d.,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\otimes_2 &amp;= p_1 \circ \otimes_1\\
\otimes_1 &amp;= p_2 \circ \otimes_2.\end{split}\]</div>
<p>und somit</p>
<div class="math notranslate nohighlight">
\[\begin{split}\otimes_2 &amp;= p_1\circ p_2 \circ \otimes_2\\
\otimes_1 &amp;= p_2\circ p_1 \circ \otimes_1.\end{split}\]</div>
<p>Da wir aber die Basis von <span class="math notranslate nohighlight">\(V\otimes_2 W\)</span> über Elemente <span class="math notranslate nohighlight">\(\otimes_2(b_i^V, b_j^W)\)</span> charakterisieren können, und aus der ersten Gleichung folgt, dass</p>
<div class="math notranslate nohighlight">
\[p_1\circ p_2(\otimes(b_i^V,b_j^W)) = \otimes(b_i^V, b_j^W)\]</div>
<p>wissen wir dass <span class="math notranslate nohighlight">\(p_1\circ p_2 = \mathrm{Id}\)</span>. Das folgt da <span class="math notranslate nohighlight">\(p_1\circ p_2\)</span> als lineare Abbildung schon ganz auf den Basiselementen festgelegt ist.
Analog folgt <span class="math notranslate nohighlight">\(p_2\circ p_1 = \mathrm{Id}\)</span> und somit sind <span class="math notranslate nohighlight">\(p_1, p_2\)</span> isomorph zueinander. D.h. wir haben insgesamt gezeigt, dass verschiedene Tensorprodukte stets isomorph zueinander sind.</p>
<div class="proof lemma admonition" id="lemma-4">
<p class="admonition-title"><span class="caption-number">Lemma 3.5 </span></p>
<div class="lemma-content section" id="proof-content">
<p>Es seien <span class="math notranslate nohighlight">\(V,W\)</span> zwei reelle Vektorräume und <span class="math notranslate nohighlight">\(\otimes_1,\otimes_2\)</span> zwei Tensorprodukte. Dann existiert genau ein Isomorphismus <span class="math notranslate nohighlight">\(p:V\otimes_1 W\to V\otimes_2 W\)</span>, s.d.</p>
<div class="math notranslate nohighlight">
\[\otimes_2 = p\circ \otimes_1.\]</div>
</div>
</div></div>
<div class="section" id="tensoren-als-linearformen">
<h2><span class="section-number">3.2.4. </span>Tensoren als Linearformen<a class="headerlink" href="#tensoren-als-linearformen" title="Permalink to this headline">¶</a></h2>
<p>Als Einleitung in das Thema wollen wir Tensoren zunächst als Linearformen auf <span class="math notranslate nohighlight">\(\V_1\times\ldots\times\V_k\)</span>
betrachten wobei für <span class="math notranslate nohighlight">\(i=1,\ldots,k\)</span> <span class="math notranslate nohighlight">\(\V_i\)</span> reelle endlich dimensionale Vektorräume sind.
Man schreibt in diesem Fall auch</p>
<div class="math notranslate nohighlight">
\[\V_1\otimes\ldots\otimes\V_k = L(\V_1\times\ldots\V_k,\R)\]</div>
<p>wobei <span class="math notranslate nohighlight">\(\otimes\)</span> das Tensorprodukt bezeichnet.</p>
<p>Der wichtige Spezialfall ist hier allerdings nun nicht <span class="math notranslate nohighlight">\(\V^k\)</span> sondern ein kartesisches Produkt der Form</p>
<div class="math notranslate nohighlight">
\[(V^\ast)^r\times V^s.\]</div>
<div class="proof definition admonition" id="definition-5">
<p class="admonition-title"><span class="caption-number">Definition 3.5 </span></p>
<div class="definition-content section" id="proof-content">
<p>Es sei <span class="math notranslate nohighlight">\(\V\)</span> ein reeller endlich-dimensionaler Vektorraum, dann nennt man</p>
<div class="math notranslate nohighlight">
\[T^r_s(V) := L((V^\ast)^r\times V^s, \R)\]</div>
<p>Menge der <span class="math notranslate nohighlight">\(r\)</span>-fach <strong>kontravarianten</strong> und <span class="math notranslate nohighlight">\(s\)</span>-fach <strong>kovarianten</strong> Tensoren, oder alternativ Tensoren der Stufe <span class="math notranslate nohighlight">\((r,s)\)</span>.</p>
</div>
</div><p>Wir wollen diese abstrakte Definition nun mit einfachen Beispielen veranschaulichen zunächst für <span class="math notranslate nohighlight">\(r+s=1\)</span>.</p>
<div class="proof example admonition" id="example-6">
<p class="admonition-title"><span class="caption-number">Example 3.4 </span></p>
<div class="example-content section" id="proof-content">
<p>Tensoren der Stufe <span class="math notranslate nohighlight">\((1,0)\)</span> können mit Elementen des Vektorraums selbst identifiziert werden, denn</p>
<div class="math notranslate nohighlight">
\[T^1_0(V) = L((V^\ast), \R) = \V^{\ast\ast}\cong \V\]</div>
<p>mit der Identifikation aus <a class="reference internal" href="multilinear.html#lem:doubledual">Lemma 3.4</a>. Weiterhin sind Tensoren der Stufe <span class="math notranslate nohighlight">\((0,1)\)</span> Elemente des
Dualraums, also einfach Linearformen auf <span class="math notranslate nohighlight">\(\V\)</span>, sogenannte <em>Kovektoren</em>.</p>
</div>
</div><p>Als weiteren Spezialfall erhalten wir Multilinearformen.</p>
<div class="proof example admonition" id="example-7">
<p class="admonition-title"><span class="caption-number">Example 3.5 </span></p>
<div class="example-content section" id="proof-content">
<p>Tensoren der Stufe <span class="math notranslate nohighlight">\((0,k)\)</span> sind <span class="math notranslate nohighlight">\(k\)</span>-Linearformen, da <span class="math notranslate nohighlight">\(T^0_k(V) = L^k(V)\)</span>.</p>
</div>
</div><div class="proof example admonition" id="example-8">
<p class="admonition-title"><span class="caption-number">Example 3.6 </span></p>
<div class="example-content section" id="proof-content">
<p>Aus einer linearen Abbildung <span class="math notranslate nohighlight">\(A:\V\to\V\)</span> erhält man direkt einen Tensor der Stufe <span class="math notranslate nohighlight">\((1,1)\)</span> über die Abbildung</p>
<div class="math notranslate nohighlight">
\[\varphi, v \mapsto \varphi(Av).\]</div>
</div>
</div></div>
<div class="section" id="auszere-formen">
<h2><span class="section-number">3.2.5. </span>Äußere Formen<a class="headerlink" href="#auszere-formen" title="Permalink to this headline">¶</a></h2>
<p>In <a class="reference internal" href="multilinear.html#ex:multi">Example 3.2</a> haben wir für <span class="math notranslate nohighlight">\(k=2\)</span> bereits den Begriff der Antisymmetrie kennengelernt. Dieser Fall lässt sich auf beliebige <span class="math notranslate nohighlight">\(k\in\N\)</span> verallgemeinern, was zur Definition der äußeren Form führt.</p>
<div class="proof definition admonition" id="aeussere_Form">
<p class="admonition-title"><span class="caption-number">Definition 3.6 </span> (Äußere Form)</p>
<div class="definition-content section" id="proof-content">
<p>Es sei <span class="math notranslate nohighlight">\(\V\)</span> ein <span class="math notranslate nohighlight">\(n\)</span>–dimensionaler <span class="math notranslate nohighlight">\(\R\)</span>-Vektorraum und <span class="math notranslate nohighlight">\(k\in\N\)</span>. Dann heißt <span class="math notranslate nohighlight">\(\varphi\in L^k(E,\R)\)</span>
<strong>äußere</strong> <span class="math notranslate nohighlight">\(k\)</span><strong>-Form</strong>,wenn sie <strong>antisymmetrisch</strong> ist, d.h., für alle <span class="math notranslate nohighlight">\(1\leq i&lt;l\leq k\)</span> und
<span class="math notranslate nohighlight">\(z\in \V^k\)</span> gilt</p>
<div class="math notranslate nohighlight">
\[\varphi(z_1,\ldots,z_i,\ldots,z_l,\ldots,z_k) =-\varphi(z_1,\ldots,z_l,\ldots,z_i,\ldots,z_k).\]</div>
<p>Der Unterraum der äußeren <span class="math notranslate nohighlight">\(k\)</span>-Formen wird mit <span class="math notranslate nohighlight">\(\Lambda^k(\V)\subset L^k(\V,\R)\)</span> bezeichnet.</p>
</div>
</div><div class="proof example admonition" id="example-10">
<p class="admonition-title"><span class="caption-number">Example 3.7 </span></p>
<div class="example-content section" id="proof-content">
<p><span class="math notranslate nohighlight">\(k=1\)</span>:</p>
<p>Hier fallen alle bisherigen Definitionen zusammen, d.h.,</p>
<div class="math notranslate nohighlight">
\[\Lambda^1(\V) = L^1(\V,\R)= \V^\ast\]</div>
<p><span class="math notranslate nohighlight">\(k=2\)</span>:</p>
<p>Für <span class="math notranslate nohighlight">\(A\in\R^{2,2}\)</span> definiert die Abbildung <span class="math notranslate nohighlight">\((x,y)\mapsto\langle x,A y\rangle\)</span> eine äußere <span class="math notranslate nohighlight">\(2\)</span>-Form auf <span class="math notranslate nohighlight">\(\R^n\)</span> genau dann, wenn die Matrix <span class="math notranslate nohighlight">\(A\)</span> antisymmetrisch ist. D.h., falls <span class="math notranslate nohighlight">\(A^T=-A\)</span> gilt.</p>
<p><span class="math notranslate nohighlight">\(k=n\)</span>:</p>
<p>Die Determinantenform ist bis auf ihre Vielfachen die einzige äußere <span class="math notranslate nohighlight">\(n\)</span>-Form auf dem <span class="math notranslate nohighlight">\(\R^n\)</span>.</p>
</div>
</div><p>Wir beweisen zwei kleine Hilfsaussagen zu äußeren Formen</p>
<div class="proof lemma admonition" id="lemma-11">
<p class="admonition-title"><span class="caption-number">Lemma 3.6 </span></p>
<div class="lemma-content section" id="proof-content">
<p>Es sein <span class="math notranslate nohighlight">\(\V\)</span> ein reeller Vektorraum und <span class="math notranslate nohighlight">\(\varphi\in\Lambda^k(V)\)</span>.</p>
<ul class="simple">
<li><p>Für jede Permutation <span class="math notranslate nohighlight">\(\pi:\{1,\ldots,k\}\rightarrow\{1,\ldots,k\}\)</span> gilt</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\varphi(z_{\pi(1)},\ldots,z_{\pi(k)}) = \sign(\pi) \varphi(z_1,\ldots,z_k).\]</div>
<ul class="simple">
<li><p>Sind <span class="math notranslate nohighlight">\(z_1,\ldots, z_k\)</span> linear abhängig, so gilt <span class="math notranslate nohighlight">\(\varphi(z_1,\ldots,z_k) = 0\)</span>.</p></li>
</ul>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. Die erste Behauptung folgt direkt aus der Tatsache, dass sich jede Permutation als Verkettung endlich vieler Transpositionen schreiben lässt.
Für die zweite Behauptung sehen wir zunächst, dass</p>
<div class="math notranslate nohighlight">
\[\varphi(z_1,\ldots,x,\ldots, x,\ldots,z_k) = -\varphi(z_1,\ldots,x,\ldots,x,\ldots,z_k)\]</div>
<p>und somit <span class="math notranslate nohighlight">\(\varphi(z_1,\ldots,x,\ldots,x,\ldots,z_k)=0\)</span>. Sind die <span class="math notranslate nohighlight">\(z_i\)</span> nun linear abhängig, so existieren Skalare <span class="math notranslate nohighlight">\(\alpha_i\)</span>, s.d.,
ein <span class="math notranslate nohighlight">\(j\)</span> existiert mit <span class="math notranslate nohighlight">\(\alpha_j\neq 0\)</span> und</p>
<div class="math notranslate nohighlight">
\[\sum_{i=1}^n \alpha_i z_i = 0 \Leftrightarrow z_j = 
\frac{1}{\alpha_j} \sum_{i\neq j} \alpha_i z_i.\]</div>
<p>Somit folgt</p>
<div class="math notranslate nohighlight">
\[\varphi(z_1,\ldots,z_j,\ldots,z_k) = 
\sum_{i\neq j} \alpha_i \varphi(z_1,\ldots,z_{j-1},z_i,z_{j+1},\ldots,z_k) = 0.\]</div>
</div>
<p>Wir werden nun eine Methode kennelernen die es uns erlaubt eine äußere <span class="math notranslate nohighlight">\(k\)</span>-Form als sogenanntes <strong>äußeres Produkt</strong> von <span class="math notranslate nohighlight">\(k\)</span> vielen Linearformen zu erhalten.</p>
<div class="proof definition admonition" id="definition-12">
<p class="admonition-title"><span class="caption-number">Definition 3.7 </span> (Äußeres Produkt)</p>
<div class="definition-content section" id="proof-content">
<p>Für einen Vektorraum <span class="math notranslate nohighlight">\(\V\)</span> ist das <strong>äußere Produkt</strong> von <span class="math notranslate nohighlight">\(\omega_1,\ldots,\omega_k\in\Lambda^1(\V)\)</span>
durch</p>
<div class="math notranslate nohighlight">
\[\begin{split}\omega_1\wedge\ldots\wedge\omega_k:V^k&amp;\to\R\\
(z_1,\ldots,z_k)&amp;\mapsto 
\det
\begin{pmatrix}
\omega_1(z_1)&amp;\ldots&amp;\omega_k(z_1)\\ 
\vdots&amp;&amp;\vdots\\
\omega_1(z_k)&amp;\ldots&amp;\omega_k(z_k)
\end{pmatrix}\end{split}\]</div>
<p>definiert.</p>
</div>
</div><div class="proof lemma admonition" id="lemma-13">
<p class="admonition-title"><span class="caption-number">Lemma 3.7 </span></p>
<div class="lemma-content section" id="proof-content">
<p>Für einen Vektorraum <span class="math notranslate nohighlight">\(\V\)</span> ist das äußere Produkt von <span class="math notranslate nohighlight">\(\omega_1,\ldots,\omega_k\in\Lambda^1(\V)\)</span> eine <span class="math notranslate nohighlight">\(k\)</span>-Linearform.</p>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. Siehe Übung.</p>
</div>
<p>Insbesondere gilt damit für die Dualbasis <span class="math notranslate nohighlight">\(\eta_1,\ldots,\eta_n\)</span> von <span class="math notranslate nohighlight">\(\V^*\)</span>, dass</p>
<div class="math notranslate nohighlight">
\[\eta_{i_1}\wedge\ldots\wedge\eta_{i_k}\in\Lambda^k(\V)\]</div>
<p>für beliebige Indexkombinationen <span class="math notranslate nohighlight">\(i_1,\ldots,i_k \in \{1,\ldots,n \}\)</span>. Wegen der Eigenschaften der Determinante gilt</p>
<div class="math notranslate nohighlight">
\[\eta_{i_1}\wedge\ldots\wedge\eta_{i_k} = \sign(\pi)\, \eta_{\pi(i_1)}\wedge\ldots\wedge\eta_{\pi(i_k)} \]</div>
<p>wobei <span class="math notranslate nohighlight">\(\pi:\{i_1,\ldots,i_k\}\rightarrow\{i_1,\ldots,i_k\}\)</span> eine Permutation ist, s.d.,</p>
<div class="math notranslate nohighlight">
\[\pi(i_1) &lt;= \ldots &lt;= \pi(i_j) &lt;= \ldots &lt;= \pi(i_k).\]</div>
<p>Desweiteren gilt auch</p>
<div class="math notranslate nohighlight">
\[\begin{split}\eta_{i_1}\wedge\ldots\wedge\eta_{i_k} &amp;\neq 0\\
&amp;\Leftrightarrow \\
i_{j}\neq i_l&amp;\text{ für } j\neq l.\end{split}\]</div>
<p>Wir können nun jede <span class="math notranslate nohighlight">\(k\)</span>-Form <span class="math notranslate nohighlight">\(\omega\in\Lambda^k(E)\)</span> eindeutig als Linearkombination</p>
<div class="math notranslate nohighlight">
\[\omega = \sum_{1\leq i_1&lt;\ldots&lt;i_k\leq n}\omega_{i_1\ldots i_k}
\alpha_{i_1}\wedge\ldots\wedge\alpha_{i_k}\]</div>
<p>mit Koeffizienten</p>
<div class="math notranslate nohighlight">
\[\omega_{i_1\ldots i_k} := \omega(e_{i_1},\ldots,e_{i_k})\in\R\]</div>
<p>darstellen. Da
die Indexmengen <span class="math notranslate nohighlight">\(\{i_1,\ldots ,i_k\}\)</span> die <span class="math notranslate nohighlight">\(k\)</span>–elementigen Teilmengen von<span class="math notranslate nohighlight">\(\{1,\ldots,n\}\)</span> durchlaufen, gilt
für <span class="math notranslate nohighlight">\(\dim(E)=n\)</span></p>
<div class="math notranslate nohighlight">
\[\dim\left(\Lambda^k(E)\right) = {n\choose k}.\]</div>
<p>Das  <em>äußere Produkt</em>
Produkt der <span class="math notranslate nohighlight">\(k\)</span>–Form <span class="math notranslate nohighlight">\(\omega\)</span> mit einer <span class="math notranslate nohighlight">\(l\)</span>–Form</p>
<div class="math notranslate nohighlight">
\[\psi := \sum_{1\leq j_1&lt;\ldots&lt;j_{l}\leq n}\psi_{j_1\ldots j_l}\,
\alpha_{j_1}\wedge\ldots\wedge\alpha_{j_l}\]</div>
<p>wird nun distributiv als <span class="math notranslate nohighlight">\(\omega\wedge\psi\in\Lambda^{k+l}(E)\)</span>,</p>
<div class="math notranslate nohighlight">
\[\omega\wedge\psi := \sum_{1\leq i_1&lt;\ldots&lt;i_k\leq n} \sum_{1\leq
j_1&lt;\ldots&lt;j_l\leq n} \omega_{i_1\ldots i_k} \psi_{j_1\ldots j_l}
\alpha_{i_1}\wedge\ldots\wedge\alpha_{i_k}\wedge\alpha_{j_1}\wedge
\ldots\wedge\alpha_{j_l}\]</div>
<p>definiert. All diejenigen Summanden, bei denen ein Indexpaar <span class="math notranslate nohighlight">\(i_r=j_s\)</span>vorkommt, sind gleich Null, denn <span class="math notranslate nohighlight">\(\alpha_l\wedge\alpha_l = -\alpha_l\wedge\alpha_l=0\)</span>.</p>
<ul class="simple">
<li><p>Das äußere Produkt ist <em>assoziativ</em>, d.h. für beliebige äußere Formen auf <span class="math notranslate nohighlight">\(E\)</span> gilt</p></li>
</ul>
<div class="math notranslate nohighlight">
\[(\omega\wedge\psi)\wedge\rho = \omega\wedge(\psi\wedge\rho).\]</div>
<ul class="simple">
<li><p>Weiter gilt für eine <span class="math notranslate nohighlight">\(k\)</span>–Form <span class="math notranslate nohighlight">\(\omega\)</span> und eine <span class="math notranslate nohighlight">\(l\)</span>–Form <span class="math notranslate nohighlight">\(\psi\)</span></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\omega\wedge\psi = (-1)^{k\cdot l}\psi\wedge\omega,\]</div>
<p>denn wir müssen <span class="math notranslate nohighlight">\(k\!\cdot\! l\)</span>–mal Eins–Formen kommutieren, um von der einen
zur anderen Gestalt zu gelangen.</p>
<div class="proof example admonition" id="symplektische Form auf dem $\R^{2n}$">
<p class="admonition-title"><span class="caption-number">Example 3.8 </span> (<a class="reference external" href="https://de.wikipedia.org/wiki/Symplektischer_Vektorraum">Wikipedia</a> <em>Symplektische Form</em>)</p>
<div class="example-content section" id="proof-content">
<div class="math notranslate nohighlight">
\[\omega := \sum_{i=1}^n\alpha_i\wedge\alpha_{i+n}\in\Lambda^2(\R^{2n}).\]</div>
<p>Für <span class="math notranslate nohighlight">\(n=2\)</span> ergibt sich</p>
<div class="math notranslate nohighlight">
\[\omega = \alpha_1\wedge\alpha_3+\alpha_2\wedge\alpha_4,\]</div>
<p>also</p>
<div class="math notranslate nohighlight">
\[\begin{split}\omega\wedge\omega &amp;=&amp; (\alpha_1\wedge\alpha_3+\alpha_2\wedge\alpha_4)
\wedge(\alpha_1\wedge\alpha_3+\alpha_2\wedge\alpha_4)\\
&amp;=&amp; \underbrace{\alpha_1\wedge\alpha_3\wedge\alpha_1\wedge\alpha_3}_0 +
\alpha_2\wedge\alpha_4\wedge\alpha_1\wedge\alpha_3\\
&amp;&amp; + \alpha_1\wedge\alpha_3\wedge\alpha_2\wedge\alpha_4 + \underbrace
{\alpha_2\wedge\alpha_4\wedge\alpha_2\wedge\alpha_4}_0\\
&amp;=&amp; (-1)^3\alpha_1\wedge\alpha_2\wedge\alpha_3\wedge\alpha_4 +
(-1)^1\alpha_1\wedge\alpha_2\wedge\alpha_3\wedge\alpha_4\\
&amp;=&amp; -2\alpha_1\wedge\alpha_2\wedge\alpha_3\wedge\alpha_4.\end{split}\]</div>
<p>Die symplektische Form <span class="math notranslate nohighlight">\(\omega\)</span> hat eine Schlüsselrolle in der Klassischen Mechanik. Dort bezeichnet man die Koordinaten <span class="math notranslate nohighlight">\(x_1,\ldots,
x_n\)</span> als Impulskoordinaten, die Koordinaten <span class="math notranslate nohighlight">\(x_{n+1},\ldots, x_{2n}\)</span> als
Ortskoordinaten.</p>
</div>
</div><div class="proof example admonition" id="example-15">
<p class="admonition-title"><span class="caption-number">Example 3.9 </span> (Vektoren und äußere Formen)</p>
<div class="example-content section" id="proof-content">
<p>Wir ordnen nun Vektoren
<span class="math notranslate nohighlight">\(v = \begin{pmatrix} v_1\\ \vdots\\ v_n \end{pmatrix} =\sum_{k=1}^nv_ke_k\in\R^n\)</span> verschiedene äußere Formen zu.</p>
<ul class="simple">
<li><p>Das kanonische innere Produkt im <span class="math notranslate nohighlight">\(\R^n\)</span> vermittelt einen Isomorphismus</p></li>
</ul>
<div class="math notranslate nohighlight">
\[v\mapsto v^*,\ v^*(u) :=\, &lt; v,u &gt; \qquad(u\in\R^n)\]</div>
<p>des <span class="math notranslate nohighlight">\(\R^n\)</span> und seines Dualraumes. Die Eins–Form <span class="math notranslate nohighlight">\(v^*\)</span> besitzt dabei die Gestalt</p>
<div class="math notranslate nohighlight">
\[v^* = \sum_{i=1}^nv_i\alpha_i
\in\Lambda^1(\R^n).\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(v\in\R^n\)</span> wird auch eine <span class="math notranslate nohighlight">\((n-1)\)</span>–Form <span class="math notranslate nohighlight">\(\omega_v\in\Lambda^{n-1}(\R^n)\)</span>,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\omega_v(u_2,\ldots,u_n) := \det(v,u_2,\ldots,u_n) \qquad (u_2,\ldots,u_n\in\R^n)\]</div>
<p>zugeordnet. Speziell im <span class="math notranslate nohighlight">\(\R^3\)</span> finden wir die <span class="math notranslate nohighlight">\(2\)</span>–Form</p>
<div class="math notranslate nohighlight">
\[\omega_v = v_1\alpha_2\wedge\alpha_3+v_2\alpha_3\wedge\alpha_1+v_3
\alpha_1\wedge\alpha_2.\]</div>
<ul class="simple">
<li><p>Wir betrachten jetzt speziell den (physikalisch wichtigen) <span class="math notranslate nohighlight">\(\R^3\)</span>.
Das äußere Produkt zweier solcher <span class="math notranslate nohighlight">\(1\)</span>–Formen ergibtauf dem <span class="math notranslate nohighlight">\(\R^3\)</span> die <span class="math notranslate nohighlight">\(2\)</span>–Form</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}v^*\wedge u^* &amp;=&amp; (v_1\alpha_1+v_2\alpha_2+v_3\alpha_3)
\wedge(u_1\alpha_1+u_2\alpha_2+u_3\alpha_3)\\
&amp;=&amp; (v_1u_2-v_2u_1)\alpha_1\wedge\alpha_2+(v_2u_3-v_3u_2)\alpha_2\wedge
\alpha_3\\
&amp;&amp; + (v_3u_1-v_1u_3)\alpha_3\wedge\alpha_1\\
&amp;=&amp; \omega_{v\times u}.\end{split}\]</div>
<p>Wir haben auf diese Weise das <a class="reference external" href="https://de.wikipedia.org/wiki/Kreuzprodukt"><em>Kreuzprodukt</em></a></p>
<div class="math notranslate nohighlight">
\[\begin{split}v\times u=\begin{pmatrix} v_2u_3-v_3u_2\\v_3u_1-v_1u_3 \\ v_1u_2-v_2u_1 \end{pmatrix} \in\R^3\end{split}\]</div>
<p>zweier Vektoren <span class="math notranslate nohighlight">\(v,u\in\R^3\)</span> gewonnen.</p>
</div>
</div><div class="proof theorem admonition" id="theorem-16">
<p class="admonition-title"><span class="caption-number">Theorem 3.2 </span></p>
<div class="theorem-content section" id="proof-content">
<p>Die Vektoren <span class="math notranslate nohighlight">\(w_1,\ldots,w_k\in E^*\)</span> sind genau dann linear abhängig, wenn</p>
<div class="math notranslate nohighlight">
\[w_1\wedge\ldots\wedge w_k=0.\]</div>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. * Wenn sie linear abhängig sind, können wir einen Index <span class="math notranslate nohighlight">\(i\in\{1,\ldots, k\}\)</span> finden, für den <span class="math notranslate nohighlight">\(w_i\)</span> eine Linearkombination <span class="math notranslate nohighlight">\(w_i=\sum_{\stackrel{l=1}{l\neq i}}^k c_l w_l\)</span> ist. Damit gilt aber</p>
<div class="math notranslate nohighlight">
\[w_1\wedge\ldots\wedge w_k = \sum_{\stackrel{l=1}{l\neq i}}^kc_l\, w_1 \wedge \ldots \wedge w_{i-1}\wedge w_l\wedge w_{i+1 \wedge\ldots\wedge w_k = 0,\]</div>
<p>denn in jedem Summanden kommt <span class="math notranslate nohighlight">\(w_l\)</span> doppelt vor.</p>
<ul class="simple">
<li><p>Andernfalls können wir die Vektoren <span class="math notranslate nohighlight">\(w_1,\ldots,w_k\)</span> zu einer Basis</p></li>
</ul>
<div class="math notranslate nohighlight">
\[w_1,\ldots,w_n \text{ mit } n:=\dim(E^*)\]</div>
<p>ergänzen, sodass <span class="math notranslate nohighlight">\(w_1\wedge\ldots\wedge w_n\neq0\)</span> ist.
Dann ist aber auch <span class="math notranslate nohighlight">\(w_1\wedge\ldots\wedge w_k\neq0\)</span>.</p>
</div>
<div class="proof definition admonition" id="Grassmannalgebra &quot;uber $E$.">
<p class="admonition-title"><span class="caption-number">Definition 3.8 </span> (Grassmannalgebra)</p>
<div class="definition-content section" id="proof-content">
<p>Für einen endlich-dimensionalen <span class="math notranslate nohighlight">\(\R\)</span>-Vektorraum <span class="math notranslate nohighlight">\(E\)</span> heißt der reelle Vektorraum</p>
<div class="math notranslate nohighlight">
\[\Lambda^*(E) := \bigoplus_{k=0}^{\dim(E)}\Lambda^k(E)\]</div>
<p>(mit <span class="math notranslate nohighlight">\(\Lambda^0(E):=\R\)</span>) mit der durch das Dachprodukt
gegebenen Multiplikation die <strong>äußere</strong> oder
<a class="reference external" href="https://de.wikipedia.org/wiki/Gra%C3%9Fmann-Algebra"><strong>Grassmann-Algebra</strong></a></p>
</div>
</div><div class="proof remark admonition" id="remark-18">
<p class="admonition-title"><span class="caption-number">Remark 3.6 </span></p>
<div class="remark-content section" id="proof-content">
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\dim(\Lambda^*(E)) = 2^{\dim(E)}\)</span>, denn <span class="math notranslate nohighlight">\(\sum_{k=0}^n{n\choose k} = 2^n\)</span>.</p></li>
<li><p>Für beliebige <span class="math notranslate nohighlight">\(k,l\in\N_0\)</span> ist für alle <span class="math notranslate nohighlight">\(\omega\in\Lambda^k(E)\)</span> und
<span class="math notranslate nohighlight">\(\varphi\in\Lambda^l(E)\)</span>:\ <span class="math notranslate nohighlight">\(\omega\wedge\varphi\in\Lambda^{k+l}(E)\)</span>, aber für
<span class="math notranslate nohighlight">\(m&gt;\dim(E)\)</span> ist <span class="math notranslate nohighlight">\(\dim(\Lambda^m(E))=0\)</span>.</p></li>
</ul>
</div>
</div><div class="proof definition admonition" id="pull-back von $\omega$ mit $f$.">
<p class="admonition-title"><span class="caption-number">Definition 3.9 </span></p>
<div class="definition-content section" id="proof-content">
<p>Für eine lineare Abbildung <span class="math notranslate nohighlight">\(f:E\to F\)</span> endlichdimensionaler <span class="math notranslate nohighlight">\(\R\)</span>–Vektorräume und <span class="math notranslate nohighlight">\(\omega\in\Lambda^k(F)\)</span> heißt die durch</p>
<div class="math notranslate nohighlight">
\[f^*(\omega)( v_1,\ldots, v_k) := \omega \big(f( v_1),\ldots,f( v_k)\big)
\qquad (v_1,\ldots,v_k\in E)\]</div>
<p>definierte <span class="math notranslate nohighlight">\(k\)</span>–Form <span class="math notranslate nohighlight">\(f^*(\omega)\)</span> die <strong>Zurückziehung</strong> (engl.
<strong>pull–back</strong>).</p>
</div>
</div><p>Es gilt offensichtlich <span class="math notranslate nohighlight">\(f^*(\omega)\in\Lambda^k(E)\)</span>, denn <span class="math notranslate nohighlight">\(f^*(\omega)\)</span>
ist <span class="math notranslate nohighlight">\(k\)</span>–linear und antisymmetrisch.</p>
<div class="proof theorem admonition" id="theorem-20">
<p class="admonition-title"><span class="caption-number">Theorem 3.3 </span></p>
<div class="theorem-content section" id="proof-content">
<ul class="simple">
<li><p>Die Abbildung <span class="math notranslate nohighlight">\(f^*:\Lambda^*(F)\to\Lambda^*(E)\)</span> ist linear.</p></li>
<li><p>Für <span class="math notranslate nohighlight">\(g\in L(F,G)\)</span> ist <span class="math notranslate nohighlight">\((g\circ f)^*=f^*\circ g^*\)</span>.</p></li>
<li><p>Für die identische Abbildung <span class="math notranslate nohighlight">\(Id_E:E\to E\)</span> ist <span class="math notranslate nohighlight">\(Id_E^* = Id_{\Lambda^*(E)}\)</span>.</p></li>
<li><p>Für eine invertierbare Abbildung <span class="math notranslate nohighlight">\(f\in {\rm GL}(E,F)\)</span> ist <span class="math notranslate nohighlight">\((f^*)^{-1}=(f^{-1})^*\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(f^*(\alpha\wedge\beta) = f^*(\alpha)\wedge f^*(\beta)\)</span>.</p></li>
</ul>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. Für alle Vektoren <span class="math notranslate nohighlight">\(v_1,\ldots,v_k\in E\)</span> gilt</p>
<ul class="simple">
<li><p>Mit <span class="math notranslate nohighlight">\(\alpha, \beta\in\Lambda^k(F)\)</span> und <span class="math notranslate nohighlight">\(c_1,c_2\in\R\)</span> ist</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}f^*(c_1\alpha+c_2\beta)(v_1,\ldots,v_k)
 &amp;=&amp; (c_1\alpha+c_2\beta) \big(f(v_1),\ldots,f(v_k)\big)\\
&amp;=&amp; c_1\alpha\big(f(v_1),\ldots,f(v_k)\big) + c_2\beta\big(f(v_1),\ldots,f(v_k)\big)\\
&amp;=&amp; c_1f^*\alpha(v_1,\ldots,v_k)+c_2f^*\beta(v_1,\ldots,v_k).\end{split}\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\((g\circ f)^*\alpha( v_1,\ldots, v_k) = \alpha\big(g\circ f( v_1),\ldots, g\circ f( v_k)\big)= g^*\alpha\big(f( v_1),\ldots,f( v_k)\big)\\=  f^*\circ g^*\alpha( v_1,\ldots, v_k)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(Id_E^*(\alpha)(v_1,\ldots,v_k) = \alpha\big(Id_E(v_1),\ldots,Id_E(v_k)\big)
= \alpha(v_1,\ldots,v_k)\)</span>.</p></li>
<li><p>Folgt aus 2. und 3.: <span class="math notranslate nohighlight">\((f^{-1})^*f^* = (f\circ f^{-1})^* = Id_F^* =
Id_{\Lambda^*(F)}\)</span>.</p></li>
<li><p>Hausaufgabe.</p></li>
</ul>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./vektoranalysis"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="multilinear.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title"><span class="section-number">3.1. </span>Multilinearformen</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="diffformen.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title"><span class="section-number">3.3. </span>Differentialformen</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By J. Laubmann, T. Roith, D. Tenbrinck<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>