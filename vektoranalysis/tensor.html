
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>3.2. Tensoren und Tensorprodukte &#8212; Mathematik für Physikstudierende C</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"Z": "\\mathbb{Z}", "V": "V", "N": "\\mathbb{N}", "C": "\\mathbb{C}", "Q": "\\mathbb{Q}", "K": "\\mathbb{K}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"], "R": ["\\mathbb{R}"], "norm": ["{\\Vert#1\\Vert}", 1], "abs": ["{|#1|}", 1], "coloneqq": ["{:=}"], "eqqcolon": ["{=:}"], "emph": ["\\pmb#1", 1], "tr": "\\operatorname{Spur}", "lin": "\\operatorname{lin}", "dv": "\\mathrm{div}~", "rot": "\\mathrm{rot}~", "Dim": "\\operatorname{dim}", "diag": "\\operatorname{diag}", "Kern": "\\operatorname{Kern}", "Bild": "\\operatorname{Bild}", "Rang": "\\operatorname{Rang}", "GL": "\\operatorname{GL}", "Eig": "\\operatorname{Eig}", "End": "\\operatorname{End}", "Hau": "\\operatorname{Haupt}", "mymathbb": ["\\boldsymbol{#1}", 1], "idx": "\\mathrm{d}x", "d": "\\mathrm{d}", "i": "\\mathrm{i}", "x": "\\mathbf{x}", "sign": "\\mathrm{sign}", "vec": ["\\mathbf{#1}", 1], "veczwei": ["\\begin{pmatrix} #1 \\\\ #2 \\end{pmatrix}", 2]}}, "tex2jax": {"processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/cropped-fau_solo_aufblau_192x192_rgb-180x180.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3.3. Differentialformen" href="diffformen.html" />
    <link rel="prev" title="3.1. Multilinearformen" href="multilinear.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/FAU-DMM-Logo-rgb-10cm.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Mathematik für Physikstudierende C</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Mathematik für Physikstudierende C
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ode/ode.html">
   1. Gewöhnliche Differentialgleichungen für dynamische Systeme
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ode/dynamicSystems.html">
     1.1. Einführung in dynamische Systeme
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ode/repetition.html">
     1.2. Wiederholung: Gewöhnliche Differentialgleichungen
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ode/fluesse.html">
     1.3. Phasenflüsse und Phasenportraits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ode/hamilton.html">
     1.4. Hamiltonsche Differentialgleichungen
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ode/ex.html">
     1.5. Aufgaben
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../odestability/stabilitaetsanalyse.html">
   2. Stabilitätsanalyse für dynamische Systeme
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../odestability/stabilitaetsbegriffe.html">
     2.1. Stabilitätsbegriffe
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../odestability/ruhelagen.html">
     2.2. Stabilität von Ruhelagen
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="vektoranalysis.html">
   3. Vektoranalysis
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="multilinear.html">
     3.1. Multilinearformen
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     3.2. Tensoren und Tensorprodukte
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="diffformen.html">
     3.3. Differentialformen
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../references.html">
   4. Bibliography
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/vektoranalysis/tensor.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/FAU-AMMN/MathPhysicsC"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivation">
   3.2.1. Motivation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#das-tensorprodukt">
   3.2.2. Das Tensorprodukt
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#existenz-und-konstruktion-des-tensorprodukts">
   3.2.3. Existenz und Konstruktion des Tensorprodukts
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#naturliche-homo-und-isomorphismen-des-tensorprodukts">
   3.2.4. Natürliche Homo- und Isomorphismen des Tensorprodukts
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tensoren-als-multilinearformen">
   3.2.5. Tensoren als Multilinearformen
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#symmetrie-und-antisymmetrie-von-tensoren">
   3.2.6. Symmetrie und Antisymmetrie von Tensoren
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#grassmann-algebra">
   3.2.7. Grassmann-Algebra
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="tensoren-und-tensorprodukte">
<h1><span class="section-number">3.2. </span>Tensoren und Tensorprodukte<a class="headerlink" href="#tensoren-und-tensorprodukte" title="Permalink to this headline">¶</a></h1>
<p>In diesem Kapitel widmen wir uns einem für die Physik sehr wichtigen aber relativ abstrakten Thema der Vektoranalysis, nämlich <em>Tensoren</em> und <em>Tensorprodukten</em>.
Der Begriff hat sehr viele verschiedene Anschauungsmöglichkeiten (siehe <a class="reference external" href="https://de.wikipedia.org/wiki/Tensorprodukt">Wikipedia</a>) weshalb es nicht leicht ist eine Einführung zu geben die gleichzeitig allgemein, aber auch verständlich ist. Da Tensoren aber eine wichtige Rolle in der Physik spielen werden wir uns hier damit beschäftigen.</p>
<div class="section" id="motivation">
<h2><span class="section-number">3.2.1. </span>Motivation<a class="headerlink" href="#motivation" title="Permalink to this headline">¶</a></h2>
<p>Wir betrachten zunächst ein konkretes Anwendungsbeispiel aus der Physik, welches auf Tensoren zurückgreift.
Hier wird der sogenannte <em>Cauchy Spannungstensor</em> verwendet.</p>
<div class="proof remark admonition" id="remark-0">
<p class="admonition-title"><span class="caption-number">Remark 3.5 </span> (Begriffsherkunft)</p>
<div class="remark-content section" id="proof-content">
<p>Der Begriff Tensor wurde von Hamilton in der Mitte des 19. Jahrhunderts eingeführt. Er leitete die Bezeichnung vom lateinischen <em>tendere</em> (spannen) ab, da die ursprüngliche Anwendung derartiger Objekte in der Elastizitätstheorie Anwendung fand.</p>
</div>
</div><div class="margin sidebar">
<p class="sidebar-title">Augustin Cauchy</p>
<p><a class="reference external" href="https://de.wikipedia.org/wiki/Augustin-Louis_Cauchy">Augustin-Louis Cauchy</a> (Geboren 21. August 1789 in Paris; Gestorben 23. Mai 1857 in Sceaux) war ein französischer Mathematiker.</p>
</div>
<p>Mechanische Spannung ist eine physikalische Größe, die die innere Beanspruchung und Kräfte in einem Volumen <span class="math notranslate nohighlight">\(V\subset\R^3\)</span> angibt, welche aufgrund einer äußeren Belastungen auftreten.
Die grundlegende Idee ist das <strong>Euler-Cauchy Spannungsprinzip</strong>, welches beschreibt, dass auf jede Schnittfläche <span class="math notranslate nohighlight">\(A\subset\R^2\)</span>, die ein Volumen in zwei Teile trennt, von diesen zwei Volumenteilen eine Spannung auf <span class="math notranslate nohighlight">\(A\)</span> ausgeübt wird, welche durch einen sogenannten <strong>Spannungsvektor</strong> <span class="math notranslate nohighlight">\(\mathbf{T}^{(n)}\)</span> beschrieben wird.
Der Komponenten des Spannungsvektors haben hierbei die Dimension “Kraft pro Fläche”.</p>
<div class="figure align-default" id="fig-stress">
<a class="reference internal image-reference" href="../_images/stress_vector.png"><img alt="../_images/stress_vector.png" src="../_images/stress_vector.png" style="height: 250px;" /></a>
<p class="caption"><span class="caption-number">Fig. 3.1 </span><span class="caption-text">Visualisierung für Normal- und Scherspannung an einer Schnittfläche. Quelle: <a class="reference external" href="https://en.wikipedia.org/wiki/Cauchy_stress_tensor">Wikipedia; Cauchy Stress Tensor</a>.</span><a class="headerlink" href="#fig-stress" title="Permalink to this image">¶</a></p>
</div>
<p>Wie in <a class="reference internal" href="#fig-stress"><span class="std std-numref">Fig. 3.1</span></a> visualisiert teilt sich die Spannung in zwei Komponenten auf:</p>
<p><strong>Normalspannung:</strong></p>
<p>Die Normalspannung <span class="math notranslate nohighlight">\(\sigma_n\)</span> ist der Teil des Spannungsvektors, der in Richtung der Normalen <span class="math notranslate nohighlight">\(\mathbf{n}\)</span> zeigt, welche orthogonal auf der Schnittfläche steht.</p>
<p><strong>Scherspannung:</strong></p>
<p>Die Scherspannung <span class="math notranslate nohighlight">\(\tau_n\)</span> ist der Teil des Spannungstensors, der parallel zur Schnittfläche liegt.</p>
<p>Man erkennt nun, dass die Spannung in <span class="math notranslate nohighlight">\(V\)</span> nicht durch einen einzigen Vektor ausgedrückt werden kann. Einerseits hängt sie vom betrachteten Punkt <span class="math notranslate nohighlight">\(x\in V\)</span> ab und zudem von der Orientierung der Schnittfläche. Allerdings hat Cauchy gezeigt, dass ein linearer Operator <span class="math notranslate nohighlight">\(\mathbf{\sigma}(x)\)</span> existiert, so dass</p>
<div class="math notranslate nohighlight">
\[\mathbf{T}^{(n)}(x) = \mathbf{\sigma}(x) \cdot n,\]</div>
<p>d.h. in jedem Punkt <span class="math notranslate nohighlight">\(x\in V\)</span> ist der Stressvektor linear im Normalenvektor <span class="math notranslate nohighlight">\(n\)</span>.</p>
<div class="figure align-default" id="fig-stress-comp">
<a class="reference internal image-reference" href="../_images/stress_tensor_comp.png"><img alt="../_images/stress_tensor_comp.png" src="../_images/stress_tensor_comp.png" style="height: 250px;" /></a>
<p class="caption"><span class="caption-number">Fig. 3.2 </span><span class="caption-text">Quelle: <a class="reference external" href="https://de.wikipedia.org/wiki/Spannungstensor">Wikipedia; Spannungstensor</a>.</span><a class="headerlink" href="#fig-stress-comp" title="Permalink to this image">¶</a></p>
</div>
<p>Der lineare Operator <span class="math notranslate nohighlight">\(\mathbf{\sigma}\)</span> wird auch <strong>Cauchy Spannungstensor</strong> genannt.
Um diesen besser zu verstehen betrachtet man für einen fixen Punkt <span class="math notranslate nohighlight">\(x\)</span> des Volumens einen infinitesimal kleinen, freigeschnittenen Würfel wie in <a class="reference internal" href="#fig-stress-comp"><span class="std std-numref">Fig. 3.2</span></a>.
Nun definieren wir für die drei verschiedenen Flächen (orthogonal zu den Einheitsvektoren <span class="math notranslate nohighlight">\(e_1, e_2\)</span> und <span class="math notranslate nohighlight">\(e_3\)</span>) die Spannungsvektoren</p>
<div class="math notranslate nohighlight">
\[\mathbf{T}^{(e_i)}:= \sum_{j=1}^3 \sigma_{ij} e_j, \quad i \in \lbrace 1,2,3 \rbrace.\]</div>
<p>So setzt sich beispielsweise der Spannungsvektor <span class="math notranslate nohighlight">\(\mathbf{T}^{(e_1)}\)</span> zusammen aus der Summe der Normalspannung <span class="math notranslate nohighlight">\(\sigma_{11} e_1\)</span> und den zwei Scherspannungskomponenten <span class="math notranslate nohighlight">\(\sigma_{12} e_2\)</span> und <span class="math notranslate nohighlight">\(\sigma_{13} e_3\)</span>.</p>
<p>Insgesamt erhält man neun Spannungskomponenten <span class="math notranslate nohighlight">\(\sigma_{ij}\)</span> für <span class="math notranslate nohighlight">\(i,j=1,2,3\)</span> welche insgesamt den Spannungszustand im Punkt <span class="math notranslate nohighlight">\(x\)</span> als Spannungsvektoren in Richtung der Einheitsvektoren vollständig beschreiben.
Dies liegt daran, dass wir jeden Spannungsvektor in <span class="math notranslate nohighlight">\(x\)</span> als Linearkombination der drei Spannungsvektoren <span class="math notranslate nohighlight">\(\mathbf{T}^{(e_i)}, i=1,2,3\)</span> darstellen können.</p>
<p>Wir führen nun eine <em>multilineare Abbildung</em> <span class="math notranslate nohighlight">\(\otimes \colon \R^n \times \R^m \rightarrow \R^{n \times m}\)</span> für zwei beliebige Vektoren <span class="math notranslate nohighlight">\(x\in\R^n\)</span> und <span class="math notranslate nohighlight">\(y\in\R^m\)</span> ein, die das <strong>dyadische Produkt</strong> der Vektoren genannt wird und wie folgt definiert ist</p>
<div class="math notranslate nohighlight">
\[\begin{split}x \otimes y := 
\begin{pmatrix}
x_1y_1 &amp;\ldots &amp;x_1 y_m\\
\vdots &amp;\ddots &amp; \vdots\\
x_n y_1&amp;\ldots&amp; x_n y_m
\end{pmatrix}.\end{split}\]</div>
<p>Fassen wir nun zeilenweise die Spannungsvektoren <span class="math notranslate nohighlight">\(\mathbf{T}^{(e_i)}, i=1,2,3\)</span> in einer Matrix zusammen, so erhalten wir den Cauchy Spannungstensor <span class="math notranslate nohighlight">\(\mathbf{\sigma}\)</span> für den Punkt <span class="math notranslate nohighlight">\(x\)</span> des Volumens als</p>
<div class="math notranslate nohighlight" id="equation-eq-cauchyspannungstensor">
<span class="eqno">(3.1)<a class="headerlink" href="#equation-eq-cauchyspannungstensor" title="Permalink to this equation">¶</a></span>\[\begin{split}\mathbf{\sigma} := 
\begin{pmatrix}
\sigma_{11} &amp; \sigma_{12} &amp; \sigma_{13} \\
\sigma_{21} &amp; \sigma_{22} &amp; \sigma_{23} \\
\sigma_{31} &amp; \sigma_{32} &amp; \sigma_{33}
\end{pmatrix} 
&amp;= 
\begin{pmatrix}
\mathbf{T}^{(e_1)} \\
\mathbf{T}^{(e_2)} \\
\mathbf{T}^{(e_3)}
\end{pmatrix}
= 
\begin{pmatrix}
\mathbf{T}^{(e_1)} \\
0 \\
0
\end{pmatrix}
+
\begin{pmatrix}
0 \\
\mathbf{T}^{(e_2)} \\
0
\end{pmatrix}
+
\begin{pmatrix}
0 \\
0 \\
\mathbf{T}^{(e_3)} \\
\end{pmatrix}\\
&amp;=
\sum_{i=1}^3 e_i \otimes \mathbf{T}^{(e_i)} = \sum_{i=1}^3 e_i\otimes ( \sum_{j=1}^3 \sigma_{ij} e_j) =
\sum_{i=1}^3\sum_{j=1}^3 \sigma_{ij} (e_i\otimes e_j).\end{split}\]</div>
<p>Wir werden später sehen, dass man die Idee, den Operator <span class="math notranslate nohighlight">\(\sigma\)</span> über das dyadische Produkt zu definieren, abstrahieren kann, was auf den allgemeinen Tensorbegriff führt.</p>
<div class="proof remark admonition" id="remark-1">
<p class="admonition-title"><span class="caption-number">Remark 3.6 </span></p>
<div class="remark-content section" id="proof-content">
<p>In der Tat handelt es sich bei dem Operator <span class="math notranslate nohighlight">\(\sigma \colon \R^3 \rightarrow \R^3\)</span> in <a class="reference internal" href="#equation-eq-cauchyspannungstensor">(3.1)</a> nicht nur um einen Tensor, sondern genauer um ein <strong>Tensorfeld</strong>, dass jedem Punkt <span class="math notranslate nohighlight">\(x\)</span> des Volumens einen Spannungstensor zuordnet.</p>
</div>
</div></div>
<div class="section" id="das-tensorprodukt">
<h2><span class="section-number">3.2.2. </span>Das Tensorprodukt<a class="headerlink" href="#das-tensorprodukt" title="Permalink to this headline">¶</a></h2>
<p>Wir wollen nun das Tensorprodukt von Vektorräumen abstrakt einführen und es an späterer Stelle für konkrete Realisierungen diskutieren.
Hierbei wollen wir uns zunächst auf einen Spezialfall einschränken, der lediglich <em>zwei Vektorräume</em> berücksichtigt, um die zu Grunde liegenden wichtigen Konzepte klarer herauszustellen.
Es ist wichtig zu verstehen, dass die folgenden Definitionen sich mit dem Konzept der <span class="math notranslate nohighlight">\(k\)</span>-Multilinearität in <a class="reference internal" href="multilinear.html#s-multilinearformen"><span class="std std-ref">Multilinearformen</span></a> auf <span class="math notranslate nohighlight">\(k \in \N\)</span> verschiedene <span class="math notranslate nohighlight">\(\R\)</span>-Vektorräume direkt verallgemeinern lassen.</p>
<div class="proof definition admonition" id="def:tensor">
<p class="admonition-title"><span class="caption-number">Definition 3.4 </span> (Tensorprodukt)</p>
<div class="definition-content section" id="proof-content">
<p>Es seien <span class="math notranslate nohighlight">\(V\)</span> und <span class="math notranslate nohighlight">\(W\)</span> zwei reelle Vektorräume.
Ein reeller Vektorraum <span class="math notranslate nohighlight">\(X\)</span> heißt <strong>Tensorproduktraum</strong> falls eine bilineare Abbildung <span class="math notranslate nohighlight">\(\otimes:V\times W\rightarrow X\)</span> existiert, so dass die folgende <strong>universelle Eigenschaft</strong> gilt:</p>
<p>Für jede Bilinearform <span class="math notranslate nohighlight">\(\phi\in L^2(V\times W; Y)\)</span> in einen beliebigen reellen Vektorraum <span class="math notranslate nohighlight">\(Y\)</span>, existiert eine eindeutige lineare Abbildung
<span class="math notranslate nohighlight">\(p \in L^1(X; Y)\)</span>, so dass gilt</p>
<div class="math notranslate nohighlight" id="equation-eq-universell">
<span class="eqno">(3.2)<a class="headerlink" href="#equation-eq-universell" title="Permalink to this equation">¶</a></span>\[\phi(v,w) = p(v\otimes w) = p(\otimes(v,w))\quad\forall (v,w)\in V\times W.\]</div>
<p>In diesem Fall schreibt man auch <span class="math notranslate nohighlight">\(X = V \otimes W\)</span>.
Wir nennen die bilineare Abbildung <span class="math notranslate nohighlight">\(\otimes\)</span> <strong>Tensorprodukt</strong> und verwenden häufig für sie die Infix-Schreibweise <span class="math notranslate nohighlight">\(v\otimes w := \otimes(v,w)\)</span>.
Elemente <span class="math notranslate nohighlight">\(x \in X\)</span> des Tensorproduktraums <span class="math notranslate nohighlight">\(X = V \otimes W\)</span> nennen wir <strong>Tensoren</strong>.</p>
</div>
</div><p>Diese Definition erscheint auf den ersten Blick abstrakt und unverständlich.
Was ist jetzt also genau ein Tensorprodukt?</p>
<p><strong>Das Tensorprodukt ist universell:</strong></p>
<p>Wir haben in der <a class="reference internal" href="#def:tensor">Definition 3.4</a> das kartesische Produkt <span class="math notranslate nohighlight">\(\times\)</span> benutzt welches eindeutig definiert ist.
Im Gegensatz dazu gibt es jedoch nicht <em>ein</em> Tensorprodukt <span class="math notranslate nohighlight">\(\otimes\)</span> oder <em>einen</em> Tensorproduktraum <span class="math notranslate nohighlight">\(V\otimes W\)</span>.
Wir haben die Freiheit <span class="math notranslate nohighlight">\(\otimes\)</span> zu wählen und wann immer die universelle Eigenschaft erfüllt ist, heißt dann <span class="math notranslate nohighlight">\(X = V\otimes W\)</span> Tensorproduktraum.
Derartige Konzepte nennt man in der Algebra <em>universell</em>.
Betrachten wir hierzu ein kurzes Beispiel für unterschiedliche Realisierungen eines Tensorproduktes.</p>
<div class="proof example admonition" id="ex:tensorproduktVarianten">
<p class="admonition-title"><span class="caption-number">Example 3.5 </span> (Varianten eines Tensorprodukts)</p>
<div class="example-content section" id="proof-content">
<p>Wir betrachten in diesem Beispiel den Euklidischen Vektorraum <span class="math notranslate nohighlight">\(V=W=\R^2\)</span> und zwei Vektoren <span class="math notranslate nohighlight">\(x, y \in \R^2\)</span>.
Nehmen wir zunächst das Tensorprodukt, dass durch das <strong>dyadische Produkt</strong> <span class="math notranslate nohighlight">\(\otimes : \R^2 \times \R^2 \rightarrow \R^{2 \times 2}\)</span> gegeben ist mit</p>
<div class="math notranslate nohighlight">
\[\begin{split}x \otimes y \, \coloneqq \,
\begin{pmatrix}
x_1y_1 &amp; x_1y_2 \\
x_2y_1 &amp; x_2y_2
\end{pmatrix}.\end{split}\]</div>
<p>Man sieht ein, dass der zugehörige <em>Tensorproduktraum</em> also <span class="math notranslate nohighlight">\(\R^{2 \times 2} = \R^2 \otimes \R^2\)</span> sein muss.
Anderseits erhält man den gleichen Tensorproduktraum, wenn man ein <strong>alternatives Tensorprodukt</strong> <span class="math notranslate nohighlight">\(\otimes^*\)</span> zum dyadischen Produkt definiert, welches lediglich die Reihenfolge der Komponenten von <span class="math notranslate nohighlight">\(y\)</span> vertauscht mit</p>
<div class="math notranslate nohighlight">
\[\begin{split}x \otimes^* y \, \coloneqq \,
\begin{pmatrix}
x_1y_2 &amp; x_1y_1 \\
x_2y_2 &amp; x_2y_1
\end{pmatrix}.\end{split}\]</div>
</div>
</div><p><strong>Was bedeutet die universelle Eigenschaft?</strong></p>
<p>Wie wir weiter unten noch genauer beschreiben werden, stellt die universelle Eigenschaft eine wichtige Beziehung zwischen dem Raum der bilinearen Abbildungen auf <span class="math notranslate nohighlight">\(V\times W\)</span> und dem Raum der linearen Abbildungen von <span class="math notranslate nohighlight">\(X = V\otimes W\)</span> nach <span class="math notranslate nohighlight">\(Y\)</span> für ein Tensorprodukt <span class="math notranslate nohighlight">\(\otimes\)</span> her.
Für den Spezialfall <span class="math notranslate nohighlight">\(Y = \R\)</span> ist letzterer gerade der <em>algebraische Dualraum</em> des Tensorproduktraums.
Sofern wir das Tensorprodukt gegeben haben erhalten wir alle Bilinearformen also schon über einfache Linearformen auf <span class="math notranslate nohighlight">\(V\otimes W\)</span>.</p>
<p>Das folgende einfache Beispiel soll uns helfen diese Beziehung besser zu verstehen.</p>
<div class="proof example admonition" id="ex:universelleEigenschaft">
<p class="admonition-title"><span class="caption-number">Example 3.6 </span> (Universelle Eigenschaft)</p>
<div class="example-content section" id="proof-content">
<p>Im Folgenden betrachten wir wieder den Euklidischen Vektorraum <span class="math notranslate nohighlight">\(V=W=\R^2\)</span> und zwei Vektoren <span class="math notranslate nohighlight">\(x, y \in \R^2\)</span>.
Wie wir in <a class="reference internal" href="#ex:tensorproduktVarianten">Example 3.5</a> festgestellt haben realisiert das dyadische Produkt</p>
<div class="math notranslate nohighlight">
\[\otimes \colon \R^2 \times \R^2 \rightarrow \R^2 \otimes \R^2 = \R^{2 \times 2} =: X\]</div>
<p>mit</p>
<div class="math notranslate nohighlight">
\[\begin{split}x \otimes y \, \coloneqq \,
\begin{pmatrix}
x_1y_1 &amp; x_1y_2 \\
x_2y_1 &amp; x_2y_2
\end{pmatrix}.\end{split}\]</div>
<p>ein <em>Tensorprodukt</em> der Vektorräume <span class="math notranslate nohighlight">\(V=W=\R^2\)</span>.
Wegen der <em>universellen Eigenschaft</em> muss nun gelten, dass für jede Bilinearform <span class="math notranslate nohighlight">\(\Phi \in L^2(V \times W; Y)\)</span> für beliebige <span class="math notranslate nohighlight">\(\R\)</span>-Vektorräume <span class="math notranslate nohighlight">\(Y\)</span> eine eindeutige lineare Abbildung <span class="math notranslate nohighlight">\(p \in L^1(X; Y)\)</span> existiert, die äquivalent im Sinne von <a class="reference internal" href="#equation-eq-universell">(3.2)</a> ist.</p>
<p>Nehmen wir also beispielsweise das Skalarprodukt <span class="math notranslate nohighlight">\(\langle \cdot, \cdot \rangle \colon V \times W \rightarrow \R\)</span> als eine mögliche Bilinearform <span class="math notranslate nohighlight">\(\Phi \in L^2(V \times W; Y)\)</span> mit</p>
<div class="math notranslate nohighlight">
\[\langle x, y \rangle = x^T \cdot y = x_1y_1 + x_2y_2.\]</div>
<p>Wir müssen nun einen linearen Operator <span class="math notranslate nohighlight">\(p \in L^1(X; Y)\)</span> finden, der eine äquivalente Berechnung wie das Skalarprodukt auf dem Tensorproduktraum <span class="math notranslate nohighlight">\(X = \R^{2 \times 2}\)</span>, der durch das dyadische Produkt induziert wird, durchführt.
Hierzu wählen wir die Spur <span class="math notranslate nohighlight">\(p(A) \coloneqq \operatorname{Spur}(A)\)</span> einer Matrix <span class="math notranslate nohighlight">\(A \in \R^{2 \times 2}\)</span>, denn diese ist <strong>linear</strong> und es gilt:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\operatorname{Spur}
\begin{pmatrix}
a_{11} &amp; a_{12} \\
a_{21} &amp; a_{22}
\end{pmatrix}
= a_{11} + a_{22}.\end{split}\]</div>
<p>Überprüfen wir mit dieser Wahl nun die <strong>universelle Eigenschaft des dyadischen Produkts</strong>, so erhalten wir</p>
<div class="math notranslate nohighlight">
\[\begin{split}\Phi(x,y) = \langle x, y \rangle = x_1y_1 + x_2y_2 = \operatorname{Spur}
\begin{pmatrix}
x_1y_1 &amp; x_1y_2 \\
x_2y_1 &amp; x_2y_2
\end{pmatrix}
 = \operatorname{Spur}(x \otimes y) = p(x \otimes y).\end{split}\]</div>
<p>Es sei angemerkt, dass wir nicht gezeigt haben, dass der Spur-Operator der <em>einzige</em> lineare Operator ist, der diese Äquivalenz erfüllt.
Betrachten wir statt dessen die alternative Variante <span class="math notranslate nohighlight">\(\otimes^*\)</span> des dyadischen Produkts aus <a class="reference internal" href="#ex:tensorproduktVarianten">Example 3.5</a>, so bleibt der Tensorproduktraum gleich, jedoch ändert sich der eindeutig bestimmte, lineare Operator <span class="math notranslate nohighlight">\(p \in L^1(X; Y)\)</span>.
Durch die Vertauschung der Elemente der Matrix <span class="math notranslate nohighlight">\(x \otimes^* y\)</span> nimmt man nicht mehr die Summe der Hauptdiagonalelemente realisiert durch den Operator <span class="math notranslate nohighlight">\(\operatorname{Spur}(A) = a_{11} + a_{22}\)</span>, sondern die <strong>Summe der Gegendiagonalelemente</strong> realisiert durch einen linearen Operator <span class="math notranslate nohighlight">\(\operatorname{Spur}^*(A) \coloneqq a_{21} + a_{12}\)</span>, d.h., die Diagonale von links unten nach rechts oben in der Matrix.
In diesem Fall erhält man nämlich analog</p>
<div class="math notranslate nohighlight">
\[\begin{split}\Phi(x,y) = \langle x, y \rangle = x_1y_1 + x_2y_2 = \operatorname{Spur}^*
\begin{pmatrix}
x_1y_2 &amp; x_1y_1 \\
x_2y_2 &amp; x_2y_1
\end{pmatrix}
 = \operatorname{Spur}^*(x \otimes^* y) = p(x \otimes^* y).\end{split}\]</div>
<p>Dies Veranschaulicht die Beziehung der involvierten Vektorräume und die zu Grunde liegende universelle Eigenschaft des Tensorprodukts.</p>
</div>
</div><div class="admonition danger">
<p class="admonition-title">Danger</p>
<p>Wir haben in <a class="reference internal" href="#ex:universelleEigenschaft">Example 3.6</a> lediglich die universelle Eigenschaft zur Veranschaulichung überprüft für ein konkretes Beispiel.
Wir haben jedoch <strong>nicht</strong> gezeigt, dass das dyadische Produkt die <em>universelle Eigenschaft</em> erfüllt.
Dafür hätten wir die Äquivalenz für <strong>alle möglichen</strong> Bilinearformen <span class="math notranslate nohighlight">\(\Phi \in L^2(V \times W; Y)\)</span> für <strong>beliebige Vektorräume</strong> <span class="math notranslate nohighlight">\(Y\)</span> beweisen müssen.</p>
</div>
</div>
<div class="section" id="existenz-und-konstruktion-des-tensorprodukts">
<h2><span class="section-number">3.2.3. </span>Existenz und Konstruktion des Tensorprodukts<a class="headerlink" href="#existenz-und-konstruktion-des-tensorprodukts" title="Permalink to this headline">¶</a></h2>
<p>Wir stellen fest, dass es für zwei beliebige <span class="math notranslate nohighlight">\(\R\)</span>-Vektorräume <span class="math notranslate nohighlight">\(V\)</span> und <span class="math notranslate nohighlight">\(W\)</span> immer ein Tensorprodukt gibt, und dass wir dieses Tensorprodukt konkret konstruieren können indem wir uns auf die Basis der Vektorräume <span class="math notranslate nohighlight">\(V\)</span> und <span class="math notranslate nohighlight">\(W\)</span> zurückziehen.
Diese Tatsache formulieren wir in der folgenden Aussage.</p>
<div class="proof theorem admonition" id="thm:existenzTensorprodukt">
<p class="admonition-title"><span class="caption-number">Theorem 3.1 </span> (Existenz des Tensorprodukts)</p>
<div class="theorem-content section" id="proof-content">
<p>Für zwei reelle Vektorräume <span class="math notranslate nohighlight">\(V, W\)</span> existiert stets mindestens ein Tensorprodukt <span class="math notranslate nohighlight">\(\otimes\in L^2(V\times W; V\otimes W)\)</span>.</p>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. Der folgende Beweis ist ein sogenannter <em>konstruktiver Beweis</em>, d.h., wir zeigen die Existenz eines Objekts indem wir es explizit angeben.
Im Gegensatz hierzu gibt es auch nicht-konstruktive Existenzbeweise.</p>
<p>Es sei <span class="math notranslate nohighlight">\(B^V = \{b_i^V: i\in I^V\}\)</span> eine Basis von <span class="math notranslate nohighlight">\(V\)</span> und es sei analog <span class="math notranslate nohighlight">\(B^W = \{b_i^W: i\in I^W\}\)</span> eine Basis von <span class="math notranslate nohighlight">\(W\)</span> für zwei Indexmengen <span class="math notranslate nohighlight">\(I^V\)</span> und <span class="math notranslate nohighlight">\(I^W\)</span>.
Wir betrachten zunächst das kartesische Produkt der beiden Indexmengen</p>
<div class="math notranslate nohighlight">
\[J := I^V \times I^W = \{(i,j): i\in I^V, j\in I^W\}.\]</div>
<p>Es sei nun <span class="math notranslate nohighlight">\(X\)</span> ein reeller Vektorraum dessen Basis sich durch <span class="math notranslate nohighlight">\(J\)</span> indizieren lässt, das heißt es existiert eine Menge</p>
<div class="math notranslate nohighlight">
\[B^X = \{b_{ij}^X: (i,j)\in J\},\]</div>
<p>so dass <span class="math notranslate nohighlight">\(B^X\)</span> eine Hamel-Basis von <span class="math notranslate nohighlight">\(X\)</span> ist.
Man kann zeigen, dass ein solcher Vektorraum immer existiert.</p>
<p>Wir definieren nun eine bilineare Abbildung <span class="math notranslate nohighlight">\(\otimes: V\times W \to X\)</span> über</p>
<div class="math notranslate nohighlight">
\[\otimes (b_i^V, b_j^W) = b_i^V \otimes b_j^W := b_{ij}^X \quad \forall (i,j)\in J.\]</div>
<p>Es sei darauf hingewiesen, dass die bilineare Abbildung <span class="math notranslate nohighlight">\(\otimes\)</span> durch eine Definition über die Indexmenge <span class="math notranslate nohighlight">\(J\)</span> eindeutig festgelegt ist.
Dies liegt daran, dass für beliebige Paare <span class="math notranslate nohighlight">\((v,w)\in V\times W\)</span> endlich viele Koeffizienten <span class="math notranslate nohighlight">\(\alpha_{i_1},\ldots,\alpha_{i_n}\)</span> und <span class="math notranslate nohighlight">\(\beta_{j_1},\ldots, \beta_{j_m}\)</span> existieren, so dass für die Vektoren <span class="math notranslate nohighlight">\(v \in V\)</span> und <span class="math notranslate nohighlight">\(w \in W\)</span> eine Darstellung in den jeweiligen Hamel-Basen existiert mit</p>
<div class="math notranslate nohighlight">
\[v = \sum_{k=1}^n \alpha_{i_k} b_{i_k}^V, \quad w = \sum_{l=1}^m \beta_{j_l} b_{j_l}^W.\]</div>
<p>Durch diese Darstellung erhalten wir für die bilineare Abbildung <span class="math notranslate nohighlight">\(\otimes: V\times W \to X\)</span> nun eine <strong>explizite Vorschrift</strong> als</p>
<div class="math notranslate nohighlight">
\[\otimes(v,w) 
= 
\otimes\big(\sum_{k=1}^n \alpha_{i_k} b_{i_k}^V, \sum_{l=1}^m \beta_{j_l} b_{j_l}^W\big) = 
\sum_{k=1}^n \sum_{l=1}^m \alpha_{i_k} \beta_{j_l} \otimes\left(b_{i_k}^V, b_{j_l}^W\right) =
\sum_{k=1}^n \sum_{l=1}^m \alpha_{i_k} \beta_{j_l} b_{i_kj_l}^X.\]</div>
<p>Wir müssen nun noch die <strong>universelle Eigenschaft</strong> der bilinearen Abbildung <span class="math notranslate nohighlight">\(\otimes\)</span> nachweisen, um zu zeigen, dass es sich um ein Tensorprodukt handelt.
Sei dazu <span class="math notranslate nohighlight">\(\phi\in L^2(V\times W; Y)\)</span> eine Bilinearform auf einen beliebigen reellen Vektorraum <span class="math notranslate nohighlight">\(Y\)</span>.
Dann können wir eine Linearform auf <span class="math notranslate nohighlight">\(p: X\to Y\)</span> explizit definieren durch Angabe ihrer Wirkung auf die Basiselemente mit</p>
<div class="math notranslate nohighlight">
\[p(b_{ij}^X) := \phi(b_i^V, b_j^W) \quad \forall (i,j) \in J.\]</div>
<p>Dann gilt nämlich, unter Ausnutzung der Linearität von <span class="math notranslate nohighlight">\(p\)</span> und der obigen Rechnung, dass gilt</p>
<div class="math notranslate nohighlight">
\[\begin{split}p(\otimes(v,w))
&amp;= p \left( \sum_{k=1}^n \sum_{l=1}^m \alpha_{i_k} \beta_{j_l} b_{i_kj_l}^X \right)
= \sum_{k=1}^n \sum_{l=1}^m \alpha_{i_k} \beta_{j_l} p(b_{i_kj_l}^X) \\
&amp;= \sum_{k=1}^n \sum_{l=1}^m \alpha_{i_k} \beta_{j_l} \phi\left(b_{i_k}^V, b_{j_l}^W\right)
= \phi\big(\sum_{k=1}^n \alpha_{i_k} b_{i_k}^V,\sum_{l=1}^m \beta_{j_l} b_{j_l}^W\big)
= \phi(v,w)\end{split}\]</div>
<p>Wir sehen also, dass <span class="math notranslate nohighlight">\(\otimes\)</span> die universelle Eigenschaft erfüllt und zwar insbesondere dadurch, dass die Linearform <span class="math notranslate nohighlight">\(p\)</span> durch die obige Definition eindeutig festgelegt ist.</p>
</div>
<p>Als Korollar aus <a class="reference internal" href="#thm:existenzTensorprodukt">Theorem 3.1</a> erhalten wir somit, dass eine Basis des Tensorproduktraums durch das kartesische Produkt der ursprünglichen Basen konstruiert werden kann.
Hieran sieht man den qualitativen Unterschied zwischen <span class="math notranslate nohighlight">\(V \times W\)</span> und <span class="math notranslate nohighlight">\(V\otimes W\)</span>.</p>
<div class="proof corollary admonition" id="corollary-6">
<p class="admonition-title"><span class="caption-number">Corollary 3.1 </span></p>
<div class="corollary-content section" id="proof-content">
<p>Für zwei reelle Vektorräume <span class="math notranslate nohighlight">\(V\)</span> und <span class="math notranslate nohighlight">\(W\)</span> mit zugehörigen Hamel-Basen</p>
<div class="math notranslate nohighlight">
\[B^V = \{b_i^V: i\in I^V\}, \quad B^W = \{b_i^W: i\in I^W\},\]</div>
<p>und einem Tensorprodukt <span class="math notranslate nohighlight">\(\otimes:V\times W \to V\otimes W\)</span> ist</p>
<div class="math notranslate nohighlight">
\[B^X \, \coloneqq \, \{b_i^V \otimes b_j^W: i\in I^V, j\in I^W\}\]</div>
<p>eine Basis von <span class="math notranslate nohighlight">\(X = V\otimes W\)</span>.</p>
</div>
</div><p>Wir wissen nun aus <a class="reference internal" href="#thm:existenzTensorprodukt">Theorem 3.1</a>, dass immer mindestens ein Tensorprodukt existiert.
Es stellt sich also die Frage inwiefern sich verschiedene Tensorprodukte auf den gleichen Vektorräumen <span class="math notranslate nohighlight">\(V\)</span> und <span class="math notranslate nohighlight">\(W\)</span> unterscheiden.
Hierzu liefert das folgende Lemma eine klare Einsicht.</p>
<div class="proof lemma admonition" id="lem:isomorphismusTensorproduktraum">
<p class="admonition-title"><span class="caption-number">Lemma 3.4 </span> (Isomorphie von Tensorprodukträumen)</p>
<div class="lemma-content section" id="proof-content">
<p>Es seien <span class="math notranslate nohighlight">\(V\)</span> und <span class="math notranslate nohighlight">\(W\)</span> zwei reelle Vektorräume und es seien</p>
<div class="math notranslate nohighlight">
\[\begin{split}\otimes_1 &amp;\colon V \times W \rightarrow V \otimes_1 W,\\
\otimes_2 &amp;\colon V \times W \rightarrow V \otimes_2 W\end{split}\]</div>
<p>zwei Tensorprodukte.
Dann existiert genau ein Isomorphismus</p>
<div class="math notranslate nohighlight">
\[p: V\otimes_1 W \to V\otimes_2 W,\]</div>
<p>so dass gilt <span class="math notranslate nohighlight">\(\otimes_2 = p\circ \otimes_1\)</span>.</p>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. Seien also zunächst zwei Tensorprodukte <span class="math notranslate nohighlight">\(\otimes_1, \otimes_2\)</span> auf <span class="math notranslate nohighlight">\(V\times W\)</span> gegeben.
Wegen der <em>universellen Eigenschaft</em> des Tensorprodukts wissen wir, dass es lineare Abbildungen</p>
<div class="math notranslate nohighlight">
\[\begin{split}p_1&amp;: V\otimes_1 W\to Y_1 \ \coloneqq \ V\otimes_2 W,\\
p_2&amp;: V\otimes_2 W\to Y_2 \ \coloneqq \ V\otimes_1 W\end{split}\]</div>
<p>gibt, so dass gilt</p>
<div class="math notranslate nohighlight">
\[\begin{split}\otimes_2 &amp;= p_1 \circ \otimes_1,\\
\otimes_1 &amp;= p_2 \circ \otimes_2.\end{split}\]</div>
<p>Durch Einsetzen der Gleichungen ineinander somit</p>
<div class="math notranslate nohighlight">
\[\begin{split}\otimes_2 &amp;= p_1\circ p_2 \circ \otimes_2,\\
\otimes_1 &amp;= p_2\circ p_1 \circ \otimes_1.\end{split}\]</div>
<p>Aus dem Beweis von <a class="reference internal" href="#thm:existenzTensorprodukt">Theorem 3.1</a> wissen wir, dass wir die Basis von <span class="math notranslate nohighlight">\(V\otimes_2 W\)</span> über die Abbildung <span class="math notranslate nohighlight">\(\otimes_2(b_i^V, b_j^W)\)</span> der Basiselemente von <span class="math notranslate nohighlight">\(V\)</span> und <span class="math notranslate nohighlight">\(W\)</span> charakterisieren können.
Setzen wir also das Tensorprodukt dieser Basiselemente in die erste Gleichung ein, so erhalten wir</p>
<div class="math notranslate nohighlight">
\[\otimes_2(b_i^V, b_j^W) = p_1\circ p_2(\otimes_2(b_i^V,b_j^W)).\]</div>
<p>Das zeigt also, dass <span class="math notranslate nohighlight">\(p_1\circ p_2 = \mathrm{Id}_{Y_1}\)</span> die Identitätsabbildung auf dem Tensorproduktraum <span class="math notranslate nohighlight">\(Y_1 = V \otimes_2 W\)</span> sein muss.
Dies folgt, weil <span class="math notranslate nohighlight">\(p_1\circ p_2\)</span> als lineare Abbildung schon ganz durch seine Wirkung auf den Basiselementen festgelegt ist.
Analog kann man nun folgern, dass <span class="math notranslate nohighlight">\(p_2\circ p_1 = \mathrm{Id}_{Y_2}\)</span> die Identitätsabbildung im Tensorproduktraum <span class="math notranslate nohighlight">\(Y_2 = V \otimes_1 W\)</span> ist und somit sind die Linearformen <span class="math notranslate nohighlight">\(p_1\)</span> und <span class="math notranslate nohighlight">\(p_2\)</span> <strong>Isomorphismen</strong> und gerade die jeweiligen Umkehrfunktionen zueinander.</p>
<p>Insgesamt haben wir also gezeigt, dass Tensorprodukträume, die durch verschiedene Tensorprodukte auf dem gleiche kartesischen Produkraum stets isomorph zueinander sind.</p>
</div>
<p>Im endlich-dimensionalen Fall können wir uns also immer auf den <span class="math notranslate nohighlight">\(\R^{n \cdot m}\)</span> zurückziehen, wie das folgende Korrolar festhält.</p>
<div class="proof corollary admonition" id="cor:isomorphieEndlichDimensional">
<p class="admonition-title"><span class="caption-number">Corollary 3.2 </span></p>
<div class="corollary-content section" id="proof-content">
<p>Betrachten wir ein Tensorprodukt <span class="math notranslate nohighlight">\(\otimes \in L^2(V \times W; V \otimes W)\)</span> zweier <strong>endlich-dimensionaler</strong> <span class="math notranslate nohighlight">\(\R\)</span>-Vektorräume <span class="math notranslate nohighlight">\(V\)</span> und <span class="math notranslate nohighlight">\(W\)</span> mit <span class="math notranslate nohighlight">\(\operatorname{dim}(V)=n \in \N\)</span> und <span class="math notranslate nohighlight">\(\operatorname{dim}(W)=m \in \N\)</span>, so existiert stets die folgende Isormorphie</p>
<div class="math notranslate nohighlight">
\[V \otimes W \cong \R^{n \cdot m}.\]</div>
<p>Das heißt für die Dimension des Tensorproduktraums <span class="math notranslate nohighlight">\(V \otimes W\)</span> gilt offensichtlich</p>
<div class="math notranslate nohighlight">
\[\operatorname{dim}(V \otimes W) = n\cdot m.\]</div>
</div>
</div><p>Das folgende Beispiel soll noch einmal die Isomorphie zwischen verschiedenen Tensorprodukträumen illustrieren.</p>
<div class="proof example admonition" id="example-9">
<p class="admonition-title"><span class="caption-number">Example 3.7 </span> (Dyadisches Produkt vs. Kronecker-Produkt)</p>
<div class="example-content section" id="proof-content">
<p>Im Folgenden betrachten wir wieder den Euklidischen Vektorraum <span class="math notranslate nohighlight">\(V=W=\R^2\)</span> und zwei Vektoren <span class="math notranslate nohighlight">\(x, y \in \R^2\)</span>.
Wie wir in <a class="reference internal" href="#ex:tensorproduktVarianten">Example 3.5</a> und <a class="reference internal" href="#ex:universelleEigenschaft">Example 3.6</a> festgestellt haben realisiert das <strong>dyadische Produkt</strong></p>
<div class="math notranslate nohighlight">
\[\otimes_d \colon \R^2 \times \R^2 \rightarrow \R^2 \otimes_d \R^2 = \R^{2 \times 2} =: X_d\]</div>
<p>mit</p>
<div class="math notranslate nohighlight">
\[\begin{split}x \otimes_d y \, \coloneqq \,
\begin{pmatrix}
x_1y_1 &amp; x_1y_2 \\
x_2y_1 &amp; x_2y_2
\end{pmatrix}.\end{split}\]</div>
<p>ein Tensorprodukt der Vektorräume <span class="math notranslate nohighlight">\(V=W=\R^2\)</span>.</p>
<p>Betrachten wir nun ein weiteres Tensorprodukt auf dem kartesischen Produktraum <span class="math notranslate nohighlight">\(V \times W\)</span>, nämlich das <strong>Kronecker-Produkt</strong> <span class="math notranslate nohighlight">\(\otimes_K\)</span>.
Das Kronecker-Produkt realisiert eine Abbildung</p>
<div class="math notranslate nohighlight">
\[\otimes_K \colon \R^2 \times \R^2 \rightarrow \R^2 \otimes_K \R^2 = \R^{4} =: X_K,\]</div>
<p>mit</p>
<div class="math notranslate nohighlight">
\[\begin{split}x \otimes_K y =
\begin{pmatrix}
x_1 \\ x_2
\end{pmatrix} \otimes_K 
\begin{pmatrix}
y_1 \\ y_2
\end{pmatrix}
\, = \, 
\begin{pmatrix}
x_1 \cdot \begin{pmatrix} y_1 \\ y_2 \end{pmatrix} \\ 
x_2 \cdot \begin{pmatrix} y_1 \\ y_2 \end{pmatrix}
\end{pmatrix}
= 
\begin{pmatrix}
x_1y_1\\
x_1y_2\\
x_2y_1\\
x_2y_2
\end{pmatrix}.\end{split}\]</div>
<p>Es wird nun klar, dass die Räume <span class="math notranslate nohighlight">\(X_d = \R^{2 \times 2}\)</span> und <span class="math notranslate nohighlight">\(X_K = \R^4\)</span> isomorph zueinander sind, d.h., es gilt <span class="math notranslate nohighlight">\(X_d \cong X_K\)</span>.
Außerdem kann man Tensoren in den jeweiligen Tensorprodukträumen durch zeilenweises Ablesen bzw. Eintragen in eine Matrix eindeutig ineinander überführen.</p>
</div>
</div><p><strong>Das Tensorprodukt?</strong></p>
<p>Die Aussage aus <a class="reference internal" href="#lem:isomorphismusTensorproduktraum">Lemma 3.4</a> zeigt also, dass obwohl es verschiedene Arten gibt Tensorprodukte auf dem kartesischen Produktraum <span class="math notranslate nohighlight">\(V \times W\)</span> zu definieren, die resultierenden Tensorprodukträume stets isomorph zueinander sind.
Deshalb spricht man auch von <strong>dem</strong> Tensorprodukt <span class="math notranslate nohighlight">\(\otimes\)</span> und <strong>dem</strong> Tensorproduktraum <span class="math notranslate nohighlight">\(V \otimes W\)</span>, was so klingt als gäbe es jeweils nur ein einziges Exemplar.
In der Tat gibt es zwar mehrere Tensorprodukte aber man kann diese problemlos ineinander umrechnen und die resultierenden Tensorprodukträume alle miteinander identifizieren.</p>
<p>Deshalb werden wir im Folgendem auch häufig von <strong>dem</strong> Tensorprodukt sprechen.</p>
</div>
<div class="section" id="naturliche-homo-und-isomorphismen-des-tensorprodukts">
<h2><span class="section-number">3.2.4. </span>Natürliche Homo- und Isomorphismen des Tensorprodukts<a class="headerlink" href="#naturliche-homo-und-isomorphismen-des-tensorprodukts" title="Permalink to this headline">¶</a></h2>
<p>Von vielen Operationen kennen wir bereits Eigenschaften wie <em>Kommutativität</em> und <em>Assoziativität</em>.
Derartige Eigenschaften gelten nicht direkt für das Tensorprodukt, allerdings erhalten wir Isomorphismen, welche bekannte Rechenregeln nachbilden.
Diese Isomorphismen nennt auch <strong>natürlich</strong> oder <strong>kanonisch</strong>, weil Sie jeweils auf die naheliegendste Art und Weise definiert sind.
Das folgende Lemma fasst die wichtigsten Eigenschaften des Tensorprodukts zusammen</p>
<div class="proof lemma admonition" id="lem:natISO">
<p class="admonition-title"><span class="caption-number">Lemma 3.5 </span> (Natürliche Isomorphismen des Tensorprodukts)</p>
<div class="lemma-content section" id="proof-content">
<p>Es seien <span class="math notranslate nohighlight">\(V_1,V_2,V_3\)</span> und <span class="math notranslate nohighlight">\(V_4\)</span> reelle Vektorräume.
Dann existieren für das Tensorprodukt die folgenden Isomorphismen:</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(V_1\otimes V_2 \cong V_2\otimes V_1, \quad v_1\otimes v_2 \mapsto v_2\otimes v_1\)</span> (<strong>Kommutativität</strong>),</p></li>
<li><p><span class="math notranslate nohighlight">\((V_1\otimes V_2)\otimes V_3 \cong V_1 \otimes (V_2 \otimes V_3),\quad (v_1\otimes v_2)\otimes v_3 \mapsto v_1 \otimes (v_2\otimes v_3)\)</span> (<strong>Assoziativität</strong>),</p></li>
<li><p><span class="math notranslate nohighlight">\(\R \otimes V_1 \cong V_1,\quad a\otimes v_1 \mapsto a\,v_1\)</span> <strong>(Produkt mit Skalaren)</strong>,</p></li>
<li><p>Falls <span class="math notranslate nohighlight">\(p_{12}:V_1\to V_2\)</span> und <span class="math notranslate nohighlight">\(p_{34}:V_3\to V_4\)</span> Isomorphismen sind, so gilt (<strong>Transitivität</strong>)</p></li>
</ol>
<div class="math notranslate nohighlight">
\[V_1\otimes V_3 \cong V_2\otimes V_4,\quad v_1\otimes v_3 \mapsto p_{12}(v_1)\otimes p_{34}(v_3)\]</div>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. Punkt 1.-3. sind in der Hausaufgabe zu zeigen.</p>
<p><strong>Zu Punkt 4.:</strong></p>
<p>Wichtig für die Transitivitätseigenschaft ist es zunächst einzusehen, dass die Definition des Tensorprodukts sinnvoll ist, denn nicht jedes Element <span class="math notranslate nohighlight">\(x\in V_1\otimes V_3\)</span> lässt sich <em>direkt</em> als Tensorprodukt schreiben.
Wir wissen lediglich, dass <em>endlich viele</em> sogenannte <strong>elementare</strong> oder <strong>zerfallende</strong> Produkte <span class="math notranslate nohighlight">\((v_1^i\otimes v_3^i)_{i=1}^n\)</span> und Skalare <span class="math notranslate nohighlight">\(\alpha_i\in\R, i=1,\ldots,n\)</span>, für <span class="math notranslate nohighlight">\(n\in\N\)</span> existieren, so dass sich jeder Vektor <span class="math notranslate nohighlight">\(x \in V_1 \otimes V_3\)</span> schreiben lässt als</p>
<div class="math notranslate nohighlight">
\[x = \sum_{i=1}^n \alpha_i (v_1^i \otimes v_3^i),\]</div>
<p>was direkt aus der Basiskonstruktion in <a class="reference internal" href="#thm:existenzTensorprodukt">Theorem 3.1</a> folgt.</p>
<p>Die angegebene Abbildung</p>
<div class="math notranslate nohighlight">
\[v_1\otimes v_3 \mapsto p_{12}(v_1)\otimes p_{34}(v_3)\]</div>
<p>ist nun <strong>nur</strong> für zerfallende Produkte definiert.
Allerdings lässt sie sich eindeutig zu einer linearen Abbildung <span class="math notranslate nohighlight">\(\Phi(V_1\otimes V_3)\to (V_2\otimes V_4)\)</span> fortsetzen, so dass für beliebige Vektoren <span class="math notranslate nohighlight">\(x \in V_1 \otimes V_3\)</span> gilt</p>
<div class="math notranslate nohighlight">
\[\Phi(x) = \Phi(\sum_{i=1}^n \alpha_i v_1^i \otimes v_3^i) = 
\sum_{i=1}^n \alpha_i \Phi(v_1^i \otimes v_3^i) = 
\sum_{i=1}^n \alpha_i (p_{12}(v_1^i)\otimes p_{34}(v_3^i)).\]</div>
<p>Auf analoge Art und Weise definiert man nun die lineare Abbildung <span class="math notranslate nohighlight">\(\Psi \colon V_2 \otimes V_4 \rightarrow V_1 \otimes V_3\)</span> mit</p>
<div class="math notranslate nohighlight">
\[\Psi(v_2\otimes v_4) := p_{12}^{-1}(v_2)\otimes p_{34}^{-1}(v_4)\]</div>
<p>und erhält sofort, dass <span class="math notranslate nohighlight">\(\Psi\circ\Phi = \mathrm{Id}\)</span> gilt, da für beliebige Vektoren <span class="math notranslate nohighlight">\(x \in V_1 \otimes V_3\)</span> gilt:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\Psi \circ \Phi(x) &amp;= \Psi \circ \Phi(\sum_{i=1}^n \alpha_i v_1^i \otimes v_3^i) = \Psi \circ \sum_{i=1}^n \alpha_i (p_{12}(v_1^i)\otimes p_{34}(v_3^i)) \\
&amp;= \sum_{i=1}^n \alpha_i \Psi(p_{12}(v_1^i)\otimes p_{34}(v_3^i)) = \sum_{i=1}^n \alpha_i (v_1^i \otimes v_3^i) = x.\end{split}\]</div>
<p>Analog gilt auch <span class="math notranslate nohighlight">\(\Phi\circ\Psi = \mathrm{Id}\)</span> und somit haben wir die Behauptung des Lemmas bewiesen.</p>
</div>
<p>Die zweite Eigenschaft in <a class="reference internal" href="#lem:natISO">Lemma 3.5</a> erlaubt es uns das Tensorprodukt über <span class="math notranslate nohighlight">\(k\)</span>-viele reelle Vektorräume <span class="math notranslate nohighlight">\(V_1,\ldots, V_k\)</span> zu bilden.
Daher können wir ab nun folgende Notation verwenden</p>
<div class="math notranslate nohighlight">
\[\bigotimes_{i=1}^k V_i :=V_1\otimes\ldots\otimes V_k\]</div>
<p>und sehen, dass dieses Objekt wohldefiniert ist.
Insbesondere ist äquivalent das Tensorprodukt über <span class="math notranslate nohighlight">\(k\)</span> Vektorräume mit Hilfe einer <span class="math notranslate nohighlight">\(k\)</span>-Multilinearform aus <a class="reference internal" href="multilinear.html#s-k-multilinearform"><span class="std std-ref">k-Multilinearformen</span></a> zu definieren anstatt nur einer Bilinearform wie in <a class="reference internal" href="#def:tensor">Definition 3.4</a>.
Die folgende Bemerkung gibt die universelle Eigenschaft für solch ein Tensorprodukt an.</p>
<div class="proof remark admonition" id="rem:kfachesTensorprodukt">
<p class="admonition-title"><span class="caption-number">Remark 3.7 </span> (<span class="math notranslate nohighlight">\(k\)</span>-faches Tensorprodukt)</p>
<div class="remark-content section" id="proof-content">
<p>Es seien <span class="math notranslate nohighlight">\(V_1,\ldots, V_k\)</span> für <span class="math notranslate nohighlight">\(k \in \N\)</span> reelle Vektorräume.
Dann besitzt das <span class="math notranslate nohighlight">\(k\)</span>-fache Tensorprodukt <span class="math notranslate nohighlight">\(\otimes \colon V_1 \times \ldots \times V_k \rightarrow \bigotimes_{i=1}^k V_i\)</span> die folgende universelle Eigenschaft:</p>
<p>Für jede <span class="math notranslate nohighlight">\(k\)</span>-Multilinearform <span class="math notranslate nohighlight">\(\phi\in L^k(V_1\times\ldots\times V_k; Y)\)</span> in einen beliebigen reellen Vektorraum <span class="math notranslate nohighlight">\(Y\)</span> existiert eine eindeutige lineare Abbildung
<span class="math notranslate nohighlight">\(p \in L^1(\bigotimes_{i=1}^k V_i; Y)\)</span>, so dass gilt</p>
<div class="math notranslate nohighlight">
\[\phi = p \circ \otimes.\]</div>
</div>
</div><p>Im folgenden Abschnitt der Vorlesung wollen wir Tensoren insbesondere als Multilinearformen interpretieren.
Deshalb interessieren wir uns im Folgenden für die Eigenschaften des Tensorprodukts, wenn wir speziell <em>Räume von linearen Abbildungen</em> betrachten.
Die lineare Abbildung im folgenden Lemma stellt hierbei die zentrale Idee dar.</p>
<div class="proof lemma admonition" id="lem:LISO">
<p class="admonition-title"><span class="caption-number">Lemma 3.6 </span></p>
<div class="lemma-content section" id="proof-content">
<p>Es seien <span class="math notranslate nohighlight">\(V_1, V_2\)</span> sowie <span class="math notranslate nohighlight">\(W_1, W_2\)</span> reelle Vektorräume.
Dann ist die Abbildung</p>
<div class="math notranslate nohighlight">
\[\begin{split}p:L(V_1; V_2)\otimes L(W_1; W_2) &amp;\rightarrow L(V_1\otimes W_1; V_2\otimes W_2)\\
(p(\eta_1\otimes\eta_2))(v_1\otimes w_1)&amp;:= \eta_1(v_1) \otimes \eta_2(w_1).\end{split}\]</div>
<p>ein <strong>Homomorphismus</strong>.</p>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. In der Hausaufgabe zu zeigen.</p>
</div>
<p>Da die Notation in <a class="reference internal" href="#lem:LISO">Lemma 3.6</a> vielleicht etwas abstrakt wirkt, soll die folgende Bemerkung auf die einzelnen Elemente der linearen Abbildung <span class="math notranslate nohighlight">\(p\)</span> nochmal genauer eingehen.</p>
<div class="proof remark admonition" id="remark-13">
<p class="admonition-title"><span class="caption-number">Remark 3.8 </span> (Funktionen als Funktionswerte)</p>
<div class="remark-content section" id="proof-content">
<p>Die lineare Abbildung in <a class="reference internal" href="#lem:LISO">Lemma 3.6</a> ist folgendermaßen zu verstehen:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\eta_1:V_1\rightarrow V_2\)</span> und <span class="math notranslate nohighlight">\(\eta_2: W_1 \rightarrow W_2\)</span> sind lineare Abbildungen mit <span class="math notranslate nohighlight">\(\eta_1 \in L(V_1; V_2)\)</span> und <span class="math notranslate nohighlight">\(\eta_2 \in L(W_1; W_2)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\eta_1 \otimes \eta_2\)</span> ist dementsprechend ein Element aus dem Tensorproduktraum <span class="math notranslate nohighlight">\(L(V_1; V_2)\otimes L(W_1; W_2)\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(p(\eta_1\otimes\eta_2)\)</span> ist dann ein Element von <span class="math notranslate nohighlight">\(L(V_1\otimes W_1; V_2\otimes W_2)\)</span>, also eine lineare Abbildung, welche vom Tensorproduktraum <span class="math notranslate nohighlight">\(V_1\otimes W_1\)</span> in den Tensorproduktraum <span class="math notranslate nohighlight">\(V_2\otimes W_2\)</span> abbildet,</p></li>
<li><p><span class="math notranslate nohighlight">\((p(\eta_1\otimes\eta_2))(v_1\otimes w_1)\)</span> ist schließlich die Auswertung dieser Abbildung am Punkt <span class="math notranslate nohighlight">\(v_1\otimes w_1\in V_1\otimes W_1\)</span>.</p></li>
</ul>
<p>In diesem Fall notiert man auch</p>
<div class="math notranslate nohighlight">
\[\eta_1\otimes\eta_2 \mapsto 
\big[
v_1\otimes w_1\mapsto \eta_1(v_1) \otimes \eta_2(w_1)
\big],\]</div>
<p>was bedeutet, dass <span class="math notranslate nohighlight">\(\eta_1\otimes\eta_2\)</span> auf eine <em>Funktion</em> abgebildet wird, welche wiederum <span class="math notranslate nohighlight">\(v_1\otimes w_1\)</span> als Argumente bekommt.</p>
</div>
</div><p>Insbesondere können wir im <strong>endlich-dimensionalen Fall</strong> zeigen, dass die Abbildung <span class="math notranslate nohighlight">\(p\)</span> in <a class="reference internal" href="#lem:LISO">Lemma 3.6</a> einen Isomorphismus definiert.
Hierzu formulieren wir zunächst das folgende nützliche Hilfslemma.</p>
<div class="proof lemma admonition" id="lem:isomorphieKartesischesProdukt">
<p class="admonition-title"><span class="caption-number">Lemma 3.7 </span></p>
<div class="lemma-content section" id="proof-content">
<p>Seien <span class="math notranslate nohighlight">\(V\)</span> und <span class="math notranslate nohighlight">\(W\)</span> zwei beliebige reelle Vektorräume und <span class="math notranslate nohighlight">\(n,m \in \N\)</span>.
Dann existiert ein Isomorphismus, so dass</p>
<div class="math notranslate nohighlight">
\[(V \otimes W)^{n\cdot m} \cong V^n \otimes W^m.\]</div>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. In der Hausaufgabe zu zeigen.</p>
</div>
<div class="proof theorem admonition" id="thm:pIsomorphismus">
<p class="admonition-title"><span class="caption-number">Theorem 3.2 </span></p>
<div class="theorem-content section" id="proof-content">
<p>Es seien <span class="math notranslate nohighlight">\(V_1, W_1\)</span> reelle <em>endlich-dimensionale</em> Vektorräume und <span class="math notranslate nohighlight">\(V_2, W_2\)</span> <em>beliebige</em> reelle Vektorräume.
Dann ist die Abbildung</p>
<div class="math notranslate nohighlight">
\[\begin{split}p:L(V_1; V_2)\otimes L(W_1; W_2) &amp;\rightarrow L(V_1\otimes W_1; V_2\otimes W_2)\\
(p(\eta_1\otimes\eta_2))(v_1\otimes w_1)&amp;:= \eta_1(v_1) \otimes \eta_2(w_1).\end{split}\]</div>
<p>ein Isomorphismus.</p>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. Seien <span class="math notranslate nohighlight">\(V_1\)</span> und <span class="math notranslate nohighlight">\(W_1\)</span> zwei endlich-dimensionale, reelle Vektorräume mit <span class="math notranslate nohighlight">\(\operatorname{dim}(V_1) = n \in \N\)</span> und <span class="math notranslate nohighlight">\(\operatorname{dim}(W_1) = m \in \N\)</span>.
Nach dem <em>Isomorphiesatz für endlich-dimensionale Vektorräume</em> 3.20 in <span id="id1">[<a class="reference internal" href="../references.html#id2">Bur20</a>]</span> existiert dann je ein Isomorphismus, so dass <span class="math notranslate nohighlight">\(V_1 \cong \R^n\)</span> und <span class="math notranslate nohighlight">\(W_1 \cong \R^m\)</span>.
Über diesen Isomorphismus lässt sich auch zeigen, dass <span class="math notranslate nohighlight">\(L(V_1; V_2) \cong L(\R^n; V_2)\)</span> und <span class="math notranslate nohighlight">\(L(W_1; W_2) \cong L(\R^m; W_2)\)</span> gilt.
Zusammen mit der <em>Transitivitätseigenschaft des Tensorprodukts</em> aus <a class="reference internal" href="#lem:natISO">Lemma 3.5</a> folgt dann aber schon</p>
<div class="math notranslate nohighlight">
\[L(V_1; V_2)\otimes L(W_1; W_2) \cong L(\R^n; V_2)\otimes L(\R^m; W_2).\]</div>
<p>Daher reicht es, die Aussage des Theorems für den einfachen Fall <span class="math notranslate nohighlight">\(V_1=\R^n, W_1=\R^m\)</span> im Folgenden in zwei Schritten zu zeigen.</p>
<p><strong>1.Schritt:</strong> Wir zeigen zunächst, dass die Isomorphie <span class="math notranslate nohighlight">\(L(\R^k; Y) \cong Y^k\)</span> gilt.</p>
<p>Es sei <span class="math notranslate nohighlight">\(Y\)</span> ein beliebiger reeller Vektorraum und es bezeichne <span class="math notranslate nohighlight">\((e_i)_{i=1}^k\)</span> die Standardbasis von <span class="math notranslate nohighlight">\(\R^k\)</span>.
Wir konstruieren nun eine Abbildung <span class="math notranslate nohighlight">\(\phi:Y^k\rightarrow L(\R^k; Y)\)</span>, so dass</p>
<div class="math notranslate nohighlight">
\[\phi(y_1,\ldots,y_k) = [e_i \mapsto y_i], \quad i = 1,\ldots,k\]</div>
<p>gilt.
Die Abbildung <span class="math notranslate nohighlight">\(\phi\)</span> ist <strong>linear</strong>, da für alle Vektoren <span class="math notranslate nohighlight">\(y,z \in Y^k\)</span> und einen beliebigen Vektor <span class="math notranslate nohighlight">\(x \in \R^k\)</span> mit der Basisdarstellung <span class="math notranslate nohighlight">\(x=\sum_{i=1}^k \alpha_i e_i\)</span> gilt:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\phi(y+z)(x) &amp;= \phi(y_1+z_1,\ldots, y_k+z_k)(\sum_{i=1}^k \alpha_i e_i) = \sum_{i=1}^k \alpha_i (y_i + z_i) \\
&amp;= \sum_{i=1}^k \alpha_i y_i + \sum_{i=1}^k \alpha_i z_i = \phi(y_1,\ldots, y_k)(\sum_{i=1}^k \alpha_i e_i) + \phi(z_1,\ldots, z_k)(\sum_{i=1}^k \alpha_i e_i) \\
&amp;= \phi(y)(x) + \phi(z)(x)\end{split}\]</div>
<p>und für jedes Skalar <span class="math notranslate nohighlight">\(\lambda \in \R\)</span> gilt:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\phi(\lambda y)(x) &amp;= \phi(\lambda y_1,\ldots, \lambda y_k)(\sum_{i=1}^k \alpha_i e_i)
= \sum_{i=1}^k \alpha_i (\lambda y_i) = \lambda \sum_{i=1}^k \alpha_i y_i \\
&amp;= \lambda \phi( y_1,\ldots, y_k)(\sum_{i=1}^k \alpha_i e_i)
= \lambda \phi(y)(x).\end{split}\]</div>
<p>Offenbar ist diese lineare Abbildung auch <strong>injektiv</strong>, denn</p>
<div class="math notranslate nohighlight">
\[\phi(y_1,\ldots,y_k)(e_i) = 0\quad\forall i\in{1,\ldots k} 
\qquad \Leftrightarrow \qquad
y_i = 0\quad\forall i\in{1,\ldots k}.\]</div>
<p>Gleichzeitig ist die lineare Abbildung jedoch auch <strong>surjektiv</strong>, da jede lineare Abbildung in <span class="math notranslate nohighlight">\(L(\R^k; Y)\)</span> sich bereits durch seine Wirkung auf den Basiselementen <span class="math notranslate nohighlight">\(e_i \in \R^k, i=1,\ldots,k\)</span> eindeutig beschreiben lässt.</p>
<p>Wir sehen also ein, dass es sich bei der Abbildung <span class="math notranslate nohighlight">\(\phi\)</span> um einen Isomorphismus handelt und somit gilt also <span class="math notranslate nohighlight">\(L(\R^k; Y) \cong Y^k\)</span>.</p>
<p><strong>2.Schritt:</strong> Als Nächstes wollen wir die folgenden Isomorphien zeigen:</p>
<div class="math notranslate nohighlight">
\[L(\R^n; V_2) \otimes L(\R^m; W_2) \cong V_2^n \otimes W_2^m\cong L(\R^n\otimes \R^m; V_2\otimes W_2).\]</div>
<p>Mit Schritt 1 des Beweises wissen wir bereits, dass <span class="math notranslate nohighlight">\(L(\R^n; V_2)\cong V_2^n\)</span> und <span class="math notranslate nohighlight">\(L(\R^m; W_2)\cong W_2^m\)</span> gilt.
Zusammen mit der <em>Transitivitätseigenschaft des Tensorprodukts</em> aus <a class="reference internal" href="#lem:natISO">Lemma 3.5</a> folgt damit schon die erste Isomorphie</p>
<div class="math notranslate nohighlight" id="equation-eq-ersteisormorphie">
<span class="eqno">(3.3)<a class="headerlink" href="#equation-eq-ersteisormorphie" title="Permalink to this equation">¶</a></span>\[L(\R^n; V_2) \otimes L(\R^m; W_2) \cong V_2^n \otimes W_2^m.\]</div>
<p>Für die zweite Isomorphie benutzen wir den Zusammenhang <span class="math notranslate nohighlight">\(\R^n\otimes \R^m \cong \R^{n\cdot m}\)</span> aus <a class="reference internal" href="#cor:isomorphieEndlichDimensional">Corollary 3.2</a> und erhalten somit</p>
<div class="math notranslate nohighlight">
\[L(\R^n\otimes \R^m; V_2\otimes W_2) \cong L(\R^{n\cdot m}; V_2\otimes W_2).\]</div>
<p>Nutzen wir wiederum die Isomorphie aus Schritt 1 so erhalten wir</p>
<div class="math notranslate nohighlight">
\[L(\R^{n\cdot m}; V_2\otimes W_2) \cong (V_2 \otimes W_2)^{n\cdot m}.\]</div>
<p>Wegen <a class="reference internal" href="#lem:isomorphieKartesischesProdukt">Lemma 3.7</a> wissen wir dann aber schon, dass gilt</p>
<div class="math notranslate nohighlight">
\[(V_2 \otimes W_2)^{n\cdot m} \cong V_2^n \otimes W_2^m.\]</div>
<p>Zusammen mit der Isomorphie <a class="reference internal" href="#equation-eq-ersteisormorphie">(3.3)</a> haben wir nun insgesamt gezeigt, dass</p>
<div class="math notranslate nohighlight">
\[L(\R^n; V_2) \otimes L(\R^m; W_2) \cong L(\R^n\otimes \R^m; V_2\otimes W_2)\]</div>
<p>gilt, was mit unseren Vorüberlegungen die Aussage des Theorems beweist.</p>
</div>
<p>Wählen wir die Zielräume der linearen Abbildungen als <span class="math notranslate nohighlight">\(V_2 = W_2 = \R\)</span>, so erhalten wir direkt folgendes Korrolar als Anwendung des allgemeinen Resultats in <a class="reference internal" href="#thm:pIsomorphismus">Theorem 3.2</a>.
Dies ermöglicht es uns später Tensoren als Linearformen zu interpretieren.</p>
<div class="proof corollary admonition" id="cor:tensorenLinearformen">
<p class="admonition-title"><span class="caption-number">Corollary 3.3 </span> (Isomorphie des algebraischen Dualraums des Tensorproduktraums)</p>
<div class="corollary-content section" id="proof-content">
<p>Es seien <span class="math notranslate nohighlight">\(V\)</span> und <span class="math notranslate nohighlight">\(W\)</span> beliebige endlich-dimensionale Vektorräume.
Dann existiert ein Isomorphismus zwischen dem Tensorproduktraum der algebraischen Dualräume von <span class="math notranslate nohighlight">\(V\)</span> und <span class="math notranslate nohighlight">\(W\)</span> und dem algebraischen Dualraum des Tensorproduktraums, d.h.,</p>
<div class="math notranslate nohighlight">
\[V^\ast \otimes W^\ast \cong (V\otimes W)^\ast = L^1(V \otimes W; \R).\]</div>
</div>
</div></div>
<div class="section" id="tensoren-als-multilinearformen">
<h2><span class="section-number">3.2.5. </span>Tensoren als Multilinearformen<a class="headerlink" href="#tensoren-als-multilinearformen" title="Permalink to this headline">¶</a></h2>
<p>Das folgende Korollar kombiniert die theoretischen Ergebnisse des letzten Abschnitts und liefert so ein mathematisches Resultat, das für die Anwendung beispielsweise in der Physik von Bedeutung ist.
Wir werden nämlich nun folgern, dass wir Tensoren als Multilinearformen auffassen können.</p>
<div class="proof corollary admonition" id="cor:tensorMultilinearform">
<p class="admonition-title"><span class="caption-number">Corollary 3.4 </span> (Tensoren als Multilinearformen)</p>
<div class="corollary-content section" id="proof-content">
<p>Seien <span class="math notranslate nohighlight">\(V\)</span> und <span class="math notranslate nohighlight">\(W\)</span> zwei reelle endlich-dimensionale Vektorräume und <span class="math notranslate nohighlight">\(\otimes \colon V \times W \rightarrow V \otimes W\)</span> das Tensorprodukt.
Dann existiert ein Isomorphismus zwischen dem Tensorproduktraum und dem Raum der Bilinearformen durch</p>
<div class="math notranslate nohighlight">
\[V \otimes W \cong L^2(V \times W; \R).\]</div>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. Wie wir in <a class="reference internal" href="#cor:tensorenLinearformen">Corollary 3.3</a> gesehen haben, besteht ein Isomorphismus zwischen dem Tensorproduktraum algebraischer Dualräume und dem algebraischen Dualraum des entsprechenden Tensorproduktraums mit</p>
<div class="math notranslate nohighlight">
\[V^\ast \otimes W^\ast \cong (V\otimes W)^\ast = L^1(V \otimes W; \R).\]</div>
<p>Da jeder endlich-dimensionale, reelle Vektorraums <span class="math notranslate nohighlight">\(V\)</span> nach <a class="reference internal" href="multilinear.html#lem:dualeBasis">Lemma 3.3</a> isomorph zu seinem algebraischen Dualraum <span class="math notranslate nohighlight">\(V^\ast\)</span> ist, können wir die <em>Transitivitätseigenschaft des Tensorprodukts</em> aus <a class="reference internal" href="#lem:natISO">Lemma 3.5</a> ausnutzen und erhalten die folgende Isomorphie</p>
<div class="math notranslate nohighlight" id="equation-eq-transitivisomorphismus">
<span class="eqno">(3.4)<a class="headerlink" href="#equation-eq-transitivisomorphismus" title="Permalink to this equation">¶</a></span>\[V \otimes W \cong V^\ast \otimes W^\ast.\]</div>
<p>Gleichzeitig besagt die <em>universelle Eigenschaft des Tensorprodukts</em> in , dass es zu jeder Bilinearform <span class="math notranslate nohighlight">\(\Phi \in L^2(V \times W; \R)\)</span> eine eindeutige Linearform <span class="math notranslate nohighlight">\(p \in L^1(V \otimes W; \R)\)</span> gibt, so dass <span class="math notranslate nohighlight">\(\Phi = p \circ \otimes\)</span> gilt.
Somit erhalten wir also auch einen Isomorphismus</p>
<div class="math notranslate nohighlight">
\[L^1(V \otimes W; \R) \cong L^2(V \times W; \R).\]</div>
<p>Kombinieren wir diese mathematischen Resultate nun alle so ergibt sich die folgende Kette von Isomorphismen:</p>
<div class="math notranslate nohighlight">
\[V \otimes W \cong V^\ast \otimes W^\ast \cong L^1(V \otimes W; \R) \cong L^2(V \times W; \R),\]</div>
<p>was die Aussage beweist.</p>
</div>
<p><a class="reference internal" href="#cor:tensorMultilinearform">Corollary 3.4</a> besagt, dass Tensoren als Elemente des Tensorproduktraums <span class="math notranslate nohighlight">\(V \otimes W\)</span> als Bilinearformen auf dem kartesischen Produktraum <span class="math notranslate nohighlight">\(V \times W\)</span> aufgefasst werden können.
Diese Aussage lässt sich mit Hilfe von <a class="reference internal" href="#rem:kfachesTensorprodukt">Remark 3.7</a> auch auf das <span class="math notranslate nohighlight">\(k\)</span>-fache Tensorprodukt verallgemeinern.
Hier erhält man dann das Resultat, dass sich Tensoren als <span class="math notranslate nohighlight">\(k\)</span>-Multilinearformen interpretieren lassen mit</p>
<div class="math notranslate nohighlight">
\[\V_1\otimes\ldots\otimes\V_k \cong L^k(\V_1\times\ldots\times\V_k;\R) \cong L(\V_1\otimes\ldots \otimes\V_k;\R).\]</div>
<p>In <a class="reference internal" href="#equation-eq-transitivisomorphismus">(3.4)</a> haben wir die Transitivitätseigenschaft des Tensorprodukts ausgenutzt, um <em>beide</em> Vektorräume mit ihren jeweiligen algebraischen Dualräumen zu identifizieren.
Dies muss jedoch nicht sein, denn wir hätten genauso gut <strong>gemischte Tensorprodukte</strong> der Form <span class="math notranslate nohighlight">\(V \otimes W^\ast\)</span> oder <span class="math notranslate nohighlight">\(V^\ast \otimes W\)</span> betrachten können, wenn wir die triviale Identifikation <span class="math notranslate nohighlight">\(V \cong V\)</span> oder <span class="math notranslate nohighlight">\(W \cong W\)</span> nutzen.
Daher wollen wir im Folgenden Tensoren einer allgemeineren Form betrachten, nämlich solche, die für kartesische Produkte der Form <span class="math notranslate nohighlight">\(V^r\times (V^\ast)^s\)</span> mit <span class="math notranslate nohighlight">\(r+s=k\)</span> definiert sind.</p>
<div class="proof definition admonition" id="def:gemischteTensoren">
<p class="admonition-title"><span class="caption-number">Definition 3.5 </span> (Gemischte Tensoren)</p>
<div class="definition-content section" id="proof-content">
<p>Es sei <span class="math notranslate nohighlight">\(V\)</span> ein reeller endlich-dimensionaler Vektorraum und <span class="math notranslate nohighlight">\(V^\ast\)</span> der zugehörige algebraische Dualraum.
Dann nennt man</p>
<div class="math notranslate nohighlight">
\[T^r_s(V) := L^k(V^r\times (V^\ast)^s; \R)\]</div>
<p>für <span class="math notranslate nohighlight">\(k = r+s \in \N\)</span> die Menge der gemischten Tensoren, welche <strong>kovariant</strong> der Stufe <span class="math notranslate nohighlight">\(r\)</span> und <strong>kontravariant</strong> der Stufe <span class="math notranslate nohighlight">\(s\)</span> sind.
In manchen Kontexten spricht man auch nur von <strong>gemischten Tensoren der Stufe <span class="math notranslate nohighlight">\(k=r+s\)</span></strong>.</p>
</div>
</div><p>Die folgende Bemerkung erklärt, woher die Begriffe <em>Kovarianz</em> und <em>Kontravarianz</em> stammen.</p>
<div class="proof remark admonition" id="remark-19">
<p class="admonition-title"><span class="caption-number">Remark 3.9 </span> (Ko- und Kontravarianz)</p>
<div class="remark-content section" id="proof-content">
<p>Die Bezeichnungen “kovariant” und “kontravariant” beziehen sich auf die Koordinatendarstellungen von Tensoren.
Genauer gesagt beschreieb Sie, wie sich solche Koordinatendarstellungen bezüglich eines Basiswechsels im zugrundeliegenden Vektorraum verhalten.</p>
<p>Zusammenfassend kann man festhalten:</p>
<ul class="simple">
<li><p><strong>Kovariant</strong> nennt man ein Transformationsverhalten, bei dem sich die Basisvektoren und die darin dargestellten Größen in gleicher Weise transformieren.</p></li>
<li><p><strong>Kontravariant</strong> nennt man ein Transformationsverhalten, wenn sich die Basisvektoren und die darin dargestellten Größen in unterschiedlicher Weise transformieren.</p></li>
</ul>
</div>
</div><p>Das folgende Beispiel gibt eine Intuition für den Begriff der Kontravarianz an Hand von Vektorkoordinaten unter Basiswechseloperationen.</p>
<div class="proof example admonition" id="example-20">
<p class="admonition-title"><span class="caption-number">Example 3.8 </span></p>
<div class="example-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(V = \R^3\)</span> der Euklidische Vektorraum und sei</p>
<div class="math notranslate nohighlight">
\[\begin{split}B_1 := \lbrace \begin{pmatrix}1\\ 0\\ 0\end{pmatrix}, \begin{pmatrix}0\\ 1\\ 0\end{pmatrix}, \begin{pmatrix}0\\ 0\\ 1\end{pmatrix} \rbrace\end{split}\]</div>
<p>die Standard-Einheitsbasis des <span class="math notranslate nohighlight">\(\R^3\)</span>.
Sei nun <span class="math notranslate nohighlight">\(x \in \R^3\)</span> ein Vektor, dessen Koordinaten bezüglich der Basis <span class="math notranslate nohighlight">\(B_1\)</span> gegeben sind als</p>
<div class="math notranslate nohighlight">
\[\begin{split}x = \begin{pmatrix}4\\ 8\\ 2\end{pmatrix}.\end{split}\]</div>
<p>Führen wir nun einen Basiswechsel von <span class="math notranslate nohighlight">\(B_1\)</span> zu einer neuen Basis <span class="math notranslate nohighlight">\(B_2\)</span> mit</p>
<div class="math notranslate nohighlight">
\[\begin{split}B_2 := \lbrace \begin{pmatrix}2\\ 0\\ 0\end{pmatrix}, \begin{pmatrix}0\\ 2\\ 0\end{pmatrix}, \begin{pmatrix}0\\ 0\\ 2\end{pmatrix} \rbrace\end{split}\]</div>
<p>durch, so ändert sich die Koordinatendarstellung von <span class="math notranslate nohighlight">\(x\)</span> bezüglich dieser Transformation zu</p>
<div class="math notranslate nohighlight">
\[\begin{split}x = \begin{pmatrix}2\\ 4\\ 1\end{pmatrix}.\end{split}\]</div>
<p>Wir sehen also, dass durch die Skalierung der Basisvektoren von <span class="math notranslate nohighlight">\(B_1\)</span> um den Faktor <span class="math notranslate nohighlight">\(2\)</span> sich die entsprechende Koordinatendarstellung halbiert, d.h., sich gerade <strong>gegensätzlich</strong> zur Basistransformation verhält.
Daher sind Vektoren <strong>kontravariant</strong> bezüglich Basiswechseltransformationen.</p>
</div>
</div><p>Wir wollen diese allgemeine Definition von gemischten Tensoren nun mit einfachen Beispielen veranschaulichen.
Beginnen wir zunächst mit dem Spezialfall von rein kovarianten Tensoren.</p>
<div class="proof example admonition" id="example-21">
<p class="admonition-title"><span class="caption-number">Example 3.9 </span> (Rein kovariante Tensoren)</p>
<div class="example-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(V\)</span> ein endlich-dimensionaler, reeller Vektorraum mit <span class="math notranslate nohighlight">\(\operatorname{dim}(V) = n \in \N\)</span>.
Wir wollen im Folgenden Tensoren unterschiedlicher Stufen betrachten, die Multilinearformen repräsentieren.
Diese haben keine <em>kontravarianten Komponenten</em>, sind also sozusagen <em>rein kovariant</em>.</p>
<p><strong>Stufe 0:</strong>
Wir betrachten Tensoren der Stufe <span class="math notranslate nohighlight">\(r+s=0+0=0\)</span>.
Elemente der Menge <span class="math notranslate nohighlight">\(T^0_0(V) = L^0(V^0; \R)\)</span> sind gerade die <strong>Skalare</strong> des zu Grunde liegenden Körpers <span class="math notranslate nohighlight">\(\R\)</span>, da der Vektorraum <span class="math notranslate nohighlight">\(V^0\)</span> nur das Nullelement enthält.</p>
<p><strong>Stufe 1:</strong>
Wir betrachten Tensoren der Stufe <span class="math notranslate nohighlight">\(r+s=1+0=1\)</span>.
In diesem Fall entsprechen Elemente der Menge <span class="math notranslate nohighlight">\(T^1_0(V) = L^1(V; \R)\)</span> gerade den <strong>Linearformen</strong> des Vektorraums <span class="math notranslate nohighlight">\(V\)</span>.
Genauer gesagt handelt es sich um Elemente des <em>algebraischen Dualraums</em> <span class="math notranslate nohighlight">\(V^\ast\)</span>.</p>
<p><strong>Stufe k:</strong>
Wir betrachten Tensoren der Stufe <span class="math notranslate nohighlight">\(r+s=k+0=k\)</span> für <span class="math notranslate nohighlight">\(k\in \N\)</span>.
Diese Tensoren entsprechen gerade den <strong><span class="math notranslate nohighlight">\(\mathbf{k}\)</span>-Multilinearformen</strong>, da <span class="math notranslate nohighlight">\(T^k_0(V) = L^k(V^k; \R) = L^k(V; \R)\)</span>.</p>
<p><strong>Stufe n:</strong>
Wir betrachten Tensoren der Stufe <span class="math notranslate nohighlight">\(r+s=n+0=n\)</span>.
Ein Beispiel für Elemente der Menge <span class="math notranslate nohighlight">\(T^n_0(V) = L^n(V^n; \R)\)</span> ist die <strong>Determinante</strong> einer <span class="math notranslate nohighlight">\(n \times n\)</span>-Matrix.</p>
</div>
</div><p>Betrachten wir als Nächstes den Spezialfall von rein kontravarianten Tensoren.</p>
<div class="proof example admonition" id="example-22">
<p class="admonition-title"><span class="caption-number">Example 3.10 </span> (Rein kontravariante Tensoren)</p>
<div class="example-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(V\)</span> ein endlich-dimensionaler, reeller Vektorraum.
Diese besitzen keine <em>kovarianten Komponenten</em>, sind also sozusagen <em>rein kontravariant</em>.</p>
<p><strong>Stufe 1:</strong>
Wir betrachten Tensoren der Stufe <span class="math notranslate nohighlight">\(r+s=0+1=1\)</span>.
In diesem Fall entsprechen Elemente der Menge <span class="math notranslate nohighlight">\(T^0_1(V) = L^1(V^\ast; \R)\)</span> gerade den <strong>Vektoren</strong> des Vektorraums <span class="math notranslate nohighlight">\(V\)</span>.
Genauer gesagt handelt es sich um Elemente des <em>Bidualraums</em> <span class="math notranslate nohighlight">\(V^{**}\)</span>, der nach <a class="reference internal" href="multilinear.html#rem:doubledual">Remark 3.4</a> isomorph zu <span class="math notranslate nohighlight">\(V\)</span> ist.</p>
<p><strong>Stufe 2:</strong>
Wir betrachten Tensoren der Stufe <span class="math notranslate nohighlight">\(r+s=0+2=2\)</span>.
In diesem Fall entsprechen Elemente der Menge <span class="math notranslate nohighlight">\(T^0_2(V) = L^2(V^\ast \times V^\ast; \R)\)</span> sogenannten <strong>Bivektoren</strong> oder <strong>Dyaden</strong>.
Ein Beispiel hierfür sind Tensoren, die durch <em>dyadische Produkte</em> erzeugt werden.</p>
</div>
</div><p>Abschließend betrachten wir noch ein Beispiel für echt gemischte Tensoren.</p>
<div class="proof example admonition" id="example-23">
<p class="admonition-title"><span class="caption-number">Example 3.11 </span> (Echt gemischte Tensoren)</p>
<div class="example-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(V\)</span> ein endlich-dimensionaler, reeller Vektorraum.
Wir wollen im Folgenden <em>echt gemischte</em> Tensoren diskutieren.
Diese besitzen sowohl kontravariante als auch kovariante Komponenten.</p>
<p>Wir betrachten echt gemischte Tensoren der Stufe <span class="math notranslate nohighlight">\(r+s=1+1=2\)</span>.
Die Menge <span class="math notranslate nohighlight">\(T^1_1(V) = L^2(V^\ast \times V; \R)\)</span> enthält dann alle linearen Abbildung, die einer Linearform und einem Vektor eine reelle Zahl zuweisen.
Ein typisches Beispiel für solch einen ist die sogenannte <strong>duale Paarung</strong></p>
<div class="math notranslate nohighlight">
\[\begin{split}\langle \cdot, \cdot \rangle \colon V^\ast \times V &amp;\rightarrow \R,\\
(L, v) &amp;\mapsto \langle L, v \rangle := L(v).\end{split}\]</div>
<p>Hier wird ein gegebener Vektor <span class="math notranslate nohighlight">\(v \in V\)</span> durch einen gegebenen linearen Operator <span class="math notranslate nohighlight">\(L \in V^\ast\)</span> ausgewertet.
Die duale Paarung stellt eine <em>Verallgemeinerung des Skalarprodukts</em> dar.</p>
</div>
</div></div>
<div class="section" id="symmetrie-und-antisymmetrie-von-tensoren">
<h2><span class="section-number">3.2.6. </span>Symmetrie und Antisymmetrie von Tensoren<a class="headerlink" href="#symmetrie-und-antisymmetrie-von-tensoren" title="Permalink to this headline">¶</a></h2>
<p>Oft spielen gerade in der Physik spezielle Familien von Tensoren eine wichtige Rolle, nämlich <em>symmetrische</em> und <em>antisymmetrische Tensoren</em>.
Diese Operatoren zeichnen sich durch ihr Verhalten unter Vertauschung von Argumenten aus und werden besonders in der Quantenmechanik und Kontinuumsmechanik betrachtet.</p>
<p>Bevor wir die Symmetrieeigenschaften von Tensoren definieren können, benötigen wir weitere Hilfsmittel aus der Kombinatorik.
Die Vertauschung von Argumenten entspricht einer Permutationsabbildung und daher wollen wir das <em>Vorzeichen</em> solch einer Permutation betrachten, welches die Symmetrieeigenschaften von Tensoren charakterisiert.</p>
<div class="proof definition admonition" id="def:signumPermutation">
<p class="admonition-title"><span class="caption-number">Definition 3.6 </span> (Signum einer Permutation)</p>
<div class="definition-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(k\in\N\)</span> und <span class="math notranslate nohighlight">\(\pi \colon \lbrace 1,\ldots, k\rbrace \rightarrow \lbrace 1,\ldots, k\rbrace\)</span> eine Permutation der Indizes <span class="math notranslate nohighlight">\(1,\ldots,k\)</span>.
Dann bezeichnen wir mit <span class="math notranslate nohighlight">\(\operatorname{sgn}(\pi) := (-1)^{|\operatorname{inv}(\pi)|}\)</span> das sogenannte <strong>Signum der Permutation</strong> <span class="math notranslate nohighlight">\(\pi\)</span>, für das man die Menge der Fehlstände der Permutation <span class="math notranslate nohighlight">\(\operatorname{inv}(\pi)\)</span> betrachtet mit:</p>
<div class="math notranslate nohighlight">
\[\operatorname{inv}(\pi) := \lbrace i,j \in \lbrace 1, \ldots, k \rbrace : i &lt; j, \pi(i) &gt; \pi(j) \rbrace.\]</div>
</div>
</div><div class="proof remark admonition" id="remark-25">
<p class="admonition-title"><span class="caption-number">Remark 3.10 </span> (Signum durch Transpositionen)</p>
<div class="remark-content section" id="proof-content">
<p>Man erhält eine äquivalente Definition indem man die Darstellung einer Permuattaion durch Transpositionen betrachtet. Eine Permuation vertauscht genau zwei Zahlen, konkret, definiert man für <span class="math notranslate nohighlight">\(r,l\in\{1,\ldots,k\}\)</span> die Permutation <span class="math notranslate nohighlight">\(\tau_{rl}:\{1,\ldots,k\}\to\{1,\ldots,k\}\)</span> wie folgt,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\tau_{rl}(i) = 
\begin{cases}
l&amp;\text{ falls } i=r,\\
r&amp;\text{ falls } i=l,\\
i\text{ sonst}
\end{cases}.\end{split}\]</div>
<p>Jede Permutation lässt sich als Verkettung von Nachbarvertauschung darstellen, also Permutationen von benachbarten Elemneten. Konkret gilt für <span class="math notranslate nohighlight">\(r&lt;l\)</span>,</p>
<div class="math notranslate nohighlight">
\[\tau_{rl} = \underbrace{\left(\tau_{l-1,l}\circ\ldots\circ \tau_{r+1,r+2} \right)}_{\text{Element }r\text{ nach vorne durchreichen}}\circ
\underbrace{\left(\tau_{r,r+1}\circ\ldots\circ \tau_{l-1,l} \right)}_{\text{Elemnet }l\text{ nach hinten durchreichen}}\]</div>
<p>und da jede Nachbarvertauschung einen Fehlstand produziert gilt</p>
<div class="math notranslate nohighlight">
\[|\operatorname{inv}\tau_{rl}| = (l-r) + (l-r-1) = 2(l-r)-1\]</div>
<p>was stets ungerade ist und somit haben wir <span class="math notranslate nohighlight">\(\operatorname{sgn}(\tau_{rl}) = -1\)</span> für belibiebige Transpositionen ungleich der Identität.
Sei <span class="math notranslate nohighlight">\(\pi\)</span> nun eine Permutation und <span class="math notranslate nohighlight">\(M(\pi)\)</span> die Anzahl der Transpostionen mit welcher wir <span class="math notranslate nohighlight">\(\pi\)</span> darstellen können, dann gilt</p>
<div class="math notranslate nohighlight">
\[\operatorname{sgn}(\pi) = -1^{M(\pi)}.\]</div>
</div>
</div><p>Das folgende einfache Beispiel illustriert die Berechnung des Signums einer Permutation.</p>
<div class="proof example admonition" id="example-26">
<p class="admonition-title"><span class="caption-number">Example 3.12 </span> (Signum zweier Permutationen)</p>
<div class="example-content section" id="proof-content">
<p>Wir betrachten im Folgenden zwei verschiedene Permutationen</p>
<div class="math notranslate nohighlight">
\[\pi_i \colon \lbrace 1, 2, 3, 4 \rbrace \rightarrow \lbrace 1, 2, 3, 4 \rbrace \quad i=1,2.\]</div>
<br/>
<p>1. Sei die Permutation <span class="math notranslate nohighlight">\(\pi_1\)</span> gegeben mit</p>
<div class="math notranslate nohighlight">
\[\pi_1(1) = 3, \quad \pi_1(2) = 2, \quad \pi_1(3) = 4, \quad \pi_1(4) = 1.\]</div>
<p>Für die Menge der Fehlstände <span class="math notranslate nohighlight">\(\operatorname{inv}(\pi_1)\)</span> selektieren wir diejenigen Elemente <span class="math notranslate nohighlight">\(i,j \in \lbrace 1,2,3,4 \rbrace\)</span> mit <span class="math notranslate nohighlight">\(i &lt; j\)</span> und <span class="math notranslate nohighlight">\(\pi(i) &gt; \pi(j)\)</span>.
Dies trifft auf folgende Paare von Elementen zu:</p>
<div class="math notranslate nohighlight">
\[\operatorname{inv}(\pi_1) = \lbrace (1,2), (1,4), (2,4), (3,4)\rbrace.\]</div>
<p>Da die Permutation <span class="math notranslate nohighlight">\(\pi_1\)</span> insgesamt <span class="math notranslate nohighlight">\(4\)</span> Fehlstände erzeugt, gilt für das Signum der Permutation:</p>
<div class="math notranslate nohighlight">
\[\operatorname{sgn}(\pi_1) := (-1)^{|\operatorname{inv}(\pi_1)|} = (-1)^4 = +1.\]</div>
<br/>
<p>2. Sei die Permutation <span class="math notranslate nohighlight">\(\pi_2\)</span> gegeben mit</p>
<div class="math notranslate nohighlight">
\[\pi_1(1) = 2, \quad \pi_1(2) = 4, \quad \pi_1(3) = 1, \quad \pi_1(4) = 3.\]</div>
<p>Für die Menge der Fehlstände <span class="math notranslate nohighlight">\(\operatorname{inv}(\pi_2)\)</span> selektieren wir diejenigen Elemente <span class="math notranslate nohighlight">\(i,j \in \lbrace 1,2,3,4 \rbrace\)</span> mit <span class="math notranslate nohighlight">\(i &lt; j\)</span> und <span class="math notranslate nohighlight">\(\pi(i) &gt; \pi(j)\)</span>.
Dies trifft auf folgende Paare von Elementen zu:</p>
<div class="math notranslate nohighlight">
\[\operatorname{inv}(\pi_2) = \lbrace (1,3), (2,3), (2,4)\rbrace.\]</div>
<p>Da die Permutation <span class="math notranslate nohighlight">\(\pi_2\)</span> insgesamt <span class="math notranslate nohighlight">\(3\)</span> Fehlstände erzeugt, gilt für das Signum der Permutation:</p>
<div class="math notranslate nohighlight">
\[\operatorname{sgn}(\pi_2) := (-1)^{|\operatorname{inv}(\pi_2)|} = (-1)^3 = -1.\]</div>
</div>
</div><p>Nun sind wir in der Lage die Symmetrieeigenschaften von Tensoren formal zu definieren.</p>
<div class="proof definition admonition" id="def:symmetrieTensor">
<p class="admonition-title"><span class="caption-number">Definition 3.7 </span> (Symmetrie und Antisymmetrie von Tensoren)</p>
<div class="definition-content section" id="proof-content">
<p>Sei V ein reeller, endlich-dimensionaler Vektorraum und <span class="math notranslate nohighlight">\(T \in T_k^0(V)\)</span> ein rein kontravarianter Tensor von Stufe <span class="math notranslate nohighlight">\(k \in \N\)</span>.</p>
<p>Wir nennen den Tensor <span class="math notranslate nohighlight">\(T\)</span> <strong>symmetrisch</strong>, wenn für alle möglichen Permutationen <span class="math notranslate nohighlight">\(\pi \colon \lbrace 1,\ldots, k\rbrace \rightarrow \lbrace 1,\ldots, k\rbrace\)</span> der Indizes <span class="math notranslate nohighlight">\(1,\ldots,k\)</span> der Wert des Tensors mit permutierten Argumenten sich nicht ändert, d.h.,</p>
<div class="math notranslate nohighlight">
\[T(v_1, \ldots, v_k) = T(v_{\pi(1)}, \ldots, v_{\pi(k)}).\]</div>
<p>Wir nennen den Tensor <span class="math notranslate nohighlight">\(T\)</span> <strong>antisymmetrisch</strong> oder <strong>schiefsymmetrisch</strong>, wenn für alle möglichen Permutationen <span class="math notranslate nohighlight">\(\pi \colon \lbrace 1,\ldots, k\rbrace \rightarrow \lbrace 1,\ldots, k\rbrace\)</span> der Indizes <span class="math notranslate nohighlight">\(1,\ldots,k\)</span> der Wert des Tensors mit permutierten Argumenten sich <em>bis auf das Vorzeichen</em> nicht ändert und dabei folgendem Zusammenhang genügt</p>
<div class="math notranslate nohighlight">
\[T(v_1, \ldots, v_k) = \operatorname{sgn}(\pi) \cdot T(v_{\pi(1)}, \ldots, v_{\pi(k)}).\]</div>
</div>
</div><p>In <a class="reference internal" href="#def:symmetrieTensor">Definition 3.7</a> haben wir die Symmetrieeigenschaften für rein kontravariante Tensoren eingeführt.
Analog lässt sich die (Anti-)Symmetrie eines rein kovarianten Tensors <span class="math notranslate nohighlight">\(T \in T^k_0(V)\)</span> von Stufe <span class="math notranslate nohighlight">\(k\)</span> definieren.
Die Definition von Symmetrie bzw. Antisymmetrie von echt gemischten Tensoren aus <a class="reference internal" href="#def:gemischteTensoren">Definition 3.5</a> ist hingegen wenig sinnvoll, da die Rechenvorschrift eine gemischten Tensors unter beliebigen Permutationen der Argumente nicht mehr wohldefiniert sein muss.</p>
<p>Im folgenden Beispiel diskutieren wir jeweils einen Vertreter für symmetrische und antisymmetrische Tensoren.</p>
<div class="margin sidebar">
<p class="sidebar-title">Tullio Levi-Civita</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Tullio_Levi-Civita">Tullio Levi-Civita</a> (Geboren 29. März 1873 in Padua; Gestorben 29. Dezember 1941 in Rom) war ein italienischer Mathematiker.</p>
</div>
<div class="proof example admonition" id="example-28">
<p class="admonition-title"><span class="caption-number">Example 3.13 </span> (Symmetrieeigenschaften von Tensoren)</p>
<div class="example-content section" id="proof-content">
<p>Betrachten wir zunächst das <em>Standardskalarprodukt</em></p>
<div class="math notranslate nohighlight">
\[\langle \cdot, \cdot \rangle \colon \R^n \times \R^n \rightarrow \R\]</div>
<p>als rein kontravarianten Tensor zweiter Stufe.
Da das Standardskalarprodukt im <span class="math notranslate nohighlight">\(\R^n\)</span> eine positiv definite, symmetrische Bilinearform ist, überträgt sich die Symmetrieeigenschaft auf die Interpretation als Tensor.
Daher ist das Standardskalarprodukt ein <strong>symmetrischer Tensor</strong>.</p>
<br/>
<p>Als zweites Beispiel betrachten wir das sogenannte <em>Levi-Civita-Symbol</em>, auch genannt <em>Epsilon-Tensor</em>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\epsilon_{i_1,\ldots,i_n} :=
\begin{cases}
\operatorname{sgn}((i_1,\ldots,i_n))&amp;\text{ falls }(i_1,\ldots,i_n)\text{ eine Permutation beschreibt,}\\
0&amp;\text{ sonst,}
\end{cases}\end{split}\]</div>
<p>welcher einem Tupel von <span class="math notranslate nohighlight">\(n\in\N\)</span> Indizes <span class="math notranslate nohighlight">\((i_1,\ldots,i_n) \in \N^n\)</span> einen Wert zuordnet, je nachdem ob eine gerade oder eine ungerade Anzahl an Vertauschung benötigt wird, um die Indizes in aufsteigender Reihenfolge zu sortieren.
Wird eine gerade Anzahl an Vertauschungen benötigt, so gilt <span class="math notranslate nohighlight">\(\epsilon_{i_1,\ldots,i_n} = +1\)</span>.
Wird eine ungerade Anzahl an Vertauschungen benötigt, so gilt <span class="math notranslate nohighlight">\(\epsilon_{i_1,\ldots,i_n} = -1\)</span>.
Aus letzterer Vorschrift lässt sich ableiten, dass der Epsilon-Tensor den Wert <span class="math notranslate nohighlight">\(0\)</span> haben muss, wenn mindestens zwei der Indizes gleich sind.
Dies unterscheidet das Levi-Civita-Symbol vom Signum einer Permutation in <a class="reference internal" href="#def:signumPermutation">Definition 3.6</a>, welche als Bijektion auf paarweise verschiedenen Indizes definiert ist.</p>
<p>Aus dieser Vorschrift lässt sich bereits direkt ableiten, dass es sich beim Levi-Civita-Symbol um einen <strong>antisymmetrischen Tensor</strong> n-ter Stufe handelt, da jede paarweise Vertauschung von Indizes das Vorzeichen des Tensors wechselt.</p>
</div>
</div><p>Es stellt sich heraus, dass die Menge der (anti-)symmetrischen Tensoren eine Vektorraumstruktur induzieren, wie das folgende Lemma zeigt.</p>
<div class="proof lemma admonition" id="lemma-29">
<p class="admonition-title"><span class="caption-number">Lemma 3.8 </span> (Vektorraum der (anti-)symmetrischen Tensoren)</p>
<div class="lemma-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(V\)</span> ein endlich-dimensionaler, reeller Vektorraum mit <span class="math notranslate nohighlight">\(\operatorname{dim}(V) = n \in \N\)</span> und sei <span class="math notranslate nohighlight">\(k \in \N\)</span> mit <span class="math notranslate nohighlight">\(k \leq n\)</span>.
Seien außerdem</p>
<div class="math notranslate nohighlight">
\[\Lambda_k(V) = \lbrace \omega \in T_k^0(V) : \omega \text{ ist antisymmetrisch} \rbrace.\]</div>
<p>die Menge der <em>antisymmetrischen Tensoren</em> der Stufe <span class="math notranslate nohighlight">\(k\)</span> auf <span class="math notranslate nohighlight">\(V\)</span> und</p>
<div class="math notranslate nohighlight">
\[\mathcal{S}_k(V) = \lbrace \omega \in T_k^0(V) : \omega \text{ ist symmetrisch} \rbrace.\]</div>
<p>die Menge der <em>symmetrischen Tensoren</em> der Stufe <span class="math notranslate nohighlight">\(k\)</span> auf <span class="math notranslate nohighlight">\(V\)</span>.</p>
<p>Dann bilden <span class="math notranslate nohighlight">\(\Lambda_k(V)\)</span> und <span class="math notranslate nohighlight">\(\mathcal{S}_k(V)\)</span> bezüglich der Addition von Tensoren und der skalaren Multiplikation in <span class="math notranslate nohighlight">\(\R\)</span> einen Vektorraum.</p>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. In der Hausaufgabe zu zeigen.</p>
</div>
<p>Abschließend wollen wir uns in diesem Abschnitt noch einem nützlichen mathematischen Werkzeug widmen, das es erlaubt beliebige Tensoren symmetrisch bzw. antisymmetrisch zu machen.
Hierzu definieren wir die folgenden Projektionsabbildungen.</p>
<div class="proof definition admonition" id="def:fermionischeProjektion">
<p class="admonition-title"><span class="caption-number">Definition 3.8 </span> (Fermionische und bosonische Projektion)</p>
<div class="definition-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(V\)</span> ein beliebiger, reeller Vektorraum und <span class="math notranslate nohighlight">\(k \in \N\)</span>.
Wir definieren zunächst die sogenannte <strong>fermionische Projektion</strong></p>
<div class="math notranslate nohighlight">
\[\begin{split}\Pi_- \colon T_k^0(V) &amp;\rightarrow \Lambda_k(V), \\
T(v_1, \ldots, v_k) &amp;\mapsto (\Pi_- T)(v_1, \ldots, v_k) := \frac{1}{k!} \sum_{\pi \in S_k} \operatorname{sgn}(\pi) \, T(v_{\pi(1)}, \ldots, v_{\pi(k)}).\end{split}\]</div>
<p>Diese Projektionsabbildung weist jedem Tensor <span class="math notranslate nohighlight">\(T\in T_k^0\)</span> der Stufe <span class="math notranslate nohighlight">\(k\)</span> einen antisymmetrischen Tensor <span class="math notranslate nohighlight">\(\Pi_-(T) \in \Lambda_k(V)\)</span> zu.</p>
<p>Analog definieren wir die sogenannte <strong>bosonische Projektion</strong></p>
<div class="math notranslate nohighlight">
\[\begin{split}\Pi_+ \colon T_k^0(V) &amp;\rightarrow \mathcal{S}_k(V), \\
T(v_1, \ldots, v_k) &amp;\mapsto (\Pi_+ T)(v_1, \ldots, v_k) := \frac{1}{k!} \sum_{\pi \in S_k} T(v_{\pi(1)}, \ldots, v_{\pi(k)}).\end{split}\]</div>
<p>Diese Projektionsabbildung weist jedem Tensor <span class="math notranslate nohighlight">\(T\in T_k^0\)</span> der Stufe <span class="math notranslate nohighlight">\(k\)</span> einen symmetrischen Tensor <span class="math notranslate nohighlight">\(\Pi_+(T) \in \mathcal{S}_k(V)\)</span> zu.</p>
</div>
</div><div class="proof remark admonition" id="remark-31">
<p class="admonition-title"><span class="caption-number">Remark 3.11 </span></p>
<div class="remark-content section" id="proof-content">
<p>Die Bezeichnung <strong>fermionisch</strong> und <strong>bosonisch</strong> in <a class="reference internal" href="#def:fermionischeProjektion">Definition 3.8</a> stammen daher, dass symmetrische Tensorprodukte <em>identische Bosonen</em> in der Quantenmechanik beschreiben, wohingegen antisymmetrische Tensorprodukte <em>identischen Fermionen</em> zugeordnet werden. Weitere Informationen findet man beispielsweise unter <a class="reference external" href="https://de.wikipedia.org/wiki/Ununterscheidbare_Teilchen#Ununterscheidbarkeit_in_der_Quantenmechanik">Ununterscheidbarkeit von Teilchen in der Quantenmechanik</a>.</p>
</div>
</div></div>
<div class="section" id="grassmann-algebra">
<h2><span class="section-number">3.2.7. </span>Grassmann-Algebra<a class="headerlink" href="#grassmann-algebra" title="Permalink to this headline">¶</a></h2>
<p>Im letzten Abschnitt haben wir gesehen, dass die Menge der antisymmetrischen Tensoren von Stufe zusammen mit der Addition von Tensoren der gleichen Stufe einen Vektorraum <span class="math notranslate nohighlight">\(\Lambda_k(V)\)</span> bildet.
Im Folgenden werden wir sehen, dass wir sogar noch mehr Struktur in Form einer Algebra erhalten, wenn wir den Vektorraum mit einer verträglichen Multiplikation von Tensoren erweitern.</p>
<p>Zunächst wollen wir das äußere Produkt zweier Tensoren definieren.</p>
<div class="proof definition admonition" id="definition-32">
<p class="admonition-title"><span class="caption-number">Definition 3.9 </span> (Äußeres Produkt von Tensoren)</p>
<div class="definition-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(V\)</span> ein endlich-dimensionaler, reeller Vektorraum und seien <span class="math notranslate nohighlight">\(r,r',s,s' \in \N\)</span>.
Sei außerdem <span class="math notranslate nohighlight">\(T \in T^r_s(V)\)</span> ein Tensor, der kovariant von Stufe <span class="math notranslate nohighlight">\(r\)</span> und kontravariant von Stufe <span class="math notranslate nohighlight">\(s\)</span> ist und sei <span class="math notranslate nohighlight">\(T' \in T^{r'}_{s'}(V)\)</span> ein Tensor, der kovariant von Stufe <span class="math notranslate nohighlight">\(r'\)</span> und kontravariant von Stufe <span class="math notranslate nohighlight">\(s'\)</span> ist.</p>
<p>Dann wird das <strong>äußere Tensorprodukt</strong> von <span class="math notranslate nohighlight">\(T\)</span> und <span class="math notranslate nohighlight">\(T'\)</span> als folgende Abbildung definiert:</p>
<div class="math notranslate nohighlight">
\[\begin{split}(T \otimes T')(v_1,\ldots,v_r,v'_1,\ldots,v'_{r'},&amp;w_1,\ldots,w_s,w'_1,\ldots,w'_{s'}) := \\
&amp;T(v_1,\ldots,v_r,w_1,\ldots,w_s)\cdot T'(v'_1,\ldots,v'_{r'},w'_1,\ldots,w'_{s'}).\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\otimes : T^r_s(V) \times T^{r'}_{s'}(V) \rightarrow T^{r+r'}_{s+s'}(V),\]</div>
</div>
</div><p>Lemma: Antisymmetrischer Tensor (linear abhängig)</p>
<p>Quotientenräume</p>
<p>Vektorräume</p>
<div class="proof definition admonition" id="definition-33">
<p class="admonition-title"><span class="caption-number">Definition 3.10 </span> (Äußeres Produkt)</p>
<div class="definition-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(V\)</span> ein endlich-dimensionaler, reeller Vektorraum mit <span class="math notranslate nohighlight">\(\operatorname{dim}(V) = n\)</span> und seien <span class="math notranslate nohighlight">\(\Lambda_k(V), \Lambda_l(V)\)</span> die Vektorräume der *antisymmeterischen</p>
</div>
</div><div class="proof definition admonition" id="definition-34">
<p class="admonition-title"><span class="caption-number">Definition 3.11 </span> (Grassmann-Algebra)</p>
<div class="definition-content section" id="proof-content">
</div>
</div></div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./vektoranalysis"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="multilinear.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title"><span class="section-number">3.1. </span>Multilinearformen</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="diffformen.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title"><span class="section-number">3.3. </span>Differentialformen</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By J. Laubmann, T. Roith, D. Tenbrinck<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-Z9NNSYF13N"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('config', 'G-Z9NNSYF13N');
                </script>

  </body>
</html>