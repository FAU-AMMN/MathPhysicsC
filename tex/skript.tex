%% Generated by Sphinx.
\def\sphinxdocclass{jupyterBook}
\documentclass[letterpaper,10pt,english]{jupyterBook}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
%% turn off hyperref patch of \index as sphinx.xdy xindy module takes care of
%% suitable \hyperpage mark-up, working around hyperref-xindy incompatibility
\PassOptionsToPackage{hyperindex=false}{hyperref}
%% memoir class requires extra handling
\makeatletter\@ifclassloaded{memoir}
{\ifdefined\memhyperindexfalse\memhyperindexfalse\fi}{}\makeatother

\PassOptionsToPackage{warn}{textcomp}

\catcode`^^^^00a0\active\protected\def^^^^00a0{\leavevmode\nobreak\ }
\usepackage{cmap}
\usepackage{fontspec}
\defaultfontfeatures[\rmfamily,\sffamily,\ttfamily]{}
\usepackage{amsmath,amssymb,amstext}
\usepackage{polyglossia}
\setmainlanguage{english}



\setmainfont{FreeSerif}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Italic,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldItalic
]
\setsansfont{FreeSans}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]
\setmonofont{FreeMono}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]


\usepackage[Bjarne]{fncychap}
\usepackage[,numfigreset=1,mathnumfig]{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}


\usepackage{sphinxmessages}



        % Start of preamble defined in sphinx-jupyterbook-latex %
         \usepackage[Latin,Greek]{ucharclasses}
        \usepackage{unicode-math}
        % fixing title of the toc
        \addto\captionsenglish{\renewcommand{\contentsname}{Contents}}
        \hypersetup{
            pdfencoding=auto,
            psdextra
        }
        % End of preamble defined in sphinx-jupyterbook-latex %
        

\title{Mathematik für Physikstudierende C}
\date{Jan 11, 2022}
\release{}
\author{J.\@{} Laubmann, T.\@{} Roith, D.\@{} Tenbrinck}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{intro::doc}}


\noindent\sphinxincludegraphics{{intro_1_0}.png}

\sphinxAtStartPar
Das vorliegende Skript begleitet die \sphinxstylestrong{Vorlesung Mathematik für Physikstudierende C} und ist im Wintersemester 21/22 an der FAU Erlangen\sphinxhyphen{}Nürnberg entstanden. Es soll den Studierenden zusätzlich zur virtuellen Vorlesung als Nachschlagewerk dienen und ist ausführlicher und genauer gehalten als die Vorlesungsnotizen.

\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{\Large Referenz}
\end{DUlineblock}

\sphinxAtStartPar
Das Skript orientiert sich teilweise an dem Vorlesungsskript “Mathematik für Physikstudierende 3” {[}\hyperlink{cite.references:id7}{Kna20}{]} von Prof.Dr.Andreas Knauf (FAU) aus dem Sommersemester 2020 und den Folien zu “Mathematik für Physiker 3” von Prof.Dr.Hermann Schulz\sphinxhyphen{}Baldes (FAU) {[}\hyperlink{cite.references:id10}{SB18}{]}. Weiterhin wird in der Vorlesung oft auch auf das Buch “Mathematische Physik: Klassiche Mechanik” {[}\hyperlink{cite.references:id8}{Kna17}{]} von Prof.Knauf verwiesen, was wir Ihnen als zusätzliches Nachschlagewerk empfehlen können.


\chapter{Gewöhnliche Differentialgleichungen für dynamische Systeme}
\label{\detokenize{ode/ode:gewohnliche-differentialgleichungen-fur-dynamische-systeme}}\label{\detokenize{ode/ode::doc}}
\sphinxAtStartPar
In diesem ersten Kapitel der Vorlesung wollen wir weiterführende Konzepte zum Thema gewöhnlicher Differentialgleichungen einführen.
Insbesondere wollen wir uns mit gewöhnlichen Differentialgleichungen für dynamische Systeme beschäftigen.
Hierfür wiederholen wir zunächst die wichtigsten Aussagen und Begriffe, die Sie in Kaptiel 8 {[}\hyperlink{cite.references:id12}{Ten21}{]} kennengelernt haben.
Anschließend definieren wir zwei grundlegende mathematische Werkzeuge um dynamische Systeme zu charakterisieren, nämlich Flüsse und Phasenportraits.
Zum Schluss wollen wir diese zur Untersuchung und Lösung von Hamiltonschen Differentialgleichungen nutzen, welche eine insbesondere in der klassischen Mechanik innerhalb der Physik eine wichtige Rolle spielen.


\section{Einführung in dynamische Systeme}
\label{\detokenize{ode/dynamicSystems:einfuhrung-in-dynamische-systeme}}\label{\detokenize{ode/dynamicSystems::doc}}
\sphinxAtStartPar
Dynamische Systeme spielen eine zentrale Rolle bei der Beschreibung zeitabhängiger Prozesse in vielen verschiedenen Anwendungsgebieten, wie zum Beispiel der Biologie oder der Physik.
Durch diese Art von mathematischen Modellen ist es beispielsweise möglich das Ausschwingen eines Pendels zu beschreiben oder den Bestand zweier unterschiedlicher Populationen über die Zeit in einer Räuber\sphinxhyphen{}Beute Beziehung zu untersuchen.

\sphinxAtStartPar
Maßgeblich für dynamische Systeme ist die Beobachtung, dass die beschriebenen Prozesse nicht von der Wahl des Anfangszeitpunktes abhängig sind, sondern lediglich von dem gewählten Anfangszustand.
Wir werden diese Eigenschaft später in Sektion {\hyperref[\detokenize{ode/fluesse:s-fluesse}]{\sphinxcrossref{\DUrole{std,std-ref}{Phasenflüsse und Phasenportraits}}}} noch genauer mathematisch charakterisieren.

\sphinxAtStartPar
Je nach Anwendungsgebiet können dynamische Systeme entweder \sphinxstylestrong{diskret} oder \sphinxstylestrong{kontinuierlich} in der Zeitentwicklung sein.
Wir wollen im Folgenden zwei Beispiele zur Illustration des Unterschieds in der Zeitmodellierung diskutieren.


\subsection{Diskrete dynamische Systeme}
\label{\detokenize{ode/dynamicSystems:diskrete-dynamische-systeme}}
\sphinxAtStartPar
Zur Veranschaulichung von diskreten dynamischen System wollen wir uns im Folgenden mit einem Beispiel aus der Biologie beschäftigen.
\label{ode/dynamicSystems:ex:bacteria}
\begin{sphinxadmonition}{note}{Example 1.1 (Wachstum von Bakterien)}



\sphinxAtStartPar
In diesem Beispiel wollen wir annehmen, dass wir das \sphinxstylestrong{exponentielle Wachstum} von Bakterien durch Zellteilung als diskretes dynamisches System zu festen, äquidistanten Zeitpunkten \(t_0, t_1, \ldots \in I\) in einem offenen Zeitintervall \(I\subset\R^+_0\) untersuchen wollen.
Wir modellieren die (ungefähre) Anzahl der Bakterien zu einem Zeitpunkt \(t \in I\) als Funktion \(F \colon I \rightarrow \R_0^+\).
Da die Zeitpunkte äquidistant gewählt sind können wir eine einheitliche Wachstumsrate \(\alpha \in \R^+\) mit \(\alpha > 1\) annehmen, so dass für alle \(n \in \N\) gilt:
\begin{equation*}
\begin{split}F(t_{n+1}) = \alpha \cdot F(t_n).\end{split}
\end{equation*}
\sphinxAtStartPar
Wir erkennen, dass der Prozess des Bakterienwachstums nicht von der konkreten Wahl des Startzeitpunkts \(t_0 \in I\) abhängt, sondern nur von anfänglichen Anzahl der Bakterien \(F_0 \coloneqq F(t_0)\). \hyperref[\detokenize{ode/dynamicSystems:fig-bacteria}]{Fig.\@ \ref{\detokenize{ode/dynamicSystems:fig-bacteria}}} zeigt, dass eine unterschiedliche Wahl des Anfangszeitpunkt bei gleicher Wahl der Anfangspopulation keinen Effekt auf die zeitliche Dynamik hat.

\sphinxAtStartPar
Dies können wir wie folgt mathematisch verifizieren. Seien \(t_m, t_n \in I\) mit \(n,m \in \N\) zwei unterschiedliche Anfangszeitpunkte für die die gleiche Anfangspopulation \(F_0 \in \N\) von Bakterien angenommen wird, d.h.,
\begin{equation*}
\begin{split}F(t_m) = F_0 = F(t_n).\end{split}
\end{equation*}
\sphinxAtStartPar
Betrachten wir nun für die beiden unterschiedlichen Anfangszeitpunkte das Bakterienwachstum nach \(k \in \N\) äquidistanten Zeitschritten, so ergibt sich:
\begin{equation*}
\begin{split}F(t_{m+k}) = \alpha \cdot F(t_{m+k-1}) = \ldots = \alpha^k \cdot F(t_{m}) = \alpha^k \cdot F_0 = \alpha^k \cdot F(t_n) = F(t_{n+k}).\end{split}
\end{equation*}
\sphinxAtStartPar
Wir erkennen also, dass unabhängig vom gewählten Anfangszeitpunkt die Bakterienpopulation nach \(k \in \N\) Zeitschritten gleich ist.
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{C:/Tim/Uni/Lectures/MathPhysicsC/_build/jupyter_execute/dynamicSystems_3_0}.png}
\caption{Visualisierung für Beispiel {\hyperref[\detokenize{ode/dynamicSystems:ex:bacteria}]{\sphinxcrossref{Example 1.1}}}. Wir erkennen, dass die Dynamik der Koloniegröße nicht von der Startzeit abhängt, sondern nur vom Anfangswert. Zu beachten gilt, es ist ein diskretes System, die angezeichneten kontinuierlichen Linien dienen lediglich zur Veranschaulichung der Dynamik.}\label{\detokenize{ode/dynamicSystems:fig-bacteria}}\end{figure}

\sphinxAtStartPar
Diskrete dynamische Systeme tauchen auch in anderen spannenden Anwendungen auf, wie beispielsweise in der \sphinxhref{https://de.wikipedia.org/wiki/Bifurkation\_(Mathematik)\#Bifurkationsdiagramm}{Chaostheorie} und in der \sphinxhref{https://de.wikipedia.org/wiki/Markow-Kette}{Stochastik}.


\subsection{Kontinuierliche dynamische Systeme}
\label{\detokenize{ode/dynamicSystems:kontinuierliche-dynamische-systeme}}
\sphinxAtStartPar
Im Unterschied zu diskreten dynamischen Systemen wird die Zeit bei kontinuierlichen dynamischen Systemen nicht an abzählbar vielen Punkten modelliert, sondern als Kontinuum.
Im Folgenden beschreiben wir das physikalische Experiment des freien Falls als Spezialfall eines kontinuierlichen dynamischen Systems.
\label{ode/dynamicSystems:ex:freefall}
\begin{sphinxadmonition}{note}{Example 1.2 (Freier Fall)}



\sphinxAtStartPar
In diesem Beispiel betrachten wir ein physikalisches Modell für den freien Fall eines Steins mit Masse \(m \in \R^+\), den wir in einer Hand halten, bis wir ihn zu einem definierten Anfangszeitpunkt \(t_0 \in I\) mit \(I \subset \R^+_0\) fallen lassen.

\sphinxAtStartPar
Die aktuelle Entfernung des Steins zum Boden zu einem Zeitpunkt \(t \in I\), d.h. seine gegenwärtige Höhe, ist gegeben durch eine monoton\sphinxhyphen{}fallende Funktion \(F \colon I \rightarrow \R^+_0\).
Unsere Hand befindet sich zum Anfangszeitpunkt \(t_0\) in einer Höhe von \(F_0 > 0\).
Für jeden beliebigen Zeitpunkt \(t > t_0\) lässt sich die aktuelle Höhe des fallenden Steins mit Hilfe des Newtonschen Gravitationsgesetzes wie folgt angeben:
\begin{equation*}
\begin{split}F(t) = \max(0, F_0 - \frac{1}{2}gt^2),\end{split}
\end{equation*}
\sphinxAtStartPar
wobei \(g \approx 9,81 \frac{m}{s^2}\) die Erdbeschleunigungskonstante bezeichnet.

\sphinxAtStartPar
Aus \hyperref[\detokenize{ode/dynamicSystems:fig-free-fall}]{Fig.\@ \ref{\detokenize{ode/dynamicSystems:fig-free-fall}}} wird klar, dass auch hier die Dynamik des freien Falls nicht von der Wahl des Anfangszeitpunkts \(t_0 \in I\) abhängt.
Anschaulich gesprochen, würde der Stein genauso fallen, wenn wir ihn noch einige Sekunden länger festhalten würden.
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{C:/Tim/Uni/Lectures/MathPhysicsC/_build/jupyter_execute/dynamicSystems_6_0}.png}
\caption{Visualisierung für Beispiel {\hyperref[\detokenize{ode/dynamicSystems:ex:freefall}]{\sphinxcrossref{Example 1.2}}}. Wir erkennen, dass die Dynamik der Fallhöhe nicht von der Startzeit abhängt, sondern nur von der Starthöhe.}\label{\detokenize{ode/dynamicSystems:fig-free-fall}}\end{figure}

\sphinxAtStartPar
Häufig kommen zur Beschreibung von kontinuierlichen dynamischen Systemen sogenannte \sphinxstylestrong{autonome gewöhnliche Differentialgleichungen} zum Einsatz, wie die in Beispiel {\hyperref[\detokenize{ode/dynamicSystems:ex:freefall}]{\sphinxcrossref{Example 1.2}}} implizit genutzten Bewegungsgleichungen.
Wir werden diese Art von Differentialgleichungen in Kapitel {\hyperref[\detokenize{ode/fluesse:s-fluesse}]{\sphinxcrossref{\DUrole{std,std-ref}{Phasenflüsse und Phasenportraits}}}} mathematisch genauer betrachten.


\section{Wiederholung: Gewöhnliche Differentialgleichungen}
\label{\detokenize{ode/repetition:wiederholung-gewohnliche-differentialgleichungen}}\label{\detokenize{ode/repetition::doc}}
\sphinxAtStartPar
In diesem Abschnitt werden wir kurz die wichtigsten Definitionen und Ergebnisse zu gewöhnlichen Differentialgleichungen aus Kapitel 8 in {[}\hyperlink{cite.references:id12}{Ten21}{]} wiederholen und um neue Begriffe erweitern, mit denen wir die Theorie dynamischer Systeme mathematisch untersuchen können.


\subsection{Gewöhnliche Differentialgleichungen}
\label{\detokenize{ode/repetition:gewohnliche-differentialgleichungen}}
\sphinxAtStartPar
Wir erinnern uns zunächst an die Definition eines gewöhnlichen Differentialgleichungssystems \(m\)\sphinxhyphen{}ter Ordnung als Grundlage für unsere weiteren Betrachtungen.
\label{ode/repetition:def:DGL}
\begin{sphinxadmonition}{note}{Definition 1.1 (Gewöhnliches Differentialgleichungssystem)}



\sphinxAtStartPar
Seien \(n,m \in \N\).
Wir betrachten im Folgenden eine offene Teilmenge \(U\subset (\R^n)^{m+1}\) und ein offenes Intervall \(I\subset\R\).
Es sei außerdem \(F:I\times U\rightarrow\R^n\) eine stetige Funktion, dann nennen wir
\begin{equation}\label{equation:ode/repetition:eq:DGL}
\begin{split}F(t,x(t),x'(t),\ldots,x^{(m)}(t)) = 0\end{split}
\end{equation}
\sphinxAtStartPar
ein \sphinxstylestrong{gewöhnliches Differentialgleichungssystem (DGL)} \(m\)\sphinxhyphen{}ter Ordnung von \(n\) Gleichungen.
Gilt \(n=1\), das heißt die Funktion \(F\) ist skalarwertig, so sprechen wir von einer \sphinxstylestrong{gewöhnlichen Differentialgleichung}.

\sphinxAtStartPar
Eine Funktion \(\phi\in C^m(I;\R^n)\) heißt \sphinxstylestrong{Lösung des Differentialgleichungssystems}, falls gilt,
\begin{equation*}
\begin{split}F(t, \phi(t), \phi'(t), \ldots, \phi^{(m)}(t)) = 0 \quad \forall t\in I.\end{split}
\end{equation*}
\sphinxAtStartPar
Wenn wir die DGL nach der höchsten auftauchenden Ableitung auflösen können, so dass sie die folgende Form hat
\begin{equation*}
\begin{split}x^{(m)}(t) = F(t,x(t),x'(t),\ldots,x^{(m-1)}(t)),\end{split}
\end{equation*}
\sphinxAtStartPar
so nennen wir die DGL \sphinxstylestrong{explizit}, ansonsten wird sie \sphinxstylestrong{implizit} genannt.
\end{sphinxadmonition}

\sphinxAtStartPar
Folgende Bemerkung beschreibt eine alternative Notation von gewöhnlichen Differentialgleichungen 1. und 2. Ordnung, die häufig in der Literatur im Kontext dynamischer Systeme auftaucht.
\label{ode/repetition:remark-1}
\begin{sphinxadmonition}{note}{Remark 1.1 (Zeitableitungen bei gewöhnlichen Differentialgleichungen)}



\sphinxAtStartPar
Viele physikalische Phänomene können durch zeitabhängige gewöhnliche Differentialgleichungen 1. und 2. Ordnung beschrieben werden.
In diesen Fällen verwendet man häufig die Variable \(t \in \R^+_0\) als unabhängige Variable anstatt einer Variable \(x \in \R\).
Auch ändert sich häufig die Notation der Zeitableitungen der gesuchten Funktion \(x\), so dass folgende Korrespondenz für die ersten beiden Ableitungen entsteht:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(x'(t) \ \ \hat{=} \ \ \dot{x}(t)\),

\item {} 
\sphinxAtStartPar
\(x''(t) \ \ \hat{=} \ \ \ddot{x}(t)\).

\end{enumerate}

\sphinxAtStartPar
Damit lässt sich das gewöhnliche Differentialgleichungssystem aus \eqref{equation:ode/repetition:eq:DGL} schreiben als
\begin{equation}\label{equation:ode/repetition:eq:DGLtime}
\begin{split}F(t, x(t), \dot{x}(t), \ldots, x{(m)}(t)) = 0 \quad \forall t\in I.\end{split}
\end{equation}\end{sphinxadmonition}


\subsection{Autonome Differentialgleichungen}
\label{\detokenize{ode/repetition:autonome-differentialgleichungen}}
\sphinxAtStartPar
Im Fall von dynamischen Systemen erhält der Definitionsbereich der Funktion \(F\) einer gewöhnlichen Differentialgleichung einen besonderen Namen, wie die folgende Bemerkung erklärt.
\label{ode/repetition:remark-2}
\begin{sphinxadmonition}{note}{Remark 1.2 ((Erweiterter) Phasenraum)}



\sphinxAtStartPar
Wird eine gewöhnliche Differentialgleichung als mathematisches Modell für ein kontinuierliches dynamisches System genutzt, so wird die offene Menge \(U\subset (\R^n)^{m+1}\) auch als \sphinxstylestrong{Phasenraum} bezeichnet.
Der Definitionsbereich \(I\times U\) der stetigen Funktion \(F\) wird auch als \sphinxstylestrong{erweiterter Phasenraum} bezeichnet.

\sphinxAtStartPar
Der Phasenraum beschreibt die Menge aller möglichen Zustände des dynamischen Systems.
Jeder Punkt des Phasenraums wird hierbei eindeutig einem Zustand des Systems zugeordnet.

\sphinxAtStartPar
In Kapitel {\hyperref[\detokenize{ode/fluesse:s-fluesse}]{\sphinxcrossref{\DUrole{std,std-ref}{Phasenflüsse und Phasenportraits}}}} werden wir spezielle Diagramme basierend auf dem Begriff des erweiterten Phasenraum betrachten (auch Phasenportraits genannt), um Lösungen von dynamischen Systemen mathematisch zu charakterisieren.
\end{sphinxadmonition}

\sphinxAtStartPar
Im Fall von \sphinxstylestrong{kontinuierlichen dynamischen Systemen} spielt eine Familie von gewöhnlichen Differentialgleichungen eine wichtige Rolle, die wir im Folgenden definieren wollen.
Diese zeichnen sich dadurch aus, dass die Funktion \(F\) in \eqref{equation:ode/repetition:eq:DGLtime} nicht explizit von der Zeit abhängt.
\label{ode/repetition:definition-3}
\begin{sphinxadmonition}{note}{Definition 1.2 (Autonome DGL)}



\sphinxAtStartPar
Hängt die Funktion \(F\) in {\hyperref[\detokenize{ode/repetition:def:DGL}]{\sphinxcrossref{Definition 1.1}}} nicht explizit von der Zeit ab, d.h., wir haben \(F:U\rightarrow\R^n\) dann heißt die Gleichung
\begin{equation}\label{equation:ode/repetition:eq:autonomeDGL}
\begin{split}F(x(t), x'(t), \ldots, x^{(m)}(t)) = 0 \quad \forall t\in I\end{split}
\end{equation}
\sphinxAtStartPar
\sphinxstylestrong{autonome DGL}.
\end{sphinxadmonition}

\sphinxAtStartPar
Im folgenden Beispiel wollen wir unterschiedliche gewöhnliche Differentialgleichungen darauf prüfen, ob sie autonom sind.
\label{ode/repetition:example-4}
\begin{sphinxadmonition}{note}{Example 1.3 (Autonome Differentialgleichungen)}



\sphinxAtStartPar
Wir betrachten drei verschiedene gewöhnliche Differentialgleichungen und untersuchen diese auf ihre Zeitabhängigkeit.
Der Einfachheit\sphinxhyphen{}halber konzentrieren wir uns hierbei auf gewöhnliche Differentialgleichungen 1. Ordnung.
Sei hierzu  im Folgenden \(I \subset \R\) ein offenes Intervall.

\sphinxAtStartPar
1. Die gewöhnliche Differentialgleichung
\begin{equation*}
\begin{split}2x'(t) = x(t)\cdot t \quad \forall t \in I\end{split}
\end{equation*}
\sphinxAtStartPar
ist \sphinxstylestrong{nicht autonom}, da die rechte Seite der Gleichung durch die Funktion
\begin{equation*}
\begin{split}F(t,x(t)) = x(t) \cdot x\end{split}
\end{equation*}
\sphinxAtStartPar
beschrieben wird und diese Funktion explizit vom Funktionsargument \(t \in I\) abhängt.



\sphinxAtStartPar
2. Die gewöhnliche Differentialgleichung
\begin{equation*}
\begin{split}2t\cdot \dot{x}(t) = x(t)\cdot t \quad \forall t \in I\end{split}
\end{equation*}
\sphinxAtStartPar
ist hingegen \sphinxstylestrong{autonom}, da die Gleichung in folgende explizite Form überführt werden kann
\begin{equation*}
\begin{split}\dot{x}(t) = \frac{1}{2} x(t) \quad \forall t \in I\end{split}
\end{equation*}
\sphinxAtStartPar
und somit die rechte Seite der Gleichung durch die Funktion
\begin{equation*}
\begin{split}F(t,x(t)) = \frac{1}{2}x(t)\end{split}
\end{equation*}
\sphinxAtStartPar
beschrieben wird, welche nicht explizit vom Funktionsargument \(t \in I\) abhängt.



\sphinxAtStartPar
3. Im Fall der gewöhnlichen Differentialgleichung
\begin{equation*}
\begin{split}2x'(t) = x(t)\cdot \sin(g(t)) \quad \forall t \in I\end{split}
\end{equation*}
\sphinxAtStartPar
können wir für beliebige Funktionen \(g \colon I \rightarrow \R\) \sphinxstylestrong{nicht entscheiden}, ob sie autonom ist wenn keine konkrete Form der Funktion \(g\) gegeben ist.
\end{sphinxadmonition}


\subsection{Anfangswertprobleme}
\label{\detokenize{ode/repetition:anfangswertprobleme}}
\sphinxAtStartPar
Um gewöhnliche Differentialgleichungen zu lösen, betrachtet man in der Regel sogenannte Anfangswertprobleme.
Hierbei wählt man einen ausgezeichneten Zeitpunkt \(t_0\in I\) aus dem Zeitintervall \(I\), an welchem man die Lösung explizit durch einen Anfangswert \(x_0\in U\) vorgibt.
Dieses Vorgehen wird in der folgenden Definition nochmal kurz wiederholt.
\label{ode/repetition:def:anfangswertproblem}
\begin{sphinxadmonition}{note}{Definition 1.3}



\sphinxAtStartPar
Sei ein gewöhnliches Differentialgleichungssystem 1. Ordnung wie in {\hyperref[\detokenize{ode/repetition:def:DGL}]{\sphinxcrossref{Definition 1.1}}} gegeben, wobei \(I \times U \subset \R_0^+ \times \R^n\) den erweiterten Phasenraum des Systems bezeichnet.
Sei außerdem \(t_0 \in I\) ein Anfangszeitpunkt und \(x_0 \in U\) der zugehörige Anfangszustand.

\sphinxAtStartPar
Dann nennen wir das Gleichungssystem
\begin{equation}\label{equation:ode/repetition:eq:AWP}
\begin{split}\dot{x}(t) &= F(t, x(t))\quad\forall t\in I, \\
x(t_0) &= x_0\end{split}
\end{equation}
\sphinxAtStartPar
\sphinxstylestrong{Anfangswertproblem} des gewöhnlichen Differentialgleichungssystems.
Sofern nicht explizit angegeben werden wir im Folgenden annehmen, dass ohne Beschränkung der Allgemeinheit \(t_0=0\) gilt.
\end{sphinxadmonition}

\sphinxAtStartPar
Die explizite Wahl des Anfangszeitpunkts und \sphinxhyphen{}zustands erlaubt es erst eine gewöhnliche Differentialgleichung eindeutig zu lösen.
Ohne diese zusätzlichen Informationen könnte man lediglich Funktionenscharen als Lösungsmenge angeben.
Dies wird durch das folgende Beispiel nochmal dargestellt.
\label{ode/repetition:example-6}
\begin{sphinxadmonition}{note}{Example 1.4}



\sphinxAtStartPar
Wir betrachten eine sehr einfache gewöhnliche Differentialgleichung erster Ordnung, die sich explizit in folgender Form schreiben lässt:
\begin{equation*}
\begin{split}x'(t) = x(t) \quad \forall t \in \R.\end{split}
\end{equation*}
\sphinxAtStartPar
Man sieht leicht ein, dass Lösungen dieser Differentialgleichung Funktionen \(x \colon \R \rightarrow \R\) von der Form
\begin{equation*}
\begin{split}x(t) = c\cdot e^t\end{split}
\end{equation*}
\sphinxAtStartPar
für eine beliebige Konstante \(c \in \R\) sein müssen.
Um diese Funktionenschar weiter einzuschränken und eine eindeutige Lösung zu erhalten, müssen wir noch Anfangswertbedindungen hinzunehmen.
Hierzu reicht es eine ausgewiesene Stelle \(t_0 \in \R\) und einen Funktionswert \(x_0 = x(t_0)\) festzulegen.

\sphinxAtStartPar
Wählen wir beispielsweise \(t_0 = 0\) und \(x_0 = x(0) = 2\), so erhalten wir als eindeutige Lösung der gewöhnlichen Differentialgleichung die Funktion
\begin{equation*}
\begin{split}x(t) = 2\cdot e^t.\end{split}
\end{equation*}
\sphinxAtStartPar
Wir sehen also, dass durch das Festlegen eines Anfangswert die unbekannte Konstante \(c \in \R\) als \(c=2\) eindeutig bestimmt wurde.
\end{sphinxadmonition}


\subsection{Existenz und Eindeutigkeit einer Lösung}
\label{\detokenize{ode/repetition:existenz-und-eindeutigkeit-einer-losung}}
\sphinxAtStartPar
Nicht jede gewöhnliche Differentialgleichung ist im Allgemeinen lösbar oder besitzt eindeutige Lösungen, wie das folgende Beispiel belegt.
\label{ode/repetition:example-7}
\begin{sphinxadmonition}{note}{Example 1.5}



\sphinxAtStartPar
Wir wollen im folgenden zwei Beispiele von autonomen, gewöhnlichen Differentialgleichungen erster Ordnung diskutieren, für die entweder die Existenz oder die Eindeutigkeit von Lösungen nicht gegeben ist.

\sphinxAtStartPar
1. Die gewöhnliche Differentialgleichung
\begin{equation*}
\begin{split}e^{x'(t)} \equiv 0 \quad \forall t \in \R\end{split}
\end{equation*}
\sphinxAtStartPar
besitzt keine Lösung, da die Exponentialfunktion strikt positiv ist und es somit keine Funktion \(y \colon \R \rightarrow \R\) gibt, so dass die obige Gleichung erfüllt werden kann.

\sphinxAtStartPar
2. Die gewöhnliche Differentialgleichung
\begin{equation*}
\begin{split}x'(t)(1-x'(t)) \equiv 0 \quad \forall t \in \R\end{split}
\end{equation*}
\sphinxAtStartPar
besitzt auf Grund ihrer Symmetrieeigenschaften zwei unterschiedliche Funktionenscharen als Lösung, nämlich
\begin{equation*}
\begin{split}x_1(t) = c \quad \text{ und } \quad x_2(t) = t + c \quad \forall t \in \R,\end{split}
\end{equation*}
\sphinxAtStartPar
wobei \(c \in \R\) eine beliebige Konstante darstellt.
\end{sphinxadmonition}

\sphinxAtStartPar
Die wichtigste Eigenschaft für die Existenz und Eindeutigkeit von Lösungen gewöhnlicher Differentialgleichungen ist die \sphinxstylestrong{(lokale) Lipschitzstetigkeit} der rechten Seite \(F \colon I \times U \rightarrow U\).
Diese wollen wir der Vollständigkeit halber im Folgenden definieren.

\begin{sphinxShadowBox}
\sphinxstylesidebartitle{Rudolf Lipschitz}

\sphinxAtStartPar
\sphinxhref{https://de.wikipedia.org/wiki/Rudolf\_Lipschitz}{Rudolf Otto Sigismund Lipschitz} (Geboren 14. Mai 1832 in Königsberg i. Pr.; Gestorben 7. Oktober 1903 in Bonn) war ein deutscher Mathematiker und Hochschullehrer. Er betreute die Doktorarbeit von \sphinxhref{https://en.wikipedia.org/wiki/Felix\_Klein}{Felix Klein}, weswegen der österreichische Mathematiker \sphinxhref{https://www.math.fau.de/angewandte-mathematik-1/mitarbeiter/prof-dr-martin-burger/}{Martin Burger} in direkter Linie im akademischen Stammbaum von Lipschitz abstammt, siehe \sphinxhref{https://genealogy.math.ndsu.nodak.edu/index.php}{Mathematics Genealogy Project}.
\end{sphinxShadowBox}
\label{ode/repetition:definition-8}
\begin{sphinxadmonition}{note}{Definition 1.4 ((Lokale) Lipschitzstetigkeit)}



\sphinxAtStartPar
Sei \(F \colon G \to \R^n\) eine Funktion mit dem erweiterten Phasenraum \(G \, \coloneqq \, I \times U \subset \R\times\R^n\).
Man sagt, dass \(F\) in \(G\) einer \sphinxstylestrong{globalen Lipschitz\sphinxhyphen{}Bedingung} genügt (bezüglich der Variablen \(x \in U\)) mit der Lipschitz\sphinxhyphen{}Konstanten \(L\geq0\), wenn gilt
\begin{equation*}
\begin{split}\Vert F(t,x) - F(t,\widetilde{x}) \Vert \leq L \Vert x-\widetilde{x}\Vert\quad\text{ für alle }(t,x), (t,\widetilde{x})\in G\,.\end{split}
\end{equation*}
\sphinxAtStartPar
Man sagt, \(F\) genüge in \(G\) einer \sphinxstylestrong{lokalen Lipschitz\sphinxhyphen{}Bedingung}, falls jeder Punkt \((t,x)\in G\) im erweiterten Phasenraum eine Umgebung \(V\) besitzt, sodass \(F\) in \(G\cap V\) einer Lipschitzbedingung mit einer gewissen (von \(V\) abhängigen) Konstanten \(L\in\R_0^+\) genügt.
\end{sphinxadmonition}

\sphinxAtStartPar
Für die \sphinxstylestrong{(lokale) Existenz von Lösungen} haben wir in Kapitel 8.4 {[}\hyperlink{cite.references:id12}{Ten21}{]} den Satz von Picard\sphinxhyphen{}Lindelöf formuliert, den wir im Folgenden wiederholen werden.
\label{ode/repetition:thm:piclindlokal}
\begin{sphinxadmonition}{note}{Theorem 1.1 (Lokaler Existenzsatz nach Picard–Lindelöf)}



\sphinxAtStartPar
Sei \(F\colon G\to\R^n\) eine stetige Funktion mit erweitertem Phasenraum \(G \coloneqq I \times U \subset \R\times\R^n\), die lokal Lipschitz\sphinxhyphen{}stetig auf \(G\) bezüglich der \(x\)\sphinxhyphen{}Variablen ist.
Dann existiert zu jedem Anfangswert \((t_0,x_0) \in G\) ein \(\varepsilon>0\), sowie genau eine Lösung
\begin{equation*}
\begin{split}\phi \colon \left[t_0-\varepsilon, t_0+\varepsilon\right] \to \R^n\end{split}
\end{equation*}
\sphinxAtStartPar
der gewöhnlichen Differentialgleichung
\begin{equation*}
\begin{split}\dot{x}(t) \ = \ F(t,x(t))\end{split}
\end{equation*}
\sphinxAtStartPar
unter der Anfangsbedingung \(\phi(t_0)=x_0\).
\end{sphinxadmonition}

\begin{sphinxShadowBox}
\sphinxstylesidebartitle{Ernst Lindelöf}

\sphinxAtStartPar
\sphinxhref{https://en.wikipedia.org/wiki/Ernst\_Leonard\_Lindel\%C3\%B6f}{Ernst Leonard Lindelöf} (Geboren 7. März 1870 in Helsingfors (Helsinki), Großfürstentum Finnland; Gestorben 4. Juni 1946 in Helsinki) war ein finnischer Mathematiker.
\end{sphinxShadowBox}

\begin{sphinxShadowBox}
\sphinxstylesidebartitle{Émile Picard}

\sphinxAtStartPar
\sphinxhref{https://de.wikipedia.org/wiki/\%C3\%89mile\_Picard}{Charles Émile Picard} (Geboren 24. Juli 1856 in Paris; Gestorben 11. Dezember 1941 ebenda) war ein französischer Mathematiker.
\end{sphinxShadowBox}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Siehe Kapitel 12, Satz 4 Kapitel 8.4 {[}\hyperlink{cite.references:id4}{For17}{]}
\end{sphinxadmonition}

\sphinxAtStartPar
Bisher haben wir nur die Existenz und Eindeutigkeit von Lösungen gewöhnlicher Differentialgleichungen in lokalen Intervallen betrachtet.
Unter den strengeren Voraussetzungen einer rechten Seite \(F\) der gewöhnlichen Differentialgleichung, die einer globalen Lipschitzbedingung genügt, lässt sich jedoch eine \sphinxstylestrong{globale Existenzaussage} formulieren, die besonders für konkrete Anwendungen sehr praktisch ist.
\label{ode/repetition:satz:picardlindeloef}
\begin{sphinxadmonition}{note}{Theorem 1.2 (Globaler Existenzsatz nach Picard\sphinxhyphen{}Lindelöf)}



\sphinxAtStartPar
Sei \(F\colon G\to\R^n\) eine stetige Funktion mit erweitertem Phasenraum \(G \, \coloneqq \, I \times U \subset \R\times\R^n\), die eine globale Lipschitzbedingung auf \(G\) bezüglich der \(x\)\sphinxhyphen{}Variablen erfüllt.
Dann existiert zu jedem Anfangswert \((t_0,x_0) \in G\) eine globale Lösung
\begin{equation*}
\begin{split}\phi \colon I \to \R^n\end{split}
\end{equation*}
\sphinxAtStartPar
der gewöhnlichen Differentialgleichung
\begin{equation*}
\begin{split}\dot{x}(t) \ = \ F(t,x(t))\end{split}
\end{equation*}
\sphinxAtStartPar
unter der Anfangsbedingung \(\phi(t_0)=x_0\).
Es existieren außerdem keine weiteren (lokalen) Lösungen.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Siehe Kapitel 2.3 {[}\hyperlink{cite.references:id5}{Kna13}{]}
\end{sphinxadmonition}
\label{ode/repetition:cor:eindeutigkeitlinear}
\begin{sphinxadmonition}{note}{Corollary 1.1}



\sphinxAtStartPar
Das Anfangswertproblem jedes \sphinxstylestrong{linearen} gewöhnlichen Differentialgleichungssystems 1. Ordnung hat eine eindeutige globale Lösung.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Siehe Theorem 2.25, Kapitel 2.3 {[}\hyperlink{cite.references:id5}{Kna13}{]}
\end{sphinxadmonition}


\subsection{Lösungen von linearen Differentialgleichungssystemen}
\label{\detokenize{ode/repetition:losungen-von-linearen-differentialgleichungssystemen}}\label{\detokenize{ode/repetition:s-lineare-dglsysteme}}
\sphinxAtStartPar
Analog zu Kapitel 8 in {[}\hyperlink{cite.references:id12}{Ten21}{]} wollen wir uns mit Lösungen für \sphinxstylestrong{homogene lineare Differentialgleichungen} beschäftigen, jedoch dieses Mal nicht im skalaren Fall \(n=1\), sondern für ein Anfangswertproblem von der Form
\begin{equation}\label{equation:ode/repetition:eq:linhomdglsystem}
\begin{split}\dot{x}(t) &= A x(t), \quad \forall t \in I \subset \R^+_0, \\
x(t_0) &= x_0 \in U \subset \R^n.\end{split}
\end{equation}
\sphinxAtStartPar
Wir bemerken hierbei, dass im Gegensatz zum skalaren Fall hier die Koeffizientenmatrix \(A \in \C^{n\times n}\) nicht von der Zeit abhängt, wir also ein autonomes Differentialgleichungssystem betrachten.

\sphinxAtStartPar
Bevor wir Lösungen von \eqref{equation:ode/repetition:eq:linhomdglsystem} angeben, wollen wir ein hilfreiches Funktionalkalkül einführen, dass die Notation im Fall von Differentialgleichungssystemen erleichtert.
\label{ode/repetition:definition-12}
\begin{sphinxadmonition}{note}{Definition 1.5 (Matrixexponential)}



\sphinxAtStartPar
Sei \(n \in \N\) und \(A \in \C^{n \times n}\) eine beliebige quadratische Matrix.
Das \sphinxstylestrong{Matrixexponential} \(e^A\) von \(A\), ist diejenige \(n\times n\)\sphinxhyphen{}Matrix, welche durch die folgende Potenzreihe definiert ist:
\begin{equation*}
\begin{split}e^A \equiv \exp(A) \ \coloneqq \ \sum_{k=0}^\infty \frac{A^k}{k!} = I_n + A + \frac{A^2}{2} + \frac{A^3}{6} + \ldots.\end{split}
\end{equation*}
\sphinxAtStartPar
Analog zur gewöhnlichen Exponentialfunktion konvergiert die Reihe für alle \(A \in \C^{n \times n}\), woraus die Wohldefiniertheit der Definition folgt.
Für den Spezialfall \(n=1\) entspricht das Matrixexponential der gewöhnlichen Exponentialfunktion.
\end{sphinxadmonition}
\label{ode/repetition:rem:matrixexponentialregeln}
\begin{sphinxadmonition}{note}{Remark 1.3 (Rechenregeln für das Matrixexponential)}



\sphinxAtStartPar
Für das Matrixexponential gelten die gleichen Rechenregeln wie für die gewöhnliche Exponentialfunktion, wie zum Beispiel:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(e^{tA}e^{sA} = e^{(t+s)A}, \quad\) für \(s,t \in \R\)

\item {} 
\sphinxAtStartPar
\(\frac{d}{dt} e^{tA} = Ae^{tA}, \quad\) für \(t \in \R\)

\item {} 
\sphinxAtStartPar
\( e^{D} = \operatorname{diag}(e^{a_1}, \ldots, e^{a_n})\) ist Diagonalmatrix für eine Diagonalmatrix \(D = \operatorname{diag}(a_1, \ldots, a_n)\).

\end{itemize}
\end{sphinxadmonition}

\sphinxAtStartPar
Folgendes Lemma stellt einen interessanten Zusammenhang des Matrixexponentials zur Spektraltheorie her.
\label{ode/repetition:lem:mpotew}
\begin{sphinxadmonition}{note}{Lemma 1.1 (Eigenwerte des Matrixexponentials)}



\sphinxAtStartPar
Sei \(A \in \C^{n\times n}\) eine beliebige quadratische Matrix und sei \(\lambda \in \C\) ein Eigenwert von \(A\) zum
Eigenvektor \(v \in \C^n\).
Dann ist der Vektor \(v\) auch Eigenvektor des Matrixexponentials \(e^A\) zum zugehörigen Eigenwert \(e^\lambda\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. In der Hausaufgabe zu zeigen.
\end{sphinxadmonition}

\sphinxAtStartPar
Mit Hilfe des Matrixexponentials lässt sich die Lösung des homogenen linearen Differentialgleichungssystems \eqref{equation:ode/repetition:eq:linhomdglsystem} kompakt angeben, wie uns folgendes Lemma zeigt.
\label{ode/repetition:lemma-15}
\begin{sphinxadmonition}{note}{Lemma 1.2}



\sphinxAtStartPar
Sei \(n\in \N\), \(I \subset \R^+_0\) und \(A \in \C^{n\times n}\) eine beliebige quadratische Matrix.
Das Anfangswertproblem \eqref{equation:ode/repetition:eq:linhomdglsystem} hat die eindeutige Lösung
\begin{equation*}
\begin{split}x(t) = e^{A(t-t_0)}x_0, \quad \forall t \in I.\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Wir zeigen zunächst, dass die Lösung \(x(t)\) die Anfangswertbedingung erfüllt:
\begin{equation*}
\begin{split}x(t_0) = e^{A(t_0-t_0)}x_0 = e^0x_0 = I_n x_0.\end{split}
\end{equation*}
\sphinxAtStartPar
Um zu zeigen, dass \(x(t)\) das lineare homogene Differentialgleichungssystem \eqref{equation:ode/repetition:eq:linhomdglsystem} löst, berechnen wir die entsprechende Zeitableitung als
\begin{equation*}
\begin{split}\dot{x}(t) = \frac{d}{dt}(e^{A(t-t_0)}x_0) = A \cdot e^{A(t-t_0)}x_0 = A x(t), \quad \forall t \in I.\end{split}
\end{equation*}
\sphinxAtStartPar
Vergleichen wir die linke und rechte Seite dieser Gleichung so erkennen wir, dass \(x(t)\) in der Tat eine Lösung des Differentialgleichungssystems ist.

\sphinxAtStartPar
Nach {\hyperref[\detokenize{ode/repetition:cor:eindeutigkeitlinear}]{\sphinxcrossref{Corollary 1.1}}} ist die Lösung eindeutig, da es sich um ein lineares Differentialgleichungssystem 1. Ordnung handelt.
\end{sphinxadmonition}

\sphinxAtStartPar
Im Allgemeinen kann man bei linearen Differentialgleichungssystemen nicht davon ausgehen, dass diese in der einfachsten Form wie in \eqref{equation:ode/repetition:eq:linhomdglsystem} vorliegen.
Außerdem ist die konkrete Berechnung des Matrixexponentials zur Bestimmung einer Lösungsfunktion \(x(t)\) in der Regel ungeeignet.
Hierzu wollen wir die abschließende Bemerkung machen.
\label{ode/repetition:remark-16}
\begin{sphinxadmonition}{note}{Remark 1.4}



\sphinxAtStartPar
1. Zur Berechnung einer konkreten Lösung \(x(t)\) des linearen homogenen Differentialgleichungssystems \eqref{equation:ode/repetition:eq:linhomdglsystem} bietet es sich an, die \sphinxstylestrong{Jordansche Normalform} \(J = SAS^{-1}\) von \(A\) aus Kapitel 2.7 in {[}\hyperlink{cite.references:id12}{Ten21}{]} auszunutzen, da für diese das Matrixexponential wie folgt berechnet werden kann:
\begin{equation*}
\begin{split}e^{tA} &=  \sum_{k=0}^\infty \frac{(t A)^k}{k!} = \sum_{k=0}^\infty \frac{(tS^{-1}JS)^k}{k!} 
\\&= 
S^{-1} \sum_{k=0}^\infty \frac{(tJ)^k}{k!} S = S^{-1} e^{tJ}S 
\\&= S^{-1} e^{t(D+N)}S = S^{-1} e^{tD} e^{tN} S\end{split}
\end{equation*}
\sphinxAtStartPar
für eine Transformationsmatrix \(S \in \C^{n \times n}\), eine Diagonalmatrix \(D \in \C^{n \times n}\) mit den Eigenwerten von \(A\) und einer nilpotenten Matrix \(N \in \C^{n \times n}\), für die die Reihendarstellung des zugehörigen Matrixexponentials nach endlich vielen Summanden (entsprechend dem Nilpotenzindex von \(N\)) abbricht.

\sphinxAtStartPar
2. Ist das vorliegende lineare Differentialgleichungssystem \sphinxstylestrong{inhomogen}, das heißt für eine stetige Störfunktion \(b \colon I \rightarrow \R^n\) von der Form
\begin{equation}\label{equation:ode/repetition:eq:lininhomdglsystem}
\begin{split}\dot{x}(t) &= A x(t) + b(t), \quad \forall t \in I \subset \R^+_0, \\
x(t_0) &= x_0 \in U \subset \R^n,\end{split}
\end{equation}
\sphinxAtStartPar
so lässt sich über die Variation der Konstanten aus Kapitel 8.2 in {[}\hyperlink{cite.references:id12}{Ten21}{]} eine eindeutige Lösung des Anfangswertproblems \eqref{equation:ode/repetition:eq:lininhomdglsystem} angeben als
\begin{equation*}
\begin{split}x(t) = e^{tA}x_0 + \int_0^t e^{(t-s)A}b(s) \, \mathrm{d}s.\end{split}
\end{equation*}
\sphinxAtStartPar
3. Im Falle eines homogenen, linearen Differentialgleichungssystems, das \sphinxstylestrong{nicht autonom} ist, das heißt die Koeffizientenmatrix \(A = A(t)\) ist zeitabhängig, können wir nicht mehr die Spektraltheorie zur konkreten Berechnung von Lösungen nutzen.
Formal lassen sich dennoch Lösungen als sogenanntes \sphinxstylestrong{zeitgeordnetes Produkt} angeben, was jedoch den Rahmen dieser Vorlesung sprengen würde.
\end{sphinxadmonition}


\section{Phasenflüsse und Phasenportraits}
\label{\detokenize{ode/fluesse:phasenflusse-und-phasenportraits}}\label{\detokenize{ode/fluesse:s-fluesse}}\label{\detokenize{ode/fluesse::doc}}
\sphinxAtStartPar
In diesem Abschnitt führen wir die grundlegende mathematischen Konzepte zur Analyse von kontinuierlichen dynamischen Systemen ein. Insbesondere diskutieren wir Flüsse als Lösungen von autonomen gewöhnlichen Differentialgleichungen und definieren sogenannte Phasenportraits, die es uns erlauben dynamische Systeme geometrisch zu interpretieren.


\subsection{Phasenflüsse}
\label{\detokenize{ode/fluesse:phasenflusse}}
\sphinxAtStartPar
Wir beginnen zunächst damit eine Klasse von Funktionen einzuführen, welche die Beschreibung zeitabhängiger Systeme vereinfacht.
Die folgende Definition ist zunächst sehr allgemein für beliebige dynamische Systreme gehalten und wird später im Kontext von konkreten Anwendungsbeispielen spezieller diskutiert.
\label{ode/fluesse:def:Fluss}
\begin{sphinxadmonition}{note}{Definition 1.6 (Fluss und dynamisches System)}



\sphinxAtStartPar
Sei \(U \subset \R^n\) eine offene Teilmenge und \(I=\R^+_0\), dann heißt eine Abbildung \(\Phi:I\times U\rightarrow U\) \sphinxstylestrong{(Phasen\sphinxhyphen{})Fluss}, falls gilt,
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(\Phi(0, x) = x\) für alle \(x\in U\),

\item {} 
\sphinxAtStartPar
\(\Phi(t, \Phi(s,x)) = \Phi(s + t, \Phi(0, x)) = \Phi(s + t, x)\) für alle \(x\in U\) und alle \(s,t\in I\).

\end{enumerate}

\sphinxAtStartPar
Das Tripel \((I, U, \Phi)\) heißt \sphinxstylestrong{dynamisches System}.

\sphinxAtStartPar
Zur Vereinfachung der Notation schreibt man häufig auch das erste Argument des Flusses als Index wie folgt
\begin{equation*}
\begin{split}\Phi_t(x) \coloneqq \Phi(t, x).\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Für die Analyse von dynamischen Systemen beschreibt der Fluss die Bewegung im Phasenraum in Abhängigkeit zur Zeit.
Im Folgenden wollen wir speziell die \sphinxstylestrong{Lösungen einer autonomen DGL}
\begin{equation*}
\begin{split}\dot{x} = F(x).\end{split}
\end{equation*}
\sphinxAtStartPar
für \(F\in C^1(U;\R^n)\) als Fluss interpretieren.
Hierbei soll das zweite Argument des Flusses jeweils den Anfangswert \(x_0\in U\) angeben und \(\Phi(x_0) = \Phi(\cdot, x_0)\) dann eine Lösung der DGL sein, d.h.,
\begin{equation*}
\begin{split}\frac{\d}{\d t} \Phi(x_0) = F(\Phi(x_0))\end{split}
\end{equation*}
\sphinxAtStartPar
So werden durch den Phasenfluss die Lösungen des dynamischen Systems in Abhängigkeit vom Anfangszustand angegeben.
Im folgenden Beispiel betrachten wir den \sphinxstylestrong{Fluss eines Vektorfeldes}, das die rechte Seite eines gewöhnlichen Differentialgleichungssystems beschreibt.
\label{ode/fluesse:example-1}
\begin{sphinxadmonition}{note}{Example 1.6}



\sphinxAtStartPar
Sei \(I\subset \R_0^+\) ein offenes Zeitintervall.
Wir interessieren uns für Lösungen des autonomen gewöhnlichen Differentialgleichungssystems
\begin{equation*}
\begin{split}\dot{\vec{x}}(t) = F(\vec{x}) \quad \forall t\in I,\end{split}
\end{equation*}
\sphinxAtStartPar
dessen rechte Seite durch das Vektorfeld \(F \colon \R^2 \rightarrow \R^2\) mit \(F(x,y) \, \coloneqq \, (y, -x)\) gegeben ist.
Abbildung \textbackslash{}xxx illustriert das Vektorfeld in \(\R^2\).

\sphinxAtStartPar
Wir wollen den Fluss des Vektorfeldes \(F\) angeben, der die Bewegung entlang der Lösungskurven der durch das Vektorfeld gegebenen gewöhnlichen Differentialgleichung beschreibt.
Dieser ist gegeben durch
\begin{equation*}
\begin{split}\Phi(t,(x,y)) = (\cos(t)x + \sin(t)y, -\sin(t)x + \cos(t)y).\end{split}
\end{equation*}
\sphinxAtStartPar
Das die Funktion \(\Phi \colon I \times \R^2 \rightarrow \R^2\) ein Fluss ist, lässt sich leicht verifizieren durch Nachrechnen der beiden Eigenschaften eines Flusses aus Definition \textbackslash{}ref.

\sphinxAtStartPar
1. Es gilt \(\Phi(0, (x,y)) = (x,y)\) für beliebige Paare \((x,y) \in \R^2\), da
\begin{equation*}
\begin{split}\Phi(0, (x,y)) = (1\cdot x + 0\cdot y, - 0 \cdot x + 1 \cdot y) = (x,y).\end{split}
\end{equation*}
\sphinxAtStartPar
2. Es gilt \(\Phi(t, \Phi(s,(x,y)) = \Phi(s + t, (x,y))\) für beliebige Paare \((x,y) \in \R^2\) und Zeitpunkte \(s,t \in I\), da wegen der Additionstheoreme von Sinus und Cosinus gilt
\begin{equation*}
\begin{split}\Phi(t, \Phi(s,(x,y))) &= \Phi(t, (\cos(s)x + \sin(s)y, -\sin(s)x + \cos(s)y)) \\
&= [\cos(t)(\cos(s)x + \sin(s)y) + \sin(t)(-\sin(s)x + \cos(s)y), \\
& \ \ -\sin(t)(\cos(s)x + \sin(s)y) + \cos(t)(-\sin(s)x + \cos(s)y)]\\
&= \ [ (\cos(t)\cos(s) - \sin(t)\sin(s))x + (\cos(t)\sin(s) + \sin(t)\cos(s))y, \\
& \quad (-\sin(t)\cos(s) - \cos(t)\sin(s))x + (\cos(t)\cos(s) - \sin(t)\sin(s))y ] \\
&= (\cos(s+t)x + \sin(s+t)y, -\sin(s+t)x + \cos(s+t)y).\end{split}
\end{equation*}
\sphinxAtStartPar
Nun verfizieren wir noch, dass der Fluss tatsächlich Lösungen des gewöhnlichen Differentialgleichungssystems realisiert.
Es gilt
\begin{equation*}
\begin{split}\dot{\Phi}(t, (x,y)) &= \frac{d}{dt}(\cos(t)x + \sin(t)y, -\sin(t)x + \cos(t)y) 
\\&=
(-\sin(t)x + \cos(t)y, -\cos(t)x - \sin(t)y) 
\\&= 
F(\Phi(t,(x,y)), \quad \forall t \in I, (x,y) \in U.\end{split}
\end{equation*}
\sphinxAtStartPar
Offensichtlich ist der Fluss \(\Phi \colon I \times \R^2 \rightarrow \R^2\) Lösung des gewöhnlichen Differentialgleichungssystems.
\end{sphinxadmonition}


\subsection{Lokale Flüsse}
\label{\detokenize{ode/fluesse:lokale-flusse}}
\sphinxAtStartPar
Nach dem Satz von Picard\sphinxhyphen{}Lindelöf {\hyperref[\detokenize{ode/repetition:thm:piclindlokal}]{\sphinxcrossref{Theorem 1.1}}} wissen wir, dass für jeden Anfangswert \(x_0\in U\) ein \(\epsilon(x_0)>0\) existiert, so dass es lokal eine eindeutige Lösung \(\phi: [-\epsilon(x_0), \epsilon(x_0)]\) gibt, falls die rechte Seite \(F\) lokal Lipschitzstetig bezüglich der \(y\)\sphinxhyphen{}Variablen ist.
In diesem Fall müssen wir das Zeitintervall \(I(x_0)=[-\epsilon(x_0), \epsilon(x_0)]\) wählen und können also nicht wie in {\hyperref[\detokenize{ode/fluesse:def:Fluss}]{\sphinxcrossref{Definition 1.6}}} auf ganz \(I = \R^+_0\) als Zeitintervall arbeiten.
Stattdessen können wir nur Tupel der Form \((t, x_0) \in I(x_0) \times \{x_0\}\) betrachten, wobei \(x_0\in U\) fixiert ist und \(t\) aus dem lokalen Existenzintervall \(I(x_0)\) gewählt werden kann.

\sphinxAtStartPar
Diese Einschränkung führt uns auf den Begriff des \sphinxstylestrong{lokalen Phasenflusses}.
\label{ode/fluesse:def:LokFluss}
\begin{sphinxadmonition}{note}{Definition 1.7 (Lokaler Fluss)}



\sphinxAtStartPar
Sei \(U \subset \R^n\) eine offene Teilmenge und der erweiterte Phasenraum \(G\subset \R^+_0\times U\) sei gegeben als
\begin{equation*}
\begin{split}G = \bigcup_{x_0\in U} I(x_0) \times \{x_0\},\end{split}
\end{equation*}
\sphinxAtStartPar
wobei \(0\in I(x_0)\) für jedes \(x_0\in U\) gelte.

\sphinxAtStartPar
Dann heißt eine Abbildung \(\Phi: G\rightarrow U\) \sphinxstylestrong{lokaler (Phasen\sphinxhyphen{})Fluss}, falls
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(\Phi(0,x) = x\) für alle \(x\in U\),

\item {} 
\sphinxAtStartPar
\(\Phi(t, \Phi(s, x)) = \Phi(s+t, x)\) für alle \(x\in U\) und alle \(s,t\) mit \(s, s+t\in I(x)\) und \(t\in I(\Phi(s,x))\).

\end{enumerate}
\end{sphinxadmonition}

\sphinxAtStartPar
Im nächsten Lemma werden wir sehen, dass die Lösung eines autonomen gewöhnlichen Differentialgleichungssystems tatsächlich als solch ein lokaler Fluss interpretiert werden kann.
In diesem Fall spircht man auch vom \sphinxstylestrong{Fluss einer Differentialgleichung}.
\label{ode/fluesse:lemma-3}
\begin{sphinxadmonition}{note}{Lemma 1.3}



\sphinxAtStartPar
Sei \(U\subset\R^n\) eine offene Teilmenge und es sei \(F \colon U \rightarrow \R^n\) eine lokal Lipschitzstetige Abbildung.
Dann existieren Intervalle \(I(x_0)\), so dass es für den erweiterten Phasenraum
\begin{equation*}
\begin{split}G = \bigcup_{x_0\in U} I(x_0)\times\{x_0\}\end{split}
\end{equation*}
\sphinxAtStartPar
eine Funktion \(\Phi \colon G\rightarrow \R^n\) gibt, mit folgenden Eigenschaften
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(\frac{\d}{\d t} \Phi(t, x_0) = F(\Phi(t, x_0))\) für alle \((t,x_0)\in G\),

\item {} 
\sphinxAtStartPar
\(\Phi\) ist ein lokaler Fluss auf \(G\).

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Da die rechte Seite \(F\) des autonomen gewöhnlichen Differentialgleichungssystems nach Voraussetzung lokal Lipschitzstetig ist, existiert nach dem Satz von Picard\sphinxhyphen{}Lindelöf {\hyperref[\detokenize{ode/repetition:thm:piclindlokal}]{\sphinxcrossref{Theorem 1.1}}} für jedes \(x_0\in U\) ein \(\epsilon(x_0)>0\), so dass eine Lösung des Differentialgleichungssystems \(\Phi_{x_0} \colon [-\epsilon(x_0),\epsilon(x_0)] \rightarrow U\) mit dem Anfangswert \(x_0\) existiert, d.h.,
\begin{equation*}
\begin{split}\dot{\Phi}_{x_0}(t) &= F(\Phi_{x_0}(t)) \quad \forall t \in [-\epsilon(x_0),\epsilon(x_0)],\\
\Phi_{x_0}(0) &= x_0.\end{split}
\end{equation*}
\sphinxAtStartPar
Daher können wir den erweiterten Phasenraum als
\begin{equation*}
\begin{split}G = \bigcup_{x_0\in U} [-\epsilon(x_0),\epsilon(x_0)] \times\{x_0\}\end{split}
\end{equation*}
\sphinxAtStartPar
wählen und die Abbildung \(\Phi\) als Einschränkung auf die Funktionen \(\Phi_{x_0}\) so definieren, dass
\begin{equation*}
\begin{split}\frac{\d}{\d t} \Phi(t, x_0) &= \dot{\Phi}_{x_0}(t) = F(\Phi_{x_0}(t)) = F(\Phi(t, x_0))\\
\Phi(0, x_0) &= \Phi_{x_0}(0) = x_0\end{split}
\end{equation*}
\sphinxAtStartPar
für alle \((t, x_0)\in G\).
Damit haben wir sowohl die erste Aussage des Lemmas als auch die erste Flusseigenschaft aus {\hyperref[\detokenize{ode/fluesse:def:Fluss}]{\sphinxcrossref{Definition 1.6}}} gezeigt.

\sphinxAtStartPar
Die zweite Flusseigenschaft ist eine direkte Folgerung aus der Eindeutigkeit der Lösung des gewöhnlichen Differentialgleichungssystems.
Wir führen den Beweis trotzdem im Folgenden explizit aus.
Es sei \(x_0\in U, s\in [-\epsilon(x_0), \epsilon(x_0)]\) und zusätzlich \(t\) so gewählt, dass \(s+t \in [-\epsilon(x_0), \epsilon(x_0)]\) und \(t\in [-\epsilon(\Phi(s,x_0)), \epsilon(\Phi(s,x_0))]\).
Per Definition löst die Funktion
\begin{equation*}
\begin{split}\phi_1(\tau) \ \coloneqq \ \Phi(s + \tau, x_0)\end{split}
\end{equation*}
\sphinxAtStartPar
sowie auch die Funktion
\begin{equation*}
\begin{split}\phi_2(\tau) \ \coloneqq \ \Phi(\tau, \Phi(s,x_0))\end{split}
\end{equation*}
\sphinxAtStartPar
das gewöhnliche Differentialgleichungssystem auf dem Intervall \([t, \epsilon(x_0)]\), da \(\Phi\) eine Lösung ist.
Weiterhin wissen wir auf Grund der ersten Flusseigenschaft, dass
\begin{equation*}
\begin{split}\phi_1(0) = \Phi(s, x_0) = \Phi(0, \Phi(s, x_0)) = \phi_2(0).\end{split}
\end{equation*}
\sphinxAtStartPar
Somit stimmen also beide Funktionen an einem Punkt überein und sind somit schon auf dem gesamten Intervall \([t, \epsilon(x_0)]\) gleich, was eine direkte Folgerung aus dem Eindeutigkeitssatz 8.20 aus {[}\hyperlink{cite.references:id12}{Ten21}{]} ist.
Wir haben also insgesamt
\begin{equation*}
\begin{split}\Phi(s + \tau, x_0) = \phi_1(\tau) = \phi_2(\tau) = \Phi(\tau, \Phi(s,x_0))\end{split}
\end{equation*}
\sphinxAtStartPar
für jedes \(\tau\in [t, \epsilon(x_0)]\), was die zweite Flusseigenschaft aus {\hyperref[\detokenize{ode/fluesse:def:Fluss}]{\sphinxcrossref{Definition 1.6}}} zeigt.
\end{sphinxadmonition}


\subsection{Phasenporträts}
\label{\detokenize{ode/fluesse:phasenportrats}}
\sphinxAtStartPar
Die teilweise abstrakten Konzepte und Eigenschaften von Phasenflüssen aus den vorangegangenen Abschnitten werden wir im Folgenden mit einfachen geometrischen Anschauungen illustrieren.
Dafür benötigen wir zunächst die folgenden Definitionen.
\label{ode/fluesse:definition-4}
\begin{sphinxadmonition}{note}{Definition 1.8 (Phasenporträt)}



\sphinxAtStartPar
Es sei \(\Phi:G\rightarrow U\) ein Phasenfluss eines gewöhnlichen Differentialgleichungssystems für den erweiterten Phasenraum \(G = I \times U\subset \R^+_0\times \R^n\).
Dann können wir folgende Begriffe für den Fluss einführen:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Für jedes \(x_0\in U\) heißt die Funktion \(t\mapsto \Phi(t, x_0)\) \sphinxstylestrong{Bahnkurve} durch \(x_0\).

\item {} 
\sphinxAtStartPar
Die Menge \(\mathcal{O}(x_0) := \{\Phi(t, x_0): (t, x_0)\in G\}\) heißt \sphinxstylestrong{Orbit} oder \sphinxstylestrong{Trajektorie} durch \(x_0\).

\item {} 
\sphinxAtStartPar
Ein Punkt \(x_0 \in U\) heißt \sphinxstylestrong{Ruhelage}, falls \(\mathcal{O}(x_0) = \{x_0\}\).

\item {} 
\sphinxAtStartPar
Ein Anfangswert \(x_0\in U\) heißt \sphinxstylestrong{periodisch} mit Periode \(T>0\), falls \(\Phi(T, x_0) = x_0\).

\end{itemize}

\sphinxAtStartPar
Wir nennen die Zerlegung des erweiterten Phasenraums \(G\) in Orbits ein \sphinxstylestrong{Phasenporträt} des dynamischen Systems \((I,U, \Phi)\).
\end{sphinxadmonition}

\sphinxAtStartPar
Phasenporträts erlauben es uns das charakteristische Verhalten kontinuierlicher dynamischer Systeme zu visualisieren und graphisch zu analysieren.
An ihnen lassen sich beispielsweise die Existenz und Stabilität von Fixpunkten und periodischen Orbits direkt erkennen.
Da ein Phasenporträt den gesamten Phasenraum zerlegt werden typischerweise nur einige charakteristische Orbits gezeichnet um die Übersichtlichkeit zu gewährleisten.
Aus dem gleichen Grund beschränkt man sich in der Regel außerdem auf ein\sphinxhyphen{} und zweidimensionale Phasenräume.

\sphinxAtStartPar
Ein klassisches Beispiel aus der Mechanik ist besonders gut geeignet, um die eben eingeführten Konzepte näher zu diskutieren \sphinxhyphen{} die gedämpfte Schwingungsgleichung.
\label{ode/fluesse:ex:oscillations}
\begin{sphinxadmonition}{note}{Example 1.7 (Gedämpfte Schwingungsgleichung)}



\sphinxAtStartPar
Die \sphinxstylestrong{gedämpfte Schwingungsgleichung} ist gegeben durch
\begin{equation}\label{equation:ode/fluesse:eq:schwingungsgleichung}
\begin{split}m\ddot{x}(t) + r\dot{x}(t) + kx(t)=0\end{split}
\end{equation}
\sphinxAtStartPar
und beschreibt beispielsweise die horizontale (eindimensionale) Auslenkung eines Federpendels, das durch Reibungsverluste Schwingungsenergie über die Zeit verliert.

\sphinxAtStartPar
Hierbei bezeichnet
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(x(t)\) die horizontale Auslenkung des Federpendels zum Zeitpunkt \(t\),

\item {} 
\sphinxAtStartPar
\(m\) die Masse des Objekts,

\item {} 
\sphinxAtStartPar
\(r\) die Dämpfungskonstante,

\item {} 
\sphinxAtStartPar
\(k\) die Federkonstante.

\end{itemize}

\sphinxAtStartPar
Durch Einführung der Variablen \(p(t):= m\dot{x}(t)\) als Impuls erhalten wir das folgende gewöhnliche Differentialgleichungssystem
\begin{equation*}
\begin{split}\dot{p}(t) &= - \frac{r}{m}p(t) -kx(t), \\
\dot{x}(t) &= \frac{1}{m}p(t).\end{split}
\end{equation*}
\sphinxAtStartPar
Dies lässt sich in kompakter Form schreiben als:
\begin{equation*}
\begin{split}\begin{pmatrix} \dot{p} \\ \dot{x} \end{pmatrix}(t) = \begin{pmatrix} -\frac{r}{m} & -k \\ \frac{1}{m} & 0\end{pmatrix} \begin{pmatrix}p \\ x\end{pmatrix}(t)\end{split}
\end{equation*}
\sphinxAtStartPar
Betrachten wir speziell den ungedämpften Fall für \(r=0\), d.h. ohne Reibungsverluste, so geht die Gleichung in die \sphinxstylestrong{Bewegungsgleichung für einen harmonischen Oszillator} über.
In diesem Fall erhalten wir zum Anfangswert \((p,x) \in U \subset \R^2 \) die Lösung
\begin{equation*}
\begin{split}\Phi(t, (p,x)) = 
\begin{pmatrix}
p \cos(\omega t) - m x \sin(\omega t) \\
\frac{p}{\omega m}\sin(\omega t) + x\cos(\omega t)
\end{pmatrix},\end{split}
\end{equation*}
\sphinxAtStartPar
wobei \(\omega=\sqrt{\frac{k}{m}}\) die Eigenfrequenz des Systems ist.
\end{sphinxadmonition}

\sphinxAtStartPar
Wir wollen im Folgenden die Phasenporträts der gedämpften Schwingungsgleichung und des harmonischen Oszillators illustrieren.

\sphinxAtStartPar
In beiden Abbildungen wird die horizontale Auslenkung \(x(t)\) des Federpendels auf der x\sphinxhyphen{}Achse und der Impuls \(p(t) = m\dot{x}(t)\) auf der y\sphinxhyphen{}Achse aufgetragen.

\sphinxAtStartPar
Das in \hyperref[\detokenize{ode/fluesse:fig-harmonic-oscillator}]{Fig.\@ \ref{\detokenize{ode/fluesse:fig-harmonic-oscillator}}} dargestellte Phasenportrait illustriert anschaulich, dass im Fall des harmonischen Oszillators ohne Dämpfung die Orbits elliptisch sind und somit jeder Startwert \(x_0 \in U\) periodisch ist.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{C:/Tim/Uni/Lectures/MathPhysicsC/_build/jupyter_execute/fluesse_3_0}.png}
\caption{Visualisierung des Phasenporträts und einiger Orbits für den Phasenfluss des harmonischen Oszillators aus {\hyperref[\detokenize{ode/fluesse:ex:oscillations}]{\sphinxcrossref{Example 1.7}}}. Das Phasenporträt zeigt das charakteristische Verhalten von Lösungen der gedämpften Schwingungsgleichung für reibungsfreie Prozesse, d.h., für eine Dämpfungskonstante \(r = 0\).}\label{\detokenize{ode/fluesse:fig-harmonic-oscillator}}\end{figure}

\sphinxAtStartPar
Betrachten wir nun für eine positive Dämpfungskonstante \(r > 0\) den Fall der allgemeinen gedämpften Schwingungsgleichung, so sieht man am dargestellen Phasenportrait in \hyperref[\detokenize{ode/fluesse:fig-damped-oscillator}]{Fig.\@ \ref{\detokenize{ode/fluesse:fig-damped-oscillator}}}, dass die Trajektorien in den Ursprung konvergieren, der als Orbit in Ruhelage einen Fixpunkt des dynamischen Systems darstellt.
Dies macht auch physikalisch Sinn, da jedes Federpendel auf Grund der Reibung nach endlicher Zeit zum Stillstand kommt.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{C:/Tim/Uni/Lectures/MathPhysicsC/_build/jupyter_execute/fluesse_6_0}.png}
\caption{Visualisierung des Phasenporträts und einiger Orbits für den Phasenfluss der gedämpften Schwingungsgleichung aus {\hyperref[\detokenize{ode/fluesse:ex:oscillations}]{\sphinxcrossref{Example 1.7}}} für eine relativ groß gewählte Dämpfungskonstante \(r > 0\).}\label{\detokenize{ode/fluesse:fig-damped-oscillator}}\end{figure}


\section{Hamiltonsche Differentialgleichungen}
\label{\detokenize{ode/hamilton:hamiltonsche-differentialgleichungen}}\label{\detokenize{ode/hamilton::doc}}
\sphinxAtStartPar
Ein wichtiges Prinzip für viele physikalischen Anwendungen und dynamische Systeme sind \sphinxstyleemphasis{Erhaltungssätze} und die dazugehörigen \sphinxstyleemphasis{Erhaltungsgrößen}.
Aus der klassichen Mechanik kennen wir beispielsweise die \sphinxstyleemphasis{Energieerhaltung} oder die \sphinxstyleemphasis{Impulserhaltung}.
In {\hyperref[\detokenize{ode/fluesse:s-fluesse}]{\sphinxcrossref{\DUrole{std,std-ref}{Phasenflüsse und Phasenportraits}}}} haben wir Bewegungsgleichungen als System von gewöhnlichen Differentialgleichungen hergeleitet und gelöst, deshalb wollen wir nun die nötige Theorie entwickeln, die es uns erlaubt Erhaltungsgrößen direkt aus der Formulierung des Differentialgleichungssystems abzulesen.

\sphinxAtStartPar
Hamiltonsche Differentialgleichungen haben in der Physik eine besondere Rolle, insbesondere in der klassischen Mechanik bei Abwesenheit von Reibung.
Typischerweise tauchen diese bei der Untersuchung von Bewegungen im Phasenraum auf, d.h., bei der Betrachtung von Paaren aus Orts\sphinxhyphen{} und Impulswerten.
Ihre Lösungen liefern uns Trajektorien im Phasenraum für die die Gesamtenergie des Systems erhalten bleibt.
Dies macht sie für uns besonders interessant.

\sphinxAtStartPar
Bevor wir die hamiltonschen Differentialgleichungen und ihre Eigenschaften näher diskutieren führen wir zunächst ein wann wir ein Vektorfeld auf dem Phasenraum Hamiltonsch nennen und was eine Hamilton\sphinxhyphen{}Funktion dieses Vektorfelds ist.
\label{ode/hamilton:def:hamiltonsch}
\begin{sphinxadmonition}{note}{Definition 1.9 (Hamilton\sphinxhyphen{}Funktion)}



\sphinxAtStartPar
Sei \(n \in N\) die \sphinxstylestrong{Anzahl der Freiheitsgrade} des betrachteten dynamischen Systems und sei \(U\subset \R^n \times \R^n\) der zugehörige Phasenraum.
Wir nennen ein Vektorfeld \(X \colon U \rightarrow \R^{2n}\) mit \(X \in C^1(P;\R^{2n})\) \sphinxstylestrong{Hamiltonsch}, falls eine reellwertige Funktion \(H \colon U \rightarrow \R\) sowie eine Matrix \(J \, \coloneqq \, \begin{pmatrix}0 & -\mathbf{1}\\ \mathbf{1} & 0 \end{pmatrix} \in \R^{2n \times 2n}\) existiert, so dass sich das Vektorfeld darstellen lässt als
\begin{equation}\label{equation:ode/hamilton:eq:hamilton_Gleichung}
\begin{split}X(p,q) = J \, \nabla H (p,q) \quad \forall (p,q) \in U.\end{split}
\end{equation}
\sphinxAtStartPar
In diesem Fall nennen wir die Funktion \(H\) eine \sphinxstylestrong{Hamilton\sphinxhyphen{}Funktion} des Vektorfelds \(X\).
\end{sphinxadmonition}

\sphinxAtStartPar
Folgende Bemerkungen zur Hamilton\sphinxhyphen{}Funktion wollen wir festhalten.
\label{ode/hamilton:remark-1}
\begin{sphinxadmonition}{note}{Remark 1.5}


\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Die Hamilton\sphinxhyphen{}Funktion lässt sich auch als Legendre\sphinxhyphen{}Transformation der Lagrange\sphinxhyphen{}Funktion des Systems herleiten, was weitere interessante Zusammenhänge in der Physik erklärt.
In dieser Vorlesung verzichten wir auf diesen Zugang zur Hamilton\sphinxhyphen{}Funktion und verweisen die interessierten Leser*innen auf Kapitel 2 {[}\hyperlink{cite.references:id9}{Nol11}{]}.

\item {} 
\sphinxAtStartPar
Im Folgenden werden wir annehmen, dass die Hamilton\sphinxhyphen{}Funktion \(H\) nicht explizit von der Zeitvariable \(t \in I\) abhängt, was jedoch im Allgemeinen sein kann.

\end{enumerate}
\end{sphinxadmonition}

\sphinxAtStartPar
Basierend auf der Hamilton\sphinxhyphen{}Funktion aus {\hyperref[\detokenize{ode/hamilton:def:hamiltonsch}]{\sphinxcrossref{Definition 1.9}}} können wir nun die Hamiltonschen Differentialgleichungen definieren.
\label{ode/hamilton:definition-2}
\begin{sphinxadmonition}{note}{Definition 1.10 (Hamiltonsche Differentialgleichung)}



\sphinxAtStartPar
Sei \(x(t) = (p(t),q(t)) \in U\) eine Bahnkurve des Phasenraums \(U \subset \R^{2n}\).
Wird das hamiltonsche Vektorfeld auf der linken Seite von \eqref{equation:ode/hamilton:eq:hamilton_Gleichung} als
\begin{equation*}
\begin{split}X = \dot{x}(t) = \begin{pmatrix} \dot{p} \\ \dot{q} \end{pmatrix} (t)\end{split}
\end{equation*}
\sphinxAtStartPar
gewählt, so lässt sich die Gleichung für \(J \, \coloneqq \, \begin{pmatrix}0 & -\mathbf{1}\\ \mathbf{1} & 0 \end{pmatrix} \in \R^{2n \times 2n}\) schreiben als
\begin{equation}\label{equation:ode/hamilton:eq:hamilton_DGL}
\begin{split}\dot{x}(t) = J \nabla H(x(t)).\end{split}
\end{equation}
\sphinxAtStartPar
In dieser Form wird die entstehende Differentialgleichung in \eqref{equation:ode/hamilton:eq:hamilton_DGL} \sphinxstylestrong{Hamiltonsche Differentialgleichung} genannt.

\sphinxAtStartPar
Äquivalent lässt sich dieses System von gewöhnlichen Differentialgleichungen auch explizit für die \(2n\) unbekannten Orts\sphinxhyphen{} und Impulsfunktionen \(q_i, p_i\) für \(1 \leq i \leq n\) schreiben als
\begin{equation*}
\begin{split}\dot{q_i}(t) = \frac{\partial H}{\partial p_i}(t), \quad \dot{p_i}(t) = -\frac{\partial H}{\partial q_i}(t), \quad i=1,\ldots,n.\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Für den einfachen Fall einer zeitunabhängigen Hamilton\sphinxhyphen{}Funktion \(H\) lässt sich beobachten, dass die Lösungskurven der Hamiltonschen Differentialgleichungen sich nicht schneiden und durch jeden Punkt des Phasenraums eine Lösungskurve verläuft.

\sphinxAtStartPar
Die Hamilton\sphinxhyphen{}Funktion \(H\) als Funktion des Phasenraumes kann als die Energie eines Systems von Teilchen aufgefasst werden.
Wir wollen uns die Rolle der Hamilton\sphinxhyphen{}Funktion \(H\) an Hand eines physikalischen Beispiels klar machen.
\label{ode/hamilton:example-3}
\begin{sphinxadmonition}{note}{Example 1.8 (Newtonsche Kraftgleichung)}



\sphinxAtStartPar
Im folgenden Beispiel wollen wir die Bewegung eines Teilchens mit Masse \(m>0\) in einem Kraftfeld \(F \colon \R^3 \rightarrow \R^3\)  untersuchen, welches nur vom Ort \(q \in \R^3\) abhängt.
Nach dem 2. Newtonschen Gesetz erhalten wir die Bewegungsgleichung
\begin{equation}\label{equation:ode/hamilton:eq:newton}
\begin{split}m\ddot{q}(t) = F(q(t)).\end{split}
\end{equation}
\sphinxAtStartPar
Die gewöhnliche Differentialgleichung 2. Ordnung in \eqref{equation:ode/hamilton:eq:newton} lässt sich durch die Definition des Impulses des Teilchens \(p(t) \, \coloneqq \, m \dot{q(t)}\) in ein gewöhnliches Differentialgleichungssystem 1. Ordnung überführen:
\begin{equation*}
\begin{split}\dot{p}(t) = F(q(t)), \quad \dot{q}(t) = \frac{1}{m}p(t).\end{split}
\end{equation*}
\sphinxAtStartPar
Wir nehmen zur Vereinfachung nun an, dass das gegebene Kraftfeld \(F\) \sphinxstyleemphasis{konservativ} sei, d.h., wir können annehmen, dass \(F = - \nabla V\) gilt für ein Potential \(V \colon \R^3 \rightarrow \R\) (z.B. die Erdanziehungskraft).
Dann können wir das physikalische Modell als kontinuierliches dynamisches System interpretieren mit dem erweiterten Phasenraum \(I \times U \subset \R^+_0 \times \R^6\).
Betrachten wir nun einen Punkt \(x = \begin{pmatrix} p \\ q\end{pmatrix} \in U\) im Phasenraum, so lässt sich das autonome gewöhnliche Differentialgleichungssystem kompakt schreiben als
\begin{equation}\label{equation:ode/hamilton:eq:newton_DGL}
\begin{split}\dot{x}(t) = \begin{pmatrix} \dot{p} \\ \dot{q} \end{pmatrix}(t) = \begin{pmatrix} -\nabla V(q) \\ \frac{p}{m} \end{pmatrix}(t)\end{split}
\end{equation}
\sphinxAtStartPar
Wählen wir nun die \sphinxstylestrong{Hamilton\sphinxhyphen{}Funktion} aus {\hyperref[\detokenize{ode/hamilton:def:hamiltonsch}]{\sphinxcrossref{Definition 1.9}}}
\begin{equation*}
\begin{split}H(p,q) \, \coloneqq \, \frac{||p||^2}{2m} + V(q),\end{split}
\end{equation*}
\sphinxAtStartPar
so erkennen wir, dass diese sich aus \sphinxstyleemphasis{kinetischer} und \sphinxstyleemphasis{potentieller Energie} zusammensetzt.
Durch diese Hamilton\sphinxhyphen{}Funktion \(H\) lässt sich \eqref{equation:ode/hamilton:eq:newton} als \sphinxstylestrong{Hamiltonsche Differentialgleichung} schreiben mit
\begin{equation*}
\begin{split}\dot{x}(t) = \begin{pmatrix}\dot{p} \\ \dot{q} \end{pmatrix}(t) = \begin{pmatrix} -\nabla V(q) \\ \frac{p}{m} \end{pmatrix}(t) = \begin{pmatrix}0 & -\mathbf{1}\\ \mathbf{1} & 0 \end{pmatrix} \begin{pmatrix} \frac{p}{m} \\ \nabla V(q) \end{pmatrix}(t) = J \nabla H(p(t),q(t)).\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Ergänzend wollen wir noch folgendes Beispiel einer Hamilton\sphinxhyphen{}Funktion nennen.
\label{ode/hamilton:example-4}
\begin{sphinxadmonition}{note}{Example 1.9}



\sphinxAtStartPar
Im Fall des eindimensionalen harmonischen Oszillators mit Masse \(m > 0\) aus {\hyperref[\detokenize{ode/fluesse:ex:oscillations}]{\sphinxcrossref{Example 1.7}}} lässt sich ebenfalls eine Hamilton\sphinxhyphen{}Funktion des dynamischen Systems angeben.
Sei \((x,p) \in U\) als Punkt des Phasenraums \(U \subset \R^2\) der Ort und Impuls eines Pendels.
Dann lässt sich die zugehörige Hamilton\sphinxhyphen{}Funktion \(H \colon U \rightarrow \R\) angeben als:
\begin{equation*}
\begin{split}H(x,p) = \frac{p^2}{2m} + \frac{m}{2} \omega^2 x^2.\end{split}
\end{equation*}
\sphinxAtStartPar
Hierbei bezeichnet \(\omega = \sqrt{\frac{k}{m}}\) die Eigenfrequenz des Systems und \(k > 0\) die Federkonstante.
\end{sphinxadmonition}

\sphinxAtStartPar
Bisher haben wir noch nicht den Grund diskutiert, warum die Hamilton\sphinxhyphen{}Funktion eine besondere Rolle im Kontext dynamischer Systeme spielt.
Das wollen wir nun im folgenden Satz nachholen.
\label{ode/hamilton:thm:hamconst}
\begin{sphinxadmonition}{note}{Theorem 1.3}



\sphinxAtStartPar
Sei \(n\in \N, U \subseteq \mathbb{R}^{2n}\) ein (offener) Phasenraum und \(J= \begin{pmatrix} 0 & - \mathbf{1} \\ \mathbf{1} & 0 \end{pmatrix} \in \mathbb{R}^{2n \times 2n}\).
Ist die Hamilton\sphinxhyphen{}Funktion \(H \in C^2(U; \mathbb{R})\), dann ist sie entlang der Lösungskurven der Hamiltonschen Differentialgleichung
\begin{equation*}
\dot x = J \nabla H(x)
\end{equation*}
\sphinxAtStartPar
konstant.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. In der Hausaufgabe zu zeigen.
\end{sphinxadmonition}

\sphinxAtStartPar
{\hyperref[\detokenize{ode/hamilton:thm:hamconst}]{\sphinxcrossref{Theorem 1.3}}} sagt uns also, dass die Orbits des kontinuierlichen Systems innerhalb der Niveaumengen der Hamilton\sphinxhyphen{}Funktion verlaufen.
Dies erlaubt es uns dynamische Systeme auf diese häufig auch \sphinxstyleemphasis{Energieschalen} genannten Niveaumengen \(H^{-1}(E)\) für \(E \in \R\) zu restringieren.
Diese Energieschalen bilden Untermannigfaltigkeiten des Phasenraums \(U\).

\sphinxAtStartPar
Für den einfachen Fall eines Freiheitsgrades, d.h., für \(n = 1\), lassen sich für eine gegebene Hamilton\sphinxhyphen{}Funktion \(H\) die Orbits des dynamischen Systems bestimmen.
Für einen Punkt \(x \in U\) im Phasenraum \(U \subset \R^2\) unterscheiden wir zwei Fälle:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Ist \(\nabla H(x) = 0\), so ist der Orbit wegem \eqref{equation:ode/hamilton:eq:hamilton_DGL} von der Form \(O(x) = {x}\).

\item {} 
\sphinxAtStartPar
Ist \(\nabla H(x) \neq 0\), so ist der Orbit \(O(x)\) gegeben durch die zusammenhängende Menge

\end{enumerate}
\begin{equation*}
\begin{split}O(x) = \{y \in U | H(y) = H(x), \nabla H(y) \neq 0\}\end{split}
\end{equation*}
\sphinxAtStartPar
Die Orientierung des Orbits erhält man durch die Richtung, die orthogonal zum Gradienten \(\nabla H\) steht, d.h., durch Drehung des Gradienten im Uhrzeigersinn um \(\frac{\pi}{2}\).
Die Matrix \(J\) entspricht eben einer solchen Drehung.
\label{ode/hamilton:remark-6}
\begin{sphinxadmonition}{note}{Remark 1.6}



\sphinxAtStartPar
Eine Formulierung der Bewegungsgleichungen eines dynamischen Systems als Hamiltonsche Differentialgleichungen hat den Vorteil, dass sie unter den sogenannten \sphinxstyleemphasis{kanonischen Transformationen} in manchen Fällen in eine einfachere, lösbare Form gebracht werden können.
\end{sphinxadmonition}


\section{Aufgaben}
\label{\detokenize{ode/ex:aufgaben}}\label{\detokenize{ode/ex::doc}}
\begin{sphinxadmonition}{note}{Aufgabe: DGL höherer Ordnung}

\sphinxAtStartPar
Gegeben sei folgende gewöhnliche Differentialgleichung 4.\textasciitilde{}Ordnung:
\begin{equation*}
\begin{split}x^{(4)}(t) = 7 x^{(3)}(t) - \dot x(t) + 5 x(t) + t^2\end{split}
\end{equation*}
\sphinxAtStartPar
Überführen Sie diese in ein System gewöhnlicher Differentialgleichungen 1.Ordnung.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Aufgabe: Autonome gewöhnliche Differentialgleichungen}

\sphinxAtStartPar
Entscheiden und begründen Sie mathematisch, ob die folgenden gewöhnlichen Differentialgleichungen \sphinxstylestrong{autonom} sind.

\sphinxAtStartPar
\sphinxstylestrong{a)} Differentialgleichung für harmonischen Oszillator:
\begin{equation*}
\begin{split}\ddot x(t) + \lambda x(t) = 0\end{split}
\end{equation*}
\sphinxAtStartPar
für eine Konstante \(\lambda \in \mathbb{R}\).

\sphinxAtStartPar
\sphinxstylestrong{b)} Newtonsche Kraftgleichung:
\begin{equation*}
\begin{split}m \ddot x(t) = F(t, x(t))\end{split}
\end{equation*}
\sphinxAtStartPar
für eine Konstante \(m > 0\), eine Kraft \(F: \mathbb{R} \times \mathbb{R}^3 \rightarrow \mathbb{R}^3\), welche von der Position im Raum \(x: \mathbb{R} \rightarrow \mathbb{R}^3\) und der Zeit \(t \in \mathbb{R}\) abhängt.

\sphinxAtStartPar
\sphinxstylestrong{c)} Newtonsche Kraftgleichung:
\begin{equation*}
\begin{split}m \ddot x(t) = F(t, x(t))\end{split}
\end{equation*}
\sphinxAtStartPar
für eine Konstante \(m > 0\), eine Kraft \(F: \mathbb{R}^3 \rightarrow \mathbb{R}^3\), welche im Gegensatz zur Situation in b) lediglich von der Position im Raum \(x: \mathbb{R} \rightarrow \mathbb{R}^3\) abhängt.

\sphinxAtStartPar
\sphinxstylestrong{d)} Mathieusche Differentialgleichung:
\begin{equation*}
\begin{split}\ddot x(t) + [\lambda + \gamma \cos(t)] ~ x(t) = 0\end{split}
\end{equation*}
\sphinxAtStartPar
für Konstanten \(\lambda, \gamma \in \mathbb{R}\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Flüsse}

\sphinxAtStartPar
Für \(I = \mathbb{R}^0_+\) und \(U = \mathbb{R}^2\) betrachten wir die Abbildung \(\phi: I \times U \rightarrow U\) mit
\begin{equation*}
\begin{split}\phi(t, x) = 
\begin{pmatrix} \frac{x_2}{2} ~ \sin(\omega t) + x_1 ~ \cos(\omega t) \\ x_2 ~ \cos(\omega t) - 2 x_1 ~ \sin(\omega t) \end{pmatrix}, \end{split}
\end{equation*}
\sphinxAtStartPar
wobei \(x = \begin{pmatrix} x_1 \\ x_2 \end{pmatrix}\) gilt.
Zeigen Sie, dass diese Abbildung die mathematischen Eigenschaften eines Flusses erfüllt.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Phasenporträt gedämpfter Oszillator}

\sphinxAtStartPar
Wir betrachten die Bewegungsgleichung für den harmonischen Oszillator
\begin{equation*}
\begin{split}m ~ \ddot x(t) + r ~ \dot x(t) + k ~ x(t) = 0\end{split}
\end{equation*}
\sphinxAtStartPar
mit Masse \(m = 1  ~ kg\), Dämpfungskonstante \(r = 0.5 ~ \frac{kg}{s}\) und Federkonstante \(k = 1.5 ~ \frac{kg}{s^2}\).

\sphinxAtStartPar
Wie in Beispiel 1.3 im Skript führen wir den Impuls \(p(t) = m ~ \dot x(t)\) ein und erhalten das Differentialgleichungssystem erster Ordnung
\begin{equation*}
\begin{split}\dot x(t) &= \frac{1}{m} ~ p(t)\\
\dot p(t) &= -k ~ x(t) - \frac{r}{m} ~ p(t).\end{split}
\end{equation*}
\sphinxAtStartPar
Zeichnen Sie händisch ein Phasenporträt für dieses System in den Unbekannten \(x\) und \(p\), indem Sie für die folgenden Punkte \((x,p)\) die durch das Differentialsystem gegebene Steigung berechnen und einzeichnen:
\begin{equation*}
\begin{split}&(-1, 0) \quad  (1, 0) \quad (0, -1) \quad  (0, 1)\\
&(-0.75, -0.75) \quad  (-0.75, 0.75) \quad (0.75, -0.75) \quad (0.75, 0.75)\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Aufgabe: Eigenschaften Hamilton\sphinxhyphen{}Funktion}

\sphinxAtStartPar
Beweisen Sie die folgende Aussage:

\sphinxAtStartPar
Sei \(P \subseteq \mathbb{R}^{2m}\) ein (offener) Phasenraum und \(\mathbb{J} = \begin{pmatrix} 0 & - 𝟙 \\ 𝟙 & 0 \end{pmatrix} \in Mat(2m, \mathbb{R})\). Ist die Hamilton\sphinxhyphen{}Funktion \(H \in C^2(P, \mathbb{R})\), dann ist sie entlang der Lösungskurven der Hamiltonschen Differentialgleichung \(\dot x = \mathbb{J} \nabla H(x)\) konstant.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Aufgabe: Hamilton\sphinxhyphen{}Funktion}

\sphinxAtStartPar
Zeigen Sie mathematisch, dass die Hamilton\sphinxhyphen{}Funktion eines eindimensionalen harmonischen Oszillators gegeben ist durch:
\begin{equation*}
\begin{split}H(x,p) = \frac{p^2}{2m} + \frac{m}{2} w^2 x^2,\end{split}
\end{equation*}
\sphinxAtStartPar
wobei \(w = \sqrt{\frac{k}{m}}\) gilt.
\end{sphinxadmonition}


\chapter{Stabilitätsanalyse für dynamische Systeme}
\label{\detokenize{odestability/stabilitaetsanalyse:stabilitatsanalyse-fur-dynamische-systeme}}\label{\detokenize{odestability/stabilitaetsanalyse::doc}}
\sphinxAtStartPar
In diesem Abschnitt beschäftigen wir uns mit der Stabilitätstheorie für kontinuierliche dynamische Systeme.
Hierbei interessieren wir uns für die Frage, wie sich \sphinxstyleemphasis{kleine Störungen} von bestimmten Zuständen des Systems auf die Lösungen der zu Grunde liegenden gewöhnlichen Differentialgleichungen auswirken.
Der untersuchte Zustand kann beispielsweise ein periodischer Orbit oder eine Ruhelage des dynamischen Systems sein.
Letztere sind oftmals von besonderes Interesse, da man in vielen technischen und physikalischen Anwendungen daran interessiert ist das System in eine oder nahe einer Gleichgewichtslage zu bringen.

\sphinxAtStartPar
Im Folgenden werden wir verschiedene Stabilitätsbegriffe für dynamische Systeme einführen und speziell Kriterien für die Stabilität von Ruhelagen diskutieren.


\section{Stabilitätsbegriffe}
\label{\detokenize{odestability/stabilitaetsbegriffe:stabilitatsbegriffe}}\label{\detokenize{odestability/stabilitaetsbegriffe::doc}}
\sphinxAtStartPar
Im Folgenden wollen wir grundlegende Begriffe der Stabilitätsanalyse von Ruhelagen einführen und diskutieren.
Wie in {\hyperref[\detokenize{ode/fluesse:s-fluesse}]{\sphinxcrossref{\DUrole{std,std-ref}{Phasenflüsse und Phasenportraits}}}} definiert, nennen wir einen Punkt \(x\in U\) im Phasenraum \(U\) \sphinxstylestrong{Ruhelage}, falls für den zugehörigen Phasenfluss \(\Phi \colon I \times U \rightarrow U\) des dynamischen Systems gilt: \(\Phi(t,x) = x, \forall t \in I\), d.h., wenn für alle \(t \in I\) der Zustand \(x \in U\) ein \sphinxstylestrong{Fixpunkt des Flusses} ist.

\sphinxAtStartPar
Für autonome Differentialgleichungssysteme mit
\begin{equation*}
\begin{split}\dot{x}(t) = F(x)\end{split}
\end{equation*}
\sphinxAtStartPar
ist \(x \in U\) auch eine Ruhelage, falls \(F(x) = 0\) gilt, d.h., falls \(x\) eine Nullstelle von \(F\) ist.
Das ist einfach zu verstehen, da die Zeitableitung auf der linken Seite für eine Ruhelage Null ist und somit die Funktion \(F\), die nur vom Ort abhängt, sich nicht ändern kann.

\sphinxAtStartPar
Anschaulich versteht man unter der Stabilitätsanalyse von Ruhelagen die mathematische Untersuchung, ob benachbarte Lösungen von einer Ruhelage wegstreben oder nicht.
Dies ist insbesondere in technischen Anwendungen wichtig, da man dort häufig danach strebt ein dynamisches System in eine Gleichgewichtslage zu bringen.
Da dies nur bis zu einer gewissen Genauigkeit möglich ist, muss man also mit kleinen Störungen rechnen.

\sphinxAtStartPar
Ist eine Ruhelage stabil, dann bleiben benachbarte Lösungen auch für zukünftige Zeitpunkte \(t \in I\) nahe der Ruhelage.
Ist sie jedoch nicht stabil, so muss das im Allgemeinen nicht gelten und die Lösungen können dann mit der Zeit von der Ruhelage divergieren.
Diese Anschauung wollen wir in der folgenden Definition mathematisch formalisieren.
Hierbei werden wir den Stabilitätsbegriff für allgemeine Lösungen einführen und später Ruhelagen als ein Spezialfall dieser Lösungen interpretieren.
\label{odestability/stabilitaetsbegriffe:def:Stabilitaet}
\begin{sphinxadmonition}{note}{Definition 2.1 (Stabilität von Lösungen)}



\sphinxAtStartPar
Sei \(\Phi \colon I \times U \rightarrow U\) der Phasenfluss zu dem Vektorfeld \(F\in C^1(U;\R^n)\) auf \(U\), dass durch die rechte Seite des zugehörigen Differentialgleichungssystems gegeben ist.

\sphinxAtStartPar
1. Eine Lösung \(t \in [0,\infty) \mapsto \Phi_t(x)\) heißt \sphinxstylestrong{(Lyapunov\sphinxhyphen{})stabil}, wenn zu jedem \(\epsilon > 0\) ein \(\delta>0\) existiert mit:
\begin{equation*}
\begin{split}\|x-y\|<\delta \ \Rightarrow \ \sup_{t\geq0}\|\Phi_t(x)-\Phi_t(y)\|<\epsilon.\end{split}
\end{equation*}
\sphinxAtStartPar
2. Eine Lösung \( t \in [0,\infty) \mapsto \Phi_t(x)\) heißt \sphinxstylestrong{asymptotisch stabil}, wenn ein \(\delta > 0\) existiert mit:
\begin{equation*}
\begin{split}\|x-y\|<\delta \ \Rightarrow \ \lim_{t\to\infty}\|\Phi_t(x)-\Phi_t(y)\|=0.\end{split}
\end{equation*}
\sphinxAtStartPar
3. Eine Lösung heißt \sphinxstylestrong{instabil}, wenn sie nicht (Lyapunov\sphinxhyphen{})stabil ist.
\end{sphinxadmonition}

\begin{sphinxShadowBox}
\sphinxstylesidebartitle{Aleksandr Lyapunov}

\sphinxAtStartPar
\sphinxhref{https://de.wikipedia.org/wiki/Alexander\_Michailowitsch\_Ljapunow}{Alexander Michailowitsch Ljapunow} (Geboren 6. Juni 1857 in Jaroslawl; Gestorben 3. November 1918 in Odessa) war ein russischer Mathematiker und Physiker.
\end{sphinxShadowBox}

\sphinxAtStartPar
Es ist klar, dass der Begriff der asymptotischen Stabilität \sphinxstyleemphasis{stärker} als der Begriff der Lyapunov\sphinxhyphen{}Stabilität von Lösungen ist, da jede asymptotisch stabile Lösung auch schon Lyapunov\sphinxhyphen{}stabil ist.
Die Umkehrung gilt jedoch im Allgemeinen nicht.
Dies wird durch das folgende Beispiel nochmal illustriert.
\label{odestability/stabilitaetsbegriffe:example-1}
\begin{sphinxadmonition}{note}{Example 2.1 (Stabilitätsanalyse für den harmonischer Oszillator)}



\sphinxAtStartPar
Der Phasenfluss für den harmonischen Oszillator ist, wie wir in {\hyperref[\detokenize{ode/fluesse:ex:oscillations}]{\sphinxcrossref{Example 1.7}}} gesehen haben, gegeben durch
\begin{equation*}
\begin{split}\Phi(t, (p,x)) = \begin{pmatrix}
p \cos(\omega t) - m x \sin(\omega t)\\
\frac{p}{\omega m}\sin(\omega t) + x\cos(\omega t)
\end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
Wir suchen nun einen Fixpunkt \((p_r,x_r) \in U\) des Flusses der unabhängig ist vom Zeitpunkt \(t\).
Man sieht leicht ein, dass eine \sphinxstylestrong{Ruhelage} sich bei \((p_r,x_r) = (0,0)^T \in U\) befindet, da \(\Phi(t,(0,0)) = (0,0)^T\) ist für alle \(t \in I\).
Die gefundene Ruhelage ist \sphinxstylestrong{Lyapunov\sphinxhyphen{}stabil}, denn wie wir im Phasenporträt in \hyperref[\detokenize{ode/fluesse:fig-harmonic-oscillator}]{Fig.\@ \ref{\detokenize{ode/fluesse:fig-harmonic-oscillator}}} gesehen haben, ist jeder Orbit um die Ruhelage \((0,0)\) periodisch. Damit kann das dynamische System insgesamt nicht wegstreben von der Ruhelage.

\sphinxAtStartPar
Mathematisch lässt sich diese Eigenschaft wie folgt zeigen.
Für ein beliebiges \(\epsilon > 0\) sei \((p,y) \in U\) ein Punkt im Phasenraum mit periodischen Orbit \(O(p,y)\) um die Ruhelage \((p_r,x_r) = (0,0)^T \in U\), so dass dessen maximaler Abstand zur Ruhelage kleiner als \(\epsilon\) ist, d.h.
\begin{equation*}
\begin{split}\sup_{t \geq 0} ||\Phi_t(p_r,x_r) - \Phi_t(p,y)|| < \epsilon\end{split}
\end{equation*}
\sphinxAtStartPar
Auf Grund der ersten Eigenschaft des Phasenflusses \(\Phi_0(p,y) = (p,y)\) gilt dann aber schon
\begin{equation*}
\begin{split}||(p_r, x_r) - (p,y)|| = ||\Phi_0(p_r, x_r) - \Phi_0(p,y)|| < \epsilon.\end{split}
\end{equation*}
\sphinxAtStartPar
Wählen wir nun \(\delta \coloneqq \epsilon\), so haben wir gezeigt, dass die Ruhelage \((p_r, x_r) = (0,0)^T\) Lyapunov\sphinxhyphen{}stabil ist.
Sie ist jedoch auf Grund der Periodizität der Orbits um die Ruhelage \sphinxstylestrong{nicht asymptotisch stabil}, da für beliebige Punkte \((p,y) \in U\) mit \(||(p_r,x_r) - (p,y)|| < \delta\) für ein \(\delta > 0\) gilt
\begin{equation*}
\begin{split}\lim_{t\to\infty}\|\Phi_t(p_r, x_r)-\Phi_t(p,y)\| \neq 0.\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Im allgemeinen Fall der gedämpften Schwingungsgleichung in {\hyperref[\detokenize{ode/fluesse:ex:oscillations}]{\sphinxcrossref{Example 1.7}}} hängt die Stabilität der Ruhelage im Ursprung intuitiverweise von der Reibungskonstanten ab, wie folgende Bemerkung festhält.
\label{odestability/stabilitaetsbegriffe:remark-2}
\begin{sphinxadmonition}{note}{Remark 2.1 (Stabilität bei der gedämpften Schwingungsgleichung)}



\sphinxAtStartPar
Für den Fall der gedämpften Schwingungsgleichung in \eqref{equation:ode/fluesse:eq:schwingungsgleichung} lässt sich folgendes Stabilitätsverhalten der Ruhelage im Ursprung in Abhängigkeit der Reibungskonstanten \(r \in \R\) beobachten:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Die Ruhelage ist \sphinxstylestrong{asymptotisch stabil} für den Fall mit positiver Reibung \(r>0\).

\item {} 
\sphinxAtStartPar
Die Ruhelage ist \sphinxstylestrong{Lyapunov\sphinxhyphen{}stabil} für den reibungsfreien Fall \(r=0\).

\item {} 
\sphinxAtStartPar
Die Ruhelage ist \sphinxstylestrong{instabil} für den Fall einer negativen Reibung \(r < 0\), d.h. für einen externen Antrieb.

\end{enumerate}
\end{sphinxadmonition}


\section{Stabilität von Ruhelagen}
\label{\detokenize{odestability/ruhelagen:stabilitat-von-ruhelagen}}\label{\detokenize{odestability/ruhelagen::doc}}
\sphinxAtStartPar
Zunächst wollen wir die Stabilität von dynamischen System im einfachen Fall von Ruhelagen für allgemeine \sphinxstylestrong{lineare} Differentialgleichungssysteme untersuchen.
Diese Familie von gewöhnlichen Differentialgleichungssystemen haben wir schon in Kapitel 8 in {[}\hyperlink{cite.references:id12}{Ten21}{]} kennen gelernt.

\sphinxAtStartPar
Das folgende Theorem beschreibt die Existenz und Eindeutigkeit einer Ruhelage eines dynamischen System, das durch ein lineares Differentialgleichungssystem charakterisiert wird und gibt Bedingungen für die Stabilität der Ruhelage.
\label{odestability/ruhelagen:thm:stablin}
\begin{sphinxadmonition}{note}{Theorem 2.1}



\sphinxAtStartPar
Sei \(A\in \C^{n\times n}\) eine Matrix mit den Eigenwerten \(\lambda_1,\dots, \lambda_n\in \C\).
Dann beschreibt der zugehörige Phasenfluss \(\Phi\) zum homogenen linearen Differentialgleichungssystem
\begin{equation*}
\begin{split}\dot{x}(t) = Ax(t)\end{split}
\end{equation*}
\sphinxAtStartPar
eine Ruhelage in \(\mathbf{0} \in \C^n\).
Diese ist sogar eindeutig, falls \(\lambda_i\neq 0, i=1,\ldots,n\) gilt.

\sphinxAtStartPar
Für
\begin{equation*}
\begin{split}\gamma \coloneqq \max_{i=1,\dots,n} \mathcal{Re}(\lambda_i)\end{split}
\end{equation*}
\sphinxAtStartPar
kann die Stabilität der Ruhelage wie folgt charakterisiert werden:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Falls \(\gamma <0\) gilt, ist die Ruhelage \(\mathbf{0}\) \sphinxstyleemphasis{asymptotisch stabil}

\item {} 
\sphinxAtStartPar
Falls \(\gamma >0\) gilt, ist die Ruhelage \(\mathbf{0}\) \sphinxstyleemphasis{instabil}.

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Wir wissen, dass für einen beliebigen Startpunkt \(x_0 \in U\) im Phasenraum der Phasenfluss \(\Phi \colon I \times U \rightarrow U\) eine Lösung des Differentialgleichungssystems realisiert.
Für homogene, lineare Differentialgleichungssysteme haben wir bereits in {\hyperref[\detokenize{ode/repetition:s-lineare-dglsysteme}]{\sphinxcrossref{\DUrole{std,std-ref}{Lösungen von linearen Differentialgleichungssystemen}}}} Lösungen mittels des \sphinxstyleemphasis{Matrixexponentials} hergeleitet.

\sphinxAtStartPar
Sei \(J = S^{-1}AS\) die Jordansche Normalform von \(A\) mit Transformationsmatrizen \(S^{-1},S \in \C^{n \times n}\), so erhalten wir die Abschätzung
\begin{equation*}
\begin{split}\|\Phi_t(x_0)\| &= \|e^{tA}x_0\| = \|S^{-1}e^{tJ}Sx_0\| = \|S^{-1}e^{tD}e^{tN}Sx_0\| \\
&\leq \|S^{-1}\| \cdot \|e^{tD}\| \cdot \|e^{tN}\| \cdot \|S\| \cdot \|x_0\| \leq C_1 \cdot \|e^{tD}\| \cdot \|e^{t N}\|,\end{split}
\end{equation*}
\sphinxAtStartPar
für eine Konstante \(C_1 > 0\), die unabhängig von \(t\) ist.
Hierbei haben wir ausgenutzt, dass sich die Jordannormalform \(J\) von \(A\) als Summe einer Diagonalmatrix \(D\) mit den Eigenwerten \(\lambda_i \in \C\), \(i=1,\ldots,n\) von \(A\) und einer nilpotenten Matrix \(N\) schreiben lässt als \(J = D + N\).
Diese Matrizen kommutieren, d.h., \(D \cdot N = N \cdot D\).

\sphinxAtStartPar
Wir sehen nun ein, dass \(e^{tN}\) wegen der Nilpotenz von \(N\) eine endliche Reihe bildet der Form
\begin{equation*}
\begin{split}e^{tN} = \sum_{k=0}^m \frac{(tN)^k}{k!} = \sum_{k=0}^m t^k\frac{N^k}{k!},\end{split}
\end{equation*}
\sphinxAtStartPar
welches ein Polynom vom Grad \(m\) darstellt, wobei \(m \in \N\) der Nilpotenzindex der Matrix \(N\) ist.

\sphinxAtStartPar
Sei nun \(\epsilon > 0\) beliebig klein gewählt.
Dann lässt sich die Norm des Polynoms mit einer genügend großen Konstanten \(C_2 > 0\), die von \(\epsilon\) jedoch nicht von \(t\) abhängt, durch eine gewöhnliche Exponentialfunktion abschätzen mit
\begin{equation*}
\begin{split} \|e^{tN}\| = \| \sum_{k=0}^m t^k\frac{N^k}{k!} \| \leq \sum_{k=0}^m t^k \frac{\|N^k\|}{k!} \leq C_2  e^{t \epsilon}.\end{split}
\end{equation*}
\sphinxAtStartPar
Wählen wir nun \(\gamma \coloneqq \max_{i=1,\dots,n} \mathcal{Re}(\lambda_i)\), so folgt direkt, dass gilt
\begin{equation*}
\begin{split}||e^{tD}|| \leq C_3 e^{t\gamma}.\end{split}
\end{equation*}
\sphinxAtStartPar
Insgesamt erhalten wir also für die Norm des Phasenflusses
\begin{equation}\label{equation:odestability/ruhelagen:eq:abschaetzungew}
\begin{split}\|\Phi_t(x_0)\| \leq C_1 \cdot \|e^{tN}\| \cdot \|e^{tD}\| \leq C_1 \cdot C_2 e^{t \epsilon} \cdot C_3 e^{t\gamma} = C e^{t \epsilon} e^{t\gamma}.\end{split}
\end{equation}
\sphinxAtStartPar
Da \(\epsilon > 0\) beliebig klein ist, können wir \(|\epsilon| < |\gamma|\) wählen.
Damit hängt das Verhalten der Norm des Flusses nur noch vom Vorzeichen von \(\gamma\) ab.
Wir unterscheiden daher zwei Fälle:

\sphinxAtStartPar
1. Wenn \(\gamma >0\) ist, so existiert zum Eigenwert \(\gamma\) von \(A\) ein zugehöriger Eigenvektor \(v\in U\), so dass die Eigenwertgleichung \(A v = \gamma v\) gilt.
Nach {\hyperref[\detokenize{ode/repetition:lem:mpotew}]{\sphinxcrossref{Lemma 1.1}}} ist dann \(e^{t\gamma}\) ein Eigenwert des Matrixexponentials \(e^{tA}\) mit zugehörigem Eigenvektor \(v\).
Insgesamt erhalten wir also
\begin{equation*}
\begin{split}||\Phi_t(\alpha v)|| = ||e^{tA}\alpha v|| = ||\lambda e^{t\gamma} \alpha v|| \to \infty, \quad \text{ für } \ t \to \infty, \quad  \forall \alpha>0. \end{split}
\end{equation*}
\sphinxAtStartPar
Also enthält jede beliebig kleine Umgebung der Ruhelage \(0\) Punkte, für die die entsprechenden Lösungen divergieren.
In diesem Fall ist die Ruhelage also \sphinxstylestrong{instabil}.

\sphinxAtStartPar
2. Falls \(\gamma <0\) gilt, so gilt auch \(\gamma + \epsilon <0\) und wir können abschätzen,
\begin{equation*}
\begin{split}0\leq \|\Phi_t(x_0)-0\|\leq C e^{t (\gamma + \epsilon)} \to 0 \quad \text{ für } \ t \to \infty.\end{split}
\end{equation*}
\sphinxAtStartPar
Dies liefert uns also \sphinxstylestrong{asymptotische Stabilität} der Ruhelage \(\mathbf{0}\).
\end{sphinxadmonition}

\sphinxAtStartPar
Wir haben also gesehen, dass im Fall eines homogenen, linearen Differentialgleichungssystems die \(\mathbf{0}\) immer eine Ruhelage des zugehörigen dynamischen Systems darstellt, deren Stabilität einzig vom Vorzeichen des größten Eigenwerts abhängt.


\subsection{Linearisierung um Ruhelage}
\label{\detokenize{odestability/ruhelagen:linearisierung-um-ruhelage}}\label{\detokenize{odestability/ruhelagen:s-linearisierung-ruhelage}}
\sphinxAtStartPar
In diesem Abschnitt wollen wir unsere Erkentnisse zur Stabilitätsanalysie vom Fall eines linearen Differentialgleichungssystems auf den allgemeinen Fall übertragen, da man es in den meisten Anwendungen leider nur selten mit linearen Differentialgleichungen zu tun hat.
Darüber hinaus ist es erstrebenswert Stabilitätsaussagen zu Differentialgleichungen zu machen, deren Lösungen man nicht explizit analytisch herleiten kann.
Daher betrachten wir im Folgenden das Anfangswertproblem eines \sphinxstylestrong{allgemeinen Differentialgleichungssystem erster Ordnung} auf dem Phasenraum \(U\in \R^n\), das nicht notwendigerweise linear sein muss und für ein Vektorfeld \(F\in C^1(U;\R^n)\) wie folgt formuliert ist
\begin{equation}\label{equation:odestability/ruhelagen:eq:awpallg}
\begin{split}\dot{x}(t) &= F(x(t)), \quad \forall t \in I \subset \R^+_0\\
x(0) &= x_0.\end{split}
\end{equation}
\sphinxAtStartPar
Wir nehmen an, dass \(x_F \in U\) eine Ruhelage des dynamischen Systems ist, so dass dementsprechend \(F(x_F) = 0\) gilt.
Durch einfache Translation der Koordinaten des Systems um \(x_F \in U\), können wir ohne Beschränkung der Allgemeinheit annehmen, dass die Ruhelage sich im Nullpunkt befindet.

\sphinxAtStartPar
Im Folgenden definieren wir zwei wichtige Werkzeuge zur Untersuchung der Stabilität von Ruhelagen für allgemeine Differentialgleichungssysteme.
\label{odestability/ruhelagen:def:linearisierung}
\begin{sphinxadmonition}{note}{Definition 2.2 (Linearisierung und Abweichung)}



\sphinxAtStartPar
Sei \(F\in C^1(U;\R^n)\) ein Vektorfeld auf dem Phasenraum \(U \subset \R^n\) und \(0\) eine Ruhelage des dynamischen Systems, dass durch das allgemeine Differentialgleichungssystem in \eqref{equation:odestability/ruhelagen:eq:awpallg} charakterisiert wird.
Sei nun \((DF)(x)\) die Jacobi\sphinxhyphen{}Matrix der Funktion \(F\) im Punkt \(x \in U\) (vgl. Kapitel 6.2 in {[}\hyperlink{cite.references:id12}{Ten21}{]}).
Dann bezeichnen wir mit \(A := (DF)(0)\) die \sphinxstylestrong{Linearisierung} von \(F\) in der Ruhelage \(0 \in U\).
Außerdem bezeichnen wir die Funktion \(R \in C^1(U; \R^n)\) mit
\begin{equation*}
\begin{split}R(x) \ \coloneqq \ F(x) - Ax\end{split}
\end{equation*}
\sphinxAtStartPar
als die \sphinxstylestrong{Abweichung} (auch \sphinxstylestrong{Residuum} genannt) des Vektorfeldes \(F\) von seiner Linearisierung \(A\) in der Ruhelage.
\end{sphinxadmonition}

\sphinxAtStartPar
Mit diesen Hilfswerkzeugen werden wir im Folgenden zeigen, dass die Lösung des Differentialgleichungssystem in führender Ordnung durch die Linearisierung \(A\) von \(F\) kontrolliert werden, solange wir uns nah genug zur Ruhelage befinden. Dies wird durch das folgende Lemma ausgedrückt.
\label{odestability/ruhelagen:lem:intexpglgn}
\begin{sphinxadmonition}{note}{Lemma 2.1}



\sphinxAtStartPar
Wir betrachten das Anfangswertproblem aus \eqref{equation:odestability/ruhelagen:eq:awpallg} auf dem Phasenraum \(U \subset \R^n\) für ein Vektorfeld \(F\in C^1(U;\R^n)\).
Außerdem sei \(A \coloneqq (DF)(0)\) die Linearisierung des Vektorfelds in der Ruhelage \(0\) des dynamischen Systems und \(R(x) \coloneqq F(x) - Ax\) die Abweichung von \(F\) von seiner Linearisierung \(A\) im Nullpunkt.

\sphinxAtStartPar
Dann lassen sich Lösungen des Differentialgleichungssystems mittels der Linearisierung \(A\) und der Abweichung \(R\) explizit angeben als
\begin{equation*}
\begin{split}x(t) = e^{At}x_0 + \int_0^t e^{A(t-s)} R(x(s))\, \mathrm{d}s, \quad \forall t \in I.\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Wir setzen zunächst die unbekannte Lösung \(x(t)\) des Anfangswertproblems \eqref{equation:odestability/ruhelagen:eq:awpallg} in der allgemeinen Form
\begin{equation*}
\begin{split}x(t) = e^{At}c(t),\quad \text{mit }c(0) = x_0\end{split}
\end{equation*}
\sphinxAtStartPar
an, und suchen eine Bestimmungsgleichung für die unbekannte Funktion \(c(t)\) mittels \sphinxstylestrong{Variation der Konstanten} (vgl. Kapitel 8.2 in {[}\hyperlink{cite.references:id12}{Ten21}{]}).

\sphinxAtStartPar
Mittels der Rechenregeln für das Matrixexponentials in {\hyperref[\detokenize{ode/repetition:rem:matrixexponentialregeln}]{\sphinxcrossref{Remark 1.3}}} können wir die Ableitung der Funktion \(x\) mittels Produktregel angeben als
\begin{equation*}
\begin{split}\dot{x}(s) = A e^{As}c(s)+ e^{As}\dot{c}(s) = Ax(s) + e^{As}\dot{c}(s).\end{split}
\end{equation*}
\sphinxAtStartPar
Aus der Definition des Residuums in {\hyperref[\detokenize{odestability/ruhelagen:def:linearisierung}]{\sphinxcrossref{Definition 2.2}}} folgt aber auch
\begin{equation*}
\begin{split}\dot{x}(s) = F(x(s)) = Ax(s) + R(x(s)).\end{split}
\end{equation*}
\sphinxAtStartPar
Vergleichen wir die beiden Gleichungen, so sieht man ein, dass
\begin{equation*}
\begin{split}e^{As}\dot{c}(s) = R(x(s))\end{split}
\end{equation*}
\sphinxAtStartPar
gelten muss.
Äquivalent können wir auch folgern, dass \(\dot{c}(s) = e^{-As}R(x(s))\) gilt.

\sphinxAtStartPar
Nach dem Hauptsatz der Differential\sphinxhyphen{} und Integralrechnung (vgl. Theorem 5.3 in {[}\hyperlink{cite.references:id12}{Ten21}{]}) gilt dann für die unbekannte Funktion \(c\) der folgende Zusammenhang
\begin{equation*}
\begin{split}c(t) = c(0) + \int_0^t \dot{c}(s)\, \mathrm{d}s = x_0+ \int_0^t e^{-As}R(x(s)) \, \mathrm{d}s.\end{split}
\end{equation*}
\sphinxAtStartPar
Setzen wir dies in die erste Gleichung unserer Ansatzfunktion ein und nutzen die Rechenregeln des Matrixexponnentials aus {\hyperref[\detokenize{ode/repetition:rem:matrixexponentialregeln}]{\sphinxcrossref{Remark 1.3}}}, so erhalten wir schließlich die Aussage des Lemmas
\begin{equation*}
\begin{split}x(t) = e^{At}x_0+ \int_0^t e^{A(t-s)}R(x(s)) \, \mathrm{d}s.\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Auf den ersten Blick nützt uns die Identität in {\hyperref[\detokenize{odestability/ruhelagen:lem:intexpglgn}]{\sphinxcrossref{Lemma 2.1}}} nicht viel, denn auch auf der rechten Seite taucht \(x(s)\), also die unbekannte Lösung des Anfangswertproblems \eqref{equation:odestability/ruhelagen:eq:awpallg} auf.
Es stellt sich jedoch heraus, dass wir die \sphinxstylestrong{Gronwall\sphinxhyphen{}Ungleichung} auf diese Integralgleichung anwenden können.
Diese wichtige Abschätzung in der Theorie von Differentialgleichungen ähnelt Münchhausens Methode, sich an den eigenen Haaren aus dem Sumpf zu ziehen.

\begin{sphinxShadowBox}
\sphinxstylesidebartitle{Thomas Gronwall}

\sphinxAtStartPar
\sphinxhref{https://de.wikipedia.org/wiki/Thomas\_Hakon\_Gr\%C3\%B6nwall}{Thomas Hakon Gronwall} (Geboren 16. Januar 1877 in Dylta Bruk bei Axberg/Gemeinde Örebro; Gestorben 9. Mai 1932 in New York, NY) war ein schwedischer Mathematiker.
\end{sphinxShadowBox}
\label{odestability/ruhelagen:lemma:Gronwall}
\begin{sphinxadmonition}{note}{Lemma 2.2 (Gronwall\sphinxhyphen{}Ungleichung)}



\sphinxAtStartPar
Für zwei stetige Funktionen \(f,g\in C([t_0,t_1]; \R^+)\) gelte für eine Konstante \(a \geq 0\) die Ungleichung
\begin{equation*}
\begin{split}f(t) \leq a + \int_{t_0}^t f(s)g(s)\, \mathrm{d}s \quad \forall t\in [t_0,t_1].\end{split}
\end{equation*}
\sphinxAtStartPar
Dann lässt sich der Wert der Funktion \(f\) durch die Funktion \(g\) wie folgt abschätzen
\begin{equation*}
\begin{split}f(t) \leq a \exp{ \left(\int_{t_0}^t g(s)\, \mathrm{d}s \right)} \quad \forall t\in [t_0,t_1].\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Wir definieren zunächst eine Hilfsfunktion
\begin{equation*}
\begin{split}h(t) \ \coloneqq \ a + \int_{t_0}^t f(s)g(s)\, \mathrm{d}s\end{split}
\end{equation*}
\sphinxAtStartPar
und bemerken, dass \(0 \leq f(t) \leq h(t)\) nach Voraussetzung gilt für alle \(t \in [t_0, t_1]\).
Nun führen wir eine einfache Fallunterscheidung durch:

\sphinxAtStartPar
1. Ist \(h(t)=0\), so folgt mit der Abschätzung \(f(t) \leq h(t)\) schon, dass \(f(t) = 0\) gelten muss, so dass die Behauptung des Lemmas trivialerweise erfüllt ist.

\sphinxAtStartPar
2. Sei also im Folgenden \(h(t) > 0\).
Aus dem Haupsatz der Integral\sphinxhyphen{} und Differentialrechnung wissen wir, dass \(h'(t) = f(t)g(t)\) gilt.
Wegen \(f(t) \leq h(t)\) für alle \(t \in [t_0, t_1]\) folgt sofort, dass
\begin{equation*}
\begin{split}f(t)g(t) \leq h(t)g(t) \quad \forall t \in [t_0,t_1].\end{split}
\end{equation*}
\sphinxAtStartPar
Kombinieren wir diese Abschätzung mit der Identität der Ableitung \(h'(t)\), so erhalten wir durch Umstellen
\begin{equation*}
\begin{split}\frac{h'(t)}{h(t)} \leq g(t) \quad \forall t \in [t_0, t_1].\end{split}
\end{equation*}
\sphinxAtStartPar
Da wir \(h(t) > 0\) angenommen haben erhalten wir durch Integration beider Seiten die Abschätzung
\begin{equation*}
\begin{split}\int_{t_0}^t \frac{h'(s)}{h(s)} \, \mathrm{d}s \leq \int_{t_0}^t g(s) \, \mathrm{d}s \end{split}
\end{equation*}
\sphinxAtStartPar
für alle \(t \in [t_0, t_1]\).
Für die linke Seite können wir das Integral explizit angeben als
\begin{equation*}
\begin{split}\int_{t_0}^t \frac{h'(s)}{h(s)} \, \mathrm{d}s = \ln(h(t)) - \ln(h(t_0)) = \ln(h(t)) - \ln(a) = \ln\left(\frac{h(t)}{a}\right).\end{split}
\end{equation*}
\sphinxAtStartPar
Es gilt also nun
\begin{equation*}
\begin{split}\ln \left(\frac{h(t)}{a}\right) \leq \int_{t_0}^t g(s)\, \mathrm{d}s.\end{split}
\end{equation*}
\sphinxAtStartPar
Durch Anwenden der Exponentialfunktion auf beiden Seiten und Ausnutzen der Voraussetzung \(f(t) \leq h(t)\) erhalten wir schließlich die Behauptung des Lemmas
\begin{equation*}
\begin{split} f(t) \leq h(t)\leq a \exp{\left( \int_{t_0}^t g(s)\, ds \right)} \quad \forall t \in [t_0,t_1].\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Wir wollen folgende Bemerkungen zur Gronwall\sphinxhyphen{}Ungleichung festhalten.
\label{odestability/ruhelagen:remark-4}
\begin{sphinxadmonition}{note}{Remark 2.2}



\sphinxAtStartPar
1. Die in {\hyperref[\detokenize{odestability/ruhelagen:lemma:Gronwall}]{\sphinxcrossref{Lemma 2.2}}} beschriebene Gronwall\sphinxhyphen{}Ungleichung ist eigentlich ein Spezialfall für eine konstante Funktion \(a(t) \equiv a \geq 0\).
Die ursprünglich bewiesene Aussage gilt auch für allgemeinere Funktionen.

\sphinxAtStartPar
2. Man kann sich die Abschätzung in der Gronwall\sphinxhyphen{}Ungleichung leicht merken wenn man Gleichheit der beiden Seiten annimmt.
Die Integralgleichung
\begin{equation*}
\begin{split}f(t) = a + \int_{t_0}^t f(s)g(s)\, \mathrm{d}s \quad t\in [t_0,t_1]\end{split}
\end{equation*}
\sphinxAtStartPar
entspricht nämlich dem \sphinxstylestrong{linearen Anfangswertproblem}
\begin{equation*}
\begin{split}\dot{f}(t) &= f(t)\cdot g(t) \quad \forall t \in [t_0, t_1], \\
f(t_0) &= a,\end{split}
\end{equation*}
\sphinxAtStartPar
welches für alle \(t \in [t_0, t_1]\) die folgende explizite Lösung besitzt
\begin{equation*}
\begin{split}f(t) = a \exp{\left( \int_{t_0}^t g(s)\, \mathrm{d}s \right)}.\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Wir werden die Resultate der beiden Lemmata in den folgenden Abschnitten anwenden, um die Stabilität von Ruhelagen eines allgemeinen dynamischen Systems durch eine Linearisierung zu untersuchen.


\subsection{Asymptotische Stabilität von Ruhelagen}
\label{\detokenize{odestability/ruhelagen:asymptotische-stabilitat-von-ruhelagen}}
\sphinxAtStartPar
Durch die explizite Darstellung von Lösungen allgemeiner Differentialgleichungssysteme basierend auf der Linearisierung und Abweichung des Vektorfeldes \(F \colon U \rightarrow \R^n\) in {\hyperref[\detokenize{odestability/ruhelagen:lem:intexpglgn}]{\sphinxcrossref{Lemma 2.1}}} und der Gronwall\sphinxhyphen{}Ungleichung in {\hyperref[\detokenize{odestability/ruhelagen:lemma:Gronwall}]{\sphinxcrossref{Lemma 2.2}}} sind wir nun in der Lage die Stabilität einer Ruhelage eines dynamischen Systems zu analysieren.

\sphinxAtStartPar
Wir formulieren direkt das Hauptresultat, dass uns ein hinreichendes Kriterium für \sphinxstylestrong{asymptotische Stabilität} der Ruhelage basierend auf den Eigenwerten der Linearisierung liefert.
\label{odestability/ruhelagen:thm:stabasymallg}
\begin{sphinxadmonition}{note}{Theorem 2.2 (Asymptotische Stabilität von Ruhelagen)}



\sphinxAtStartPar
Sei \(F \in C^1(U; \R^n)\) ein Vektorfeld auf dem offenen Phasenraum \(U \subset \R^n\).
Eine Ruhelage \(x_F \in  U \subset \R^n\) des dynamischen Systems, das durch das allgemeine Differentialgleichungssystem
\begin{equation*}
\begin{split}\dot{x}(t) = F(x(t)), \quad \forall t \in \R^+_0\end{split}
\end{equation*}
\sphinxAtStartPar
charakterisiert wird, ist \sphinxstylestrong{asymptotisch stabil} wenn für die Eigenwerte \(\lambda_i \in \C, i=1,\ldots,n\) der Linearisierung \(A \, \coloneqq \, (Df)(x_F)\) gilt
\begin{equation*}
\begin{split}\mathcal{Re}(\lambda_i)<0, \quad \text{für } i=1,\ldots,n.\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Wie bereits in {\hyperref[\detokenize{odestability/ruhelagen:s-linearisierung-ruhelage}]{\sphinxcrossref{\DUrole{std,std-ref}{Linearisierung um Ruhelage}}}} diskutiert können wir durch Translation der Koordinaten des dynamischen Systems annehmen, dass ohne Beschränkung der Allgemeinheit \(x_F = 0 \in U\) gilt.
Da \(U\subseteq\R^n\) nach Vorraussetzung offen ist, können wir eine offene Kugel \(B_{{r^\ast}}(0) \coloneqq \{y \in U \colon ||y|| < {r^\ast}\}\) mit Radius \({r^\ast} > 0\) als Umgebung der Ruhelage \(0\) finden, so dass \(B_{r^\ast}(0) \subset U\) gilt.

\sphinxAtStartPar
Wir nehmen im Folgenden an, dass der Realteil der Eigenwerte \(\lambda_i \in \C, i=1,\ldots,n\) der Linearisierung \(A \, \coloneqq \, Df(0)\) echt negativ ist, d.h., für ein geeignetes \(\Lambda > 0\) gilt die Abschätzung
\begin{equation*}
\begin{split}\mathcal{Re}(\lambda_i)< -\Lambda, \quad \text{für } i=1,\ldots,n. \end{split}
\end{equation*}
\sphinxAtStartPar
Dann gibt es analog zum Beweis von {\hyperref[\detokenize{odestability/ruhelagen:thm:stablin}]{\sphinxcrossref{Theorem 2.1}}} eine Konstante \(c>0\), so dass gilt
\begin{equation}\label{equation:odestability/ruhelagen:eq:normexp}
\begin{split}\|e^{At}\| \leq c\cdot e^{-\Lambda t}\quad \forall t\in \R^+_0.\end{split}
\end{equation}
\sphinxAtStartPar
Hierbei haben wir ausgenutzt, dass wir die Konstante \(\epsilon > 0\) in \eqref{equation:odestability/ruhelagen:eq:abschaetzungew} so klein wählen können, dass \(\gamma + \epsilon < -\Lambda\) gilt.

\sphinxAtStartPar
Wir können nun einen Radius \(r\in (0,{r^\ast})\) bestimmen, so dass die folgende Abschätzung gilt
\begin{equation}\label{equation:odestability/ruhelagen:eq:residuum}
\begin{split}\|R(x)\| \leq \frac{\Lambda}{2c} \|x\|, \quad \forall \|x\| \leq r.\end{split}
\end{equation}
\sphinxAtStartPar
Dies liegt an der totalen Differenzierbarkeit des Vektorfelds \(F\) in der Ruhelage (vgl. Kapitel 6.2 in {[}\hyperlink{cite.references:id12}{Ten21}{]}), denn dies bedeutet, dass das Residuum in der Nähe der Ruhelage schnell genug gegen Null konvergiert, so dass gilt
\begin{equation*}
\begin{split}\lim_{x\to 0} \frac{\|R(x)\|}{\|x\|} = \lim_{x\to 0}\frac{\|F(x)- (DF)(0)\cdot x\|}{\|x\|} = 0.\end{split}
\end{equation*}
\sphinxAtStartPar
Wir wollen im Folgenden zeigen, dass wenn der Anfangswert unserer unbekannten Lösung des Differentialgleichungssystems beschränkt ist durch
\begin{equation*}
\begin{split}\|x(0)\| \leq \epsilon <\frac{r}{c},\end{split}
\end{equation*}
\sphinxAtStartPar
dann soll schon für die Norm der Lösung für beliebiges \(t \geq 0\) gelten
\begin{equation*}
\begin{split}\|x(t)\| \leq c\epsilon e^{-\frac{\Lambda t}{2}}.\end{split}
\end{equation*}
\sphinxAtStartPar
Da \(c\epsilon e^{- \frac{\Lambda t}{2}} \leq c\epsilon < r <\tilde{r}\) gilt, liegt die Lösung somit noch in der offenen Kugel \(B_{{r^\ast}}(0) \subset U\) und konvergiert für \(t \rightarrow \infty\) gegen 0, was den Satz beweist.

\sphinxAtStartPar
Nehmen wir also an, dass \(\|x(0)\| \leq \epsilon <\frac{r}{c}\) gelte.
Nun können wir nach {\hyperref[\detokenize{odestability/ruhelagen:lem:intexpglgn}]{\sphinxcrossref{Lemma 2.1}}} die unbekannte Lösung durch ihre Linearisierung darstellen als
\begin{equation*}
\begin{split}x(t) = e^{At}x_0 + \int_0^t e^{A(t-s)} R(x(s))\, \mathrm{d}s.\end{split}
\end{equation*}
\sphinxAtStartPar
Nehmen wir also die Norm der unbekannten Lösung in dieser Darstellung und nutzen die Abschätzungen \eqref{equation:odestability/ruhelagen:eq:normexp} und \eqref{equation:odestability/ruhelagen:eq:residuum}, so erhalten wir
\begin{equation*}
\begin{split}\|x(t)\|\leq ce^{-\Lambda t}\|x_0\| + \int_0^tce^{-\Lambda (t-s)}\frac{\Lambda}{2c}\|x(s)\|\, \mathrm{d}s, \quad \forall \|x\| \leq r.\end{split}
\end{equation*}
\sphinxAtStartPar
Multiplizieren wir beide Seiten der Ungleichung mit \(e^{\Lambda t}\) und definieren uns eine Hilfsfunktion \(f(t):=e^{\Lambda t}\|x(t)\|\), dann erhalten wir
\begin{equation*}
\begin{split}f(t)\leq \underbrace{c\|x_0\|}_{=:a} + \int_0^t \underbrace{\frac{\Lambda}{2}}_{=:g(s)} f(s)\, \mathrm{d}s.\end{split}
\end{equation*}
\sphinxAtStartPar
Für diese Form der Ungleichung bietet es sich an das {\hyperref[\detokenize{odestability/ruhelagen:lemma:Gronwall}]{\sphinxcrossref{Lemma 2.2}}} zur Gronwall\sphinxhyphen{}Ungleichung anzuwenden, durch das wir schließlich folgendes Resultat bekommen
\begin{equation*}
\begin{split}f(t) \leq c \|x_0\| \exp{\left( \frac{1}{2} \int_0^t \Lambda \, \mathrm{d}s \right) }
\leq c \epsilon e^{\frac{\Lambda}{2} t} \leq r e^{\frac{\Lambda}{2} t}.\end{split}
\end{equation*}
\sphinxAtStartPar
Durch Multiplikation beider Seiten mit \(e^{-\Lambda t}\) führt dies zur finalen Abschätzung
\begin{equation*}
\begin{split} \|x(t)\|\leq re^{-\frac{\Lambda}{2}t}, \quad \forall t\in\R^+_0.\end{split}
\end{equation*}
\sphinxAtStartPar
Wir sehen also ein, dass die unbekannte Lösung für alle nicht\sphinxhyphen{}negativen Zeiten in der offenen Kugel \(B_r(0) \subset B_{{r^\ast}}(0) \subset U\) enthalten ist und offensichtlich gegen Null konvergiert.
Damit ist die Ruhelage \(0 \in U\) asymptotisch stabil.
\end{sphinxadmonition}

\sphinxAtStartPar
Folgende Bemerkung geht speziell auf ein Detail des Beweises ein, das eine Aussage zum Konvergenzradius der Lösungen eines dynamisches Systems zulässt.
\label{odestability/ruhelagen:remark-6}
\begin{sphinxadmonition}{note}{Remark 2.3 (Attraktionsbassin)}



\sphinxAtStartPar
Der Beweis von {\hyperref[\detokenize{odestability/ruhelagen:thm:stabasymallg}]{\sphinxcrossref{Theorem 2.2}}} liefert zusätzlich die Aussage, dass alle Punkte \(x\in U\) im Phasenraum mit
\begin{equation*}
\begin{split}\|x\| < \frac{r}{c}\end{split}
\end{equation*}
\sphinxAtStartPar
zu Orbits gehören, die gegen die Ruhelage \(0 \in U\) konvergieren.
Diesen attraktiven Einzugsbereich der Ruhelage nennt man auch das \sphinxstylestrong{Attraktionsbassin} der Ruhelage.
\end{sphinxadmonition}


\subsection{Lyapunov\sphinxhyphen{}Stabilität von Ruhelagen}
\label{\detokenize{odestability/ruhelagen:lyapunov-stabilitat-von-ruhelagen}}
\sphinxAtStartPar
Während ein hinreichendes Kriterium für das Vorliegen \sphinxstyleemphasis{asymptotischer Stabilität} die strikte Ungleichung \(Re(\lambda_i)<0\) für die Eigenwerte \(\lambda_i\) der Jacobi\sphinxhyphen{}Matrix war, ist die Situation bezüglich der Lyapunov\sphinxhyphen{}Stabilität einer Ruhelage \sphinxstylestrong{komplizierter}.
Hierzu wollen wir ein Resultat für den Fall von linearen dynamischen Systemen im Folgenden formulieren.
\label{odestability/ruhelagen:thm:stablyaplinear}
\begin{sphinxadmonition}{note}{Theorem 2.3 (Lyapunov\sphinxhyphen{}Stabilität von Ruhelagen)}



\sphinxAtStartPar
Sei \(A\in \R^{n\times n}\) eine Matrix mit den Eigenwerten \(\lambda_1,\dots, \lambda_n\in \C\).
Besitzen die Eigenwerte \(\lambda_i \in \C, i=1,\ldots,n\) von \(A\) einen nicht\sphinxhyphen{}positiven Realteil \(Re(\lambda_i) \leq 0\), und ist im Fall \(Re(\lambda_i)=0\) die geometrische Vielfachheit gleich der algebraischen Vielfachheit des Eigenwerts, dann ist \(0\in \R^n\) eine \sphinxstylestrong{Lyapunov\sphinxhyphen{}stabile} Ruhelage des dynamischen Systems, dass durch das lineare Differentialgleichungssystem
\begin{equation*}
\begin{split}\dot{x}(t) = Ax(t), \quad  \forall t \in I \subset \R^+_0\end{split}
\end{equation*}
\sphinxAtStartPar
charakterisiert wird.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Aus {\hyperref[\detokenize{odestability/ruhelagen:thm:stablin}]{\sphinxcrossref{Theorem 2.1}}} wissen wir bereits, dass im Fall eines linearen dynamischen Systems \(\vec{0} \in U\) eine Ruhelage im Phasenraum \(U \subset \R^n\) ist.
Seien \(\lambda_1, \ldots, \lambda_k \in \C\) für \(k \leq n\) die paarweise verschiedenen Eigenwerte der Matrix \(A\).
Wir betrachten wieder die Jordansche Normalform \(J = S^{-1}AS\) der Matrix \(A\) für Transformationsmatrizen \(S,S^{-1} \in \C^{n \times n}\) und
\begin{equation*}
\begin{split}J=
\begin{pmatrix}
J_{r_1}(\lambda_1)& & & 0\\
 & J_{r_2}(\lambda_2) & & \\
 & & \ddots & \\
 0 & & & J_{r_k}(\lambda_k)
\end{pmatrix}.\end{split}
\end{equation*}
\sphinxAtStartPar
Hierbei bezeichnen \(r_i \in \N, i=1,\ldots, k\) die algebraischen Vielfachheiten der zugehörigen Eigenwerte und jeder Jordanblock (vgl. Kapitel 2.7 in {[}\hyperlink{cite.references:id12}{Ten21}{]})) hat die Gestalt
\begin{equation*}
\begin{split} J_r(\lambda) \ \coloneqq \ \begin{pmatrix}
\lambda & 1 & & 0\\
 & \ddots & \ddots & \\
 & & \ddots & 1\\
 0 & & & \lambda
 \end{pmatrix} \in \C^{r\times r}\end{split}
\end{equation*}
\sphinxAtStartPar
Mit den Rechenregeln für das Matrixexponential aus {\hyperref[\detokenize{ode/repetition:rem:matrixexponentialregeln}]{\sphinxcrossref{Remark 1.3}}} folgt
\begin{equation*}
\begin{split}e^{Jt} = \begin{pmatrix}
\exp{(J_{r_1}(\lambda_1)t)} & & 0\\
 & \ddots & \\
 0& & \exp{(J_{r_k}(\lambda_k)t)}
 \end{pmatrix}.\end{split}
\end{equation*}
\sphinxAtStartPar
Betrachten wir nun die Norm der Lösungen des homogenen, linearen Differentialgleichungssystems für einen Startwert \(x_0 \in U\) mit
\begin{equation*}
\begin{split}\| \Phi_t(x_0) \| = \|e^{At}x_0\| = \|S^{-1}e^{Jt}S x_0\| \leq \|S^{-1}\| \|e^{Jt}\| \|S\| \|x_0\|,\end{split}
\end{equation*}
\sphinxAtStartPar
so sehen wir ein, dass die Ruhelage \(\vec{0} \in U\) \sphinxstylestrong{Lyapunov\sphinxhyphen{}stabil} ist wenn für alle Jordanblöcke \(J_{r_i}(\lambda_i), i=1,\ldots,k\) von \(J\) der Ursprung \(0\in \C^{r_i}\) eine Lyapunov\sphinxhyphen{}stabile Ruhelage des folgenden linearen Differentialgleichungssystems ist
\begin{equation*}
\begin{split} \dot{y}(t) = J_{r_i}(\lambda_i) y(t), \quad t \in I \subset \R^+_0.\end{split}
\end{equation*}
\sphinxAtStartPar
Dies ist bereits gegeben falls für einen Eigenwert \(Re(\lambda_i)<0\) gilt, denn damit folgt aus {\hyperref[\detokenize{odestability/ruhelagen:thm:stablin}]{\sphinxcrossref{Theorem 2.1}}} sogar schon \sphinxstylestrong{asymptotische Stabilität}, welche Lyapunov\sphinxhyphen{}Stabilität induziert.

\sphinxAtStartPar
Betrachten wir also nun einen komplexen Eigenwert \(\lambda_i \in \C\) von \(A\) mit \(Re(\lambda_i)=0\) und für den die geometrische Vielfachheit nach Vorraussetzung gleich der algebraischen Vielfachheit ist.
In diesem Fall ist der ihm zugeordnete Jordanblock eine Diagonalmatrix auf deren Hauptdiagonale der Eigenwert \(\lambda_i \in \C\) steht, da alle Jordankästchen eindimensional sind.
In diesem Fall sehen wir, dass die Norm des Matrixexponentials beschränkt ist und wir dadurch \sphinxstylestrong{Lyapunov\sphinxhyphen{}Stabilität} der Ruhelage gezeigt haben, da gilt
\begin{equation*}
\begin{split}\|e^{J_{r_i}(\lambda_i)t)}\| = |e^{\lambda_i t}| = |e^0e^{\mathcal{Im}(\lambda_i) t}| = |\cos{(\mathcal{Im}(\lambda_i)t)} + i \sin{(\mathcal{Im}(\lambda_i)t)}| = 1.\end{split}
\end{equation*}
\sphinxAtStartPar
Für diese Umformung haben wir die Definition der komplexen Exponentialfunktion genutzt, für die gilt:
\begin{equation*}
\begin{split}e^z = e^{x+iy} = e^xe^iy = e^x(\cos(y) + i\sin(y)), \quad \text{für } z = x+iy \in \C.\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Das folgende Beispiel illustriert, dass eine Ruhelage instabil werden kann, wenn die geometrische Vielfachheit nicht mit der algebraischen Vielfachheit übereinstimmt für einen Eigenwert \(\lambda =0\) der Koeffizientenmatrix \(A\).
\label{odestability/ruhelagen:example-8}
\begin{sphinxadmonition}{note}{Example 2.2}



\sphinxAtStartPar
Sei \(U \subset \R^2\) der Phasenraum und wir betrachten das homogene, lineare Differentialgleichungssystem
\begin{equation*}
\begin{split}\dot{x}(t) = A x(t), \quad \forall t \in \R_0^+\end{split}
\end{equation*}
\sphinxAtStartPar
für eine Koeffizientenmatrix
\begin{equation*}
\begin{split}A = \begin{pmatrix} 0&1\\0&0\end{pmatrix}.\end{split}
\end{equation*}
\sphinxAtStartPar
Wie man leicht nachrechnet besitzt diese Matrix den Eigenwert \(\lambda = 0\) mit algebraischer Vielfachheit \(2\) und geometrischer Vielfachheit \(1\) zum Eigenvektor \(v = (1,0)^T \in \R^2\).
Die Vielfachheiten des Eigenwert \sphinxstylestrong{stimmen} also \sphinxstylestrong{nicht überein}.

\sphinxAtStartPar
Aus {\hyperref[\detokenize{odestability/ruhelagen:thm:stablin}]{\sphinxcrossref{Theorem 2.1}}} wissen wir, dass eine Ruhelage in \(\vec{0} \in \R^2\) existiert.
Man sieht jedoch leicht ein, dass sogar jeder Punkt \(x_0 = (y, 0) \in U\) eine Ruhelage des Systems darstellt, da diese Punkte ein Vielfaches des Eigenvektors zum Eigenwert \(\lambda = 0\) darstellen und somit im Kern der Matrix \(A\) liegen, d.h., für diese Punkte ist die rechte Seite des Differentialgleichungssystems \(\vec{0} \in \R^2\) und somit liegt eine Ruhelage vor.

\sphinxAtStartPar
Wir wollen die Stabilität dieser Ruhelagen im Folgenden untersuchen.
Hierzu betrachten wir die Norm des Phasenflusses \(\Phi \colon I \times U \rightarrow U\), der für einen gegebenen Anfangswert \(x_0 = (y,z) \in U\) mit \(z \neq 0\) der die Lösung des Differentialgleichungssystems beschreibt mit
\begin{equation*}
\begin{split}\| \Phi_t(x_0) \| &= \| e^{At}x_0 \| = \| \sum_{k=0}^\infty \frac{(At)^k}{k!} x_0\| = \| [\underbrace{(At)^0}_{=I_2} + (At)^1] x_0\| \\
&= \| \begin{pmatrix} 1 & t \\ 0 & 1\end{pmatrix}\begin{pmatrix} y \\ z \end{pmatrix} \| = \| \begin{pmatrix} y + tz \\ z\end{pmatrix} \| \overset{t\to \infty}{\longrightarrow} \infty.\end{split}
\end{equation*}
\sphinxAtStartPar
Wir sehen also, dass für jeden Anfangswert \(x_0 = (y,z)\) mit \(z \neq 0\) die Lösung des Differentialgleichungssystems divergiert und somit ist jede Ruhelage des dynamischen Systems \sphinxstylestrong{instabil}.
\end{sphinxadmonition}

\sphinxAtStartPar
Leider kann man nicht wie im Fall der asymptotischen Stabilität vom linearen auf den nichtlinearen Fall schließen, wie das folgende Beispiel zeigt.
\label{odestability/ruhelagen:example-9}
\begin{sphinxadmonition}{note}{Example 2.3}



\sphinxAtStartPar
Wir betrachten eine gewöhnliche Differentialgleichung 1. Ordnung der Form
\begin{equation*}
\begin{split}\dot{x}(t) = \alpha x(t) + \beta x^3(t), \forall t \in \R^+_0.\end{split}
\end{equation*}
\sphinxAtStartPar
mit freien Parametern \(\alpha, \beta \in \R\).

\sphinxAtStartPar
Wie man einsieht ist \(0\) eine Ruhelage des dynamischen Systems, das durch diese Differentialgleichung charakterisiert wird.
Wir betrachten die Linearisierung der Differentialgleichung in der Ruhelage mit \(A := (DF)(0) = \alpha\) und erhalten
\begin{equation*}
\begin{split}\dot{x}(t) = A x(t) = \alpha x(t), \quad \forall t \in \R^+_0.\end{split}
\end{equation*}
\sphinxAtStartPar
Folgende Fallunterscheidung zeigt nun das Stabilitätsverhalten der Ruhelage in Abhängigkeit der gewählten Parameter \(\alpha, \beta \in \R\):


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline

\sphinxAtStartPar

&\sphinxstyletheadfamily 
\sphinxAtStartPar
linearisierte Gleichung
&\sphinxstyletheadfamily 
\sphinxAtStartPar
nicht lineare Gleichung
\\
\hline
\sphinxAtStartPar
\(\alpha<0\)
&
\sphinxAtStartPar
asymptotisch stabil
&
\sphinxAtStartPar
asymptotisch stabil
\\
\hline
\sphinxAtStartPar
\(\alpha>0\)
&
\sphinxAtStartPar
instabil
&
\sphinxAtStartPar
instabil
\\
\hline
\sphinxAtStartPar
\(\alpha=0\)
&
\sphinxAtStartPar
Lyapunov\sphinxhyphen{}stabil
&
\sphinxAtStartPar
asymptotisch stabil für \(\beta<0\)
\\
\hline
\sphinxAtStartPar

&
\sphinxAtStartPar

&
\sphinxAtStartPar
stabil für \(\beta =0 \)
\\
\hline
\sphinxAtStartPar

&
\sphinxAtStartPar

&
\sphinxAtStartPar
instabil \(\beta > 0\)
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
Wie man sieht hängt die Stabilität im nichtlinearen Fall nicht nur vom Parameter \(\alpha\), sondern ebenfalls von \(\beta\) ab, was eine Stabilitätsanalyse deutlich komplizierter macht.
\end{sphinxadmonition}


\chapter{Vektoranalysis}
\label{\detokenize{vektoranalysis/vektoranalysis:vektoranalysis}}\label{\detokenize{vektoranalysis/vektoranalysis::doc}}
\sphinxAtStartPar
In diesem Kapitel der Vorlesung führen wir wichtige Konzepte der \sphinxstyleemphasis{Vektoranalysis} ein.
Insbesondere schaffen wir die mathematischen Grundlagen für eine spezielle Art der mehrdimensionalen Integration, das Integrieren über sogenannte \sphinxstyleemphasis{Untermannigfaltigkeiten} des \(\R^n\).
Um diese Integration durchführen zu können, entwickeln wir das Kalkül der \sphinxstyleemphasis{Differentialformen} auf Mannigfaltigkeiten.

\sphinxAtStartPar
Dieses Kalkül lässt auch den geometrischen Gehalt physikalischer Theorien wie Elektrodynamik oder Allgemeine Relativitätstheorie klar hervortreten.
So lassen sich beispielsweise die Maxwellschen Gleichungen der Elektrodynamik mit Hilfe des Differentialformenkalkül elegant beschreiben.

\sphinxAtStartPar
Als zusätzliche Literatur und Referenz für diese Thematiken empfehlen wir das Buch von Agricola und Friedrich {[}\hyperlink{cite.references:id13}{AF13}{]}.


\section{Multilinearformen}
\label{\detokenize{vektoranalysis/multilinear:multilinearformen}}\label{\detokenize{vektoranalysis/multilinear:s-multilinearformen}}\label{\detokenize{vektoranalysis/multilinear::doc}}
\sphinxAtStartPar
In diesem Abschnitt wollen wir die Definition der sogenannten \sphinxstyleemphasis{Multilinearformen} einführen.
Für beliebige Vektorräume \(\V, W\) über einem Körper \(\K\) haben Sie bereits den Begriff der \sphinxstyleemphasis{Linearform}, also einer linearen Abbildung \(\varphi:\V\rightarrow W\) kennengelernt.
Die Idee der Multilinearform ist anstatt nur einem, gleich \(k\)\sphinxhyphen{}viele Vektorräume \(V_1,\ldots,V_k\) für \(k \in \N\) über \(\K\) zu betrachten und das Konzept der Linearität auf eine Abbildung \(\varphi:\V_1\times\ldots\V_k\rightarrow W\) zu übertragen.

\sphinxAtStartPar
Zur Vereinfachung werden wir im Folgenden nur den Körper \(\K=\R\) betrachten, in den meisten Fällen lassen sich die hier beschriebenen Konzepte aber direkt auf allgemeine Körper übertragen.
Wir beginnen zunächst mit einer Wiederholung und betrachten die schon bekannten Linearformen.
Insbesondere soll der nächste Abschnitt die verschiedenen Begriffe des Dualraums abgrenzen.


\subsection{Dualräume}
\label{\detokenize{vektoranalysis/multilinear:dualraume}}
\sphinxAtStartPar
Für einen reellen Vektorraum \(\V\) wollen wir lineare Abbildungen \(\varphi:V\to\R\) betrachten.
Diese lassen sich mit Hilfe der folgenden Definition zum algebraischen Dualraum zusammenfassen.
\label{vektoranalysis/multilinear:def:algebraischerDualraum}
\begin{sphinxadmonition}{note}{Definition 3.1 (Algebraischer Dualraum)}



\sphinxAtStartPar
Es sei \(\V\) ein beliebiger \(\R\)\sphinxhyphen{}Vektorraum.
Dann nennen wir die Menge
\begin{equation*}
\begin{split}\V^\ast := \{\varphi:\V\rightarrow\R: \varphi\text{ ist linear}\}\end{split}
\end{equation*}
\sphinxAtStartPar
den \sphinxstylestrong{algebraischer Dualraum} zu \(V\).
\end{sphinxadmonition}

\sphinxAtStartPar
Aus {[}\hyperlink{cite.references:id12}{Ten21}{]} ist bereits der Begriff des \sphinxstyleemphasis{topologischen Dualraums} bekannt, welcher allerdings eine etwas restriktivere Definition hat.
Sie fordert nämlich noch zusätzlich die Stetigkeit der linearen Abbildungen.
\label{vektoranalysis/multilinear:def:topologischerDualraum}
\begin{sphinxadmonition}{note}{Definition 3.2 (Topologischer Dualraum)}



\sphinxAtStartPar
Es sei \(\V\) ein normierter \(\R\)\sphinxhyphen{}Vektorraum für einen Körper \(\R\).
Dann nennen wir die Menge
\begin{equation*}
\begin{split}\V^\prime := \{\varphi:\V\rightarrow\R: \varphi\text{ ist linear und stetig}\}\end{split}
\end{equation*}
\sphinxAtStartPar
den \sphinxstylestrong{topologischer Dualraum} zu \(V\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{danger}{Danger:}
\sphinxAtStartPar
Der algebraische Dualraum ist im Allgemeinen nicht gleich dem topologischen Dualraum.
Der Hauptzweck dieses Abschnitts ist es diese Tatsache klar zu machen und die Unterschiede der beiden Definitionen herauszustellen.
\end{sphinxadmonition}

\sphinxAtStartPar
Der Integraloperator ist ein typisches Beispiel für einen linearen stetigen Operator.
\label{vektoranalysis/multilinear:example-2}
\begin{sphinxadmonition}{note}{Example 3.1 (Integraloperator)}



\sphinxAtStartPar
Es sei \(\V := C([0,1])\) der Funktionenraum der stetigen Funktionen auf dem Intervall \([0,1] \subset \R\).
Dann ist der durch \(T \colon C([0,1]) \rightarrow \R\) definierte Integraloperator mit
\begin{equation*}
\begin{split}T(f) := \int_0^1 f(x) \, \mathrm{d}x\end{split}
\end{equation*}
\sphinxAtStartPar
ein Element des \sphinxstyleemphasis{topologischen Dualraums}, d.h. \(T \in \V^\prime\), da man zeigen kann, dass er linear und stetig ist.
\end{sphinxadmonition}

\sphinxAtStartPar
Folgende Bemerkung sagt etwas über die minimale Struktur, die der Vektorraum \(V\) haben muss, damit die Definition des topologischen Dualraums sinnvoll ist.
\label{vektoranalysis/multilinear:remark-3}
\begin{sphinxadmonition}{note}{Remark 3.1}



\sphinxAtStartPar
Damit die {\hyperref[\detokenize{vektoranalysis/multilinear:def:topologischerDualraum}]{\sphinxcrossref{Definition 3.2}}} sinnvoll ist, ist es in der Tat nicht notwendig, dass \(V\) ein normierter Raum ist. Es reicht anzunehmen, dass \(\V\) ein \sphinxstyleemphasis{topologischer Vektorraum} ist.
\end{sphinxadmonition}

\sphinxAtStartPar
Durch Vergleichen von {\hyperref[\detokenize{vektoranalysis/multilinear:def:algebraischerDualraum}]{\sphinxcrossref{Definition 3.1}}} und {\hyperref[\detokenize{vektoranalysis/multilinear:def:topologischerDualraum}]{\sphinxcrossref{Definition 3.2}}} erkennt man sofort, dass stets \(\V^\prime\subset \V^\ast\) gilt.
Außerdem stellt man fest, dass die beiden Räume im endlich\sphinxhyphen{}dimensionalen Fall überein stimmen, wie folgendes Lemma aussagt.
\label{vektoranalysis/multilinear:lemma-4}
\begin{sphinxadmonition}{note}{Lemma 3.1}



\sphinxAtStartPar
Für \(n\in\N\) sei \(\V\) ein \(n\)\sphinxhyphen{}dimensionaler \(\R\)\sphinxhyphen{}Vektorraum, dessen Norm durch das Standardskalarprodukt induziert ist.
Dann gilt
\begin{equation*}
\begin{split}V^\prime = V^\ast.\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. In der Hausaufgabe zu zeigen.
\end{sphinxadmonition}

\sphinxAtStartPar
Das folgende Beispiel aus der Funktionalanalysis erklärt, dass die Gleichheit von algebraischen und topologischen Dualräumen nicht mehr in unendlich\sphinxhyphen{}dimensionalen Räumen gilt.
\label{vektoranalysis/multilinear:example-5}
\begin{sphinxadmonition}{note}{Example 3.2 (Differentialoperator)}



\sphinxAtStartPar
Sei \(\V := C^1([0,1])\) der Vektorraum der stetig differenzierbaren Funktionen auf dem Intervall \([0,1] \subset \R\).
Wir betrachten im Folgenden den \sphinxstyleemphasis{Differentialoperator}
\begin{equation*}
\begin{split}D \colon V &\rightarrow \R \\
(Df)(x) &\mapsto f'(x), \quad \forall x \in [0,1].\end{split}
\end{equation*}
\sphinxAtStartPar
Bekanntermaßen ist der Differentialoperator \(D\) \sphinxstylestrong{linear} und ist somit ein Element des algebraischen Dualraums, d.h., \(D \in V^\ast\).
Statten wir den Vektorraum \(C^1([0,1])\) mit der \sphinxstyleemphasis{Supremumsnorm}
\begin{equation*}
\begin{split}||f||_\infty := \sup_{x \in [0,1]} |f(x)|\end{split}
\end{equation*}
\sphinxAtStartPar
aus und betrachten die Funktionenfolge \(f_n(x) := x^n\), dann sehen wir ein, dass die Supremumsnorm der Folge konstant ist mit \(||f_n||_\infty \equiv 1\) für alle \(n\in\N\).
Für den Differentialoperator \(D\) gilt jedoch
\begin{equation*}
\begin{split}||Df_n||_\infty = \sup_{x \in [0,1]} |(Df_n)(x)| = \sup_{x \in [0,1]} |f_n'(x)| = \sup_{x \in [0,1]} |nx^{n-1}| = n.\end{split}
\end{equation*}
\sphinxAtStartPar
Um die \sphinxstyleemphasis{Stetigkeit} des Differentialoperators zu untersuchen betrachten wir die konstante Nullfunktion \(F_0 \in V\) mit \(F_0(x) \equiv 0\) für alle \(x \in [0,1]\).
Vergleichen wir nun den Abstand der konstanten Nullfunktionen zum ersten Folgenglied \(f_1\) unserer Funktionenfolge, so erhalten wir erwartungsgemäß
\begin{equation*}
\begin{split}||f_1 - F_0||_\infty = ||f_1||_\infty = ||x^1||_\infty = 1 < \frac{3}{2} =: \delta.\end{split}
\end{equation*}
\sphinxAtStartPar
Für den Differenzialoperator erhalten wir analog
\begin{equation*}
\begin{split}||Df_1 - DF_0||_\infty = ||Df_1||_\infty = ||1||\infty < \frac{3}{2} =: \epsilon.\end{split}
\end{equation*}
\sphinxAtStartPar
Wäre der Differenzialoperator \(D\) stetig, so müsste nach dem \(\epsilon-\delta\)\sphinxhyphen{}Kriterium nun für jedes Folgenglied \(f_n\) unserer Funktionenfolge \(||Df_n - DF_0|| < \epsilon\) gelten, da der Abstand kleiner \(\delta\) ist wegen
\begin{equation*}
\begin{split}||f_n - F_0||_\infty = ||f_n||_\infty = ||x^n||_\infty = 1 < \delta.\end{split}
\end{equation*}
\sphinxAtStartPar
Jedoch sehen wir, dass die Folge der Ableitungen divergiert, d.h.,
\begin{equation*}
\begin{split}||Df_n - DF_0||_\infty = ||Df_n||_\infty = ||nx^{n-1}||_\infty = n > \epsilon \quad \text{für } n\geq 2.\end{split}
\end{equation*}
\sphinxAtStartPar
Wir sehen also ein, dass der Differentialoperator \sphinxstylestrong{nicht stetig} ist und somit kein Element des topologischen Dualraums \(V'\) sein kann.
Damit haben wir gezeigt, dass in unendlich\sphinxhyphen{}dimensionalen Räumen \(V' \subsetneq V^\ast\) gilt.
\end{sphinxadmonition}


\subsection{k\sphinxhyphen{}Multilinearformen}
\label{\detokenize{vektoranalysis/multilinear:k-multilinearformen}}\label{\detokenize{vektoranalysis/multilinear:s-k-multilinearform}}
\sphinxAtStartPar
Nachdem wir uns den Begriff der Linearität ins Gedächtnis zurückgerufen haben und Dualräume erklärt haben, wollen wir was Konzept linearer Abbildungen in der folgenden Definition verallgemeinern.
\label{vektoranalysis/multilinear:def:multilinear}
\begin{sphinxadmonition}{note}{Definition 3.3 (k\sphinxhyphen{}Multilinearität)}



\sphinxAtStartPar
Sei \(k \in \N\) und es seien \(\V_i, i=1,\ldots,k\), sowie \(W\) reelle Vektorräume.

\sphinxAtStartPar
Wir nennen eine Abbildung
\begin{equation*}
\begin{split}\varphi : \V_1\times\ldots\times \V_k\ \to W\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{k\sphinxhyphen{}(multi)linear}, falls alle zugehörigen partiellen Abbildungen \(\varphi_i\) für \(i\in\{1,\ldots,k\}\) mit
\begin{equation*}
\begin{split}\varphi_i \colon V_i &\to W\\
x&\mapsto \varphi_i(x):= \varphi(z_1,\ldots, z_{i-1}, x, z_{i+1},\ldots,z_k)\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstyleemphasis{linear} sind.

\sphinxAtStartPar
Die Menge aller \(k\)\sphinxhyphen{}linearen Abbildungen wird mit \(L^k(\V_1\times\ldots\times \V_k; W)\) bezeichnet.
Falls alle Vektorräume übereinstimmen, d.h., \(\V_i = \V\) für alle \(i=1,\ldots,k\) gilt, so schreibt man auch \(L^k(\V\times\ldots\times \V; W) =: L^k(\V; W)\).
\end{sphinxadmonition}
\label{vektoranalysis/multilinear:remark-7}
\begin{sphinxadmonition}{note}{Remark 3.2}



\sphinxAtStartPar
Ausgeschrieben bedeutet die Bedingung in der obigen Definition, dass für beliebige Vektoren \(x,y\in \V_i\) und Skalare \(\lambda \in \R\) gilt
\begin{equation*}
\begin{split}\varphi(z_1,\ldots,z_{i-1},\lambda \cdot x, z_{i+1},\ldots,z_k) = \lambda \cdot \varphi(z_1,\ldots,z_{i-1}, x, z_{i+1}, \ldots,z_k)\end{split}
\end{equation*}
\sphinxAtStartPar
und
\begin{equation*}
\begin{split}\varphi(z_1,\ldots,z_{i-1},x+y,z_{i+1},\ldots,z_k) = \varphi(z_1,\ldots,x,\ldots,z_k) + \varphi(z_1,\ldots,y,\ldots,z_k).\end{split}
\end{equation*}
\sphinxAtStartPar
für jedes Argument \(i = 1,\ldots,k\) der Abbildung \(\varphi \colon V_1 \times \ldots \times \V_k \rightarrow W\).
\end{sphinxadmonition}

\sphinxAtStartPar
Viele multilineare Abbildungen kennen wir bereits aus der Linearen Algebra ohne sie bisher so bezeichnet zu haben.
Im folgenden Beispiel wiederholen wir einige bekannte Beispiele unter dem Aspekt der Multilinearität.
\label{vektoranalysis/multilinear:ex:multilinear}
\begin{sphinxadmonition}{note}{Example 3.3}



\sphinxAtStartPar
Wir betrachten im Folgenden Beispiele für \(k\)\sphinxhyphen{}lineare Abbildungen mit verschiedenen \(k\in\N\).

\sphinxAtStartPar
\sphinxstylestrong{\(k=1\)}: In diesem einfachen Fall sind alle Linearformen \(1\)\sphinxhyphen{}linear.
Daher ist der Raum der \(1\)\sphinxhyphen{}Linearformen gerade der algebraische Dualraum aus {\hyperref[\detokenize{vektoranalysis/multilinear:def:algebraischerDualraum}]{\sphinxcrossref{Definition 3.1}}}, d.h. es gilt \(L^1(\V; \R) = \V^\ast\).

\sphinxAtStartPar
\sphinxstylestrong{\(k=2\)}: Es sei \(\V=\R^n\) der Euklidische Vektorraum mit kanonischem innerem Produkt \(\langle\cdot,\cdot\rangle\).
Für \(A\in\R^{n,n}\) ist
\begin{equation*}
\begin{split}\varphi:\V\times \V &\to\R\\ 
(x,y) &\mapsto \varphi(x, y) :=\langle x,A y \rangle\end{split}
\end{equation*}
\sphinxAtStartPar
eine \sphinxstylestrong{Bilinearform} bzw. eine \(2\)\sphinxhyphen{}Linearform nach {\hyperref[\detokenize{vektoranalysis/multilinear:def:multilinear}]{\sphinxcrossref{Definition 3.3}}}.
Sie heißt \sphinxstyleemphasis{symmetrisch}, falls
\begin{equation*}
\begin{split}\varphi(x, y) = \varphi(y, x), \quad \forall x, y\in \V\end{split}
\end{equation*}
\sphinxAtStartPar
und \sphinxstyleemphasis{antisymmetrisch} falls
\begin{equation*}
\begin{split}\varphi(x, y) = -\varphi(y, x), \quad \forall x, y\in \V.\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{\(k=n\)}: Es sei \(n\in \N\) und \(\V=\R^n\) der Euklidische Vektorraum.
Die \(n\)\sphinxhyphen{}lineare Abbildung
\begin{equation*}
\begin{split}\varphi :\V \times \ldots \times \V &\to\R\\ 
(z_1, \ldots, z_n) &\mapsto \varphi(z_1,\ldots,z_n) := \det([z_1,\ldots,z_n])\end{split}
\end{equation*}
\sphinxAtStartPar
heißt \sphinxstylestrong{Determinantenform}.
Wir beachten, dass hierbei jedes \(z_i \in \R^n\) für \(i=1,\ldots,n\) ein Vektor ist und es sich bei \([z_1,\ldots,z_n] \in \R^{n\times n}\) um eine Matrix handelt.
Die Determinantenform gibt das orientierte Volumen des von den Vektoren \(z_1,\ldots,z_n\) aufgespannten Parallelotops an.
\end{sphinxadmonition}


\subsection{Der Vektorraum der Multilinearformen}
\label{\detokenize{vektoranalysis/multilinear:der-vektorraum-der-multilinearformen}}
\sphinxAtStartPar
Die Menge der \(k\)\sphinxhyphen{}linearen Abbildung \(L^k(V_1 \times \ldots \times V_k; W)\) für \(\R\)\sphinxhyphen{}Vektorräume \(V_1,\ldots,V_k\) und \(W\) besitzt mehr Struktur als wir ihr bisher angesehen haben.
Mit den entsprechenden Verknüpfungen handelt es sich ebenfalls um einen Vektorraum, wie das folgende Lemma zeigt.
\label{vektoranalysis/multilinear:lemma-9}
\begin{sphinxadmonition}{note}{Lemma 3.2}



\sphinxAtStartPar
Sei \(k \in \N\) und es seien \(\V_1,\ldots,\V_k\) sowie \(W\) reelle Vektorräume.
Dann ist die Menge \(L^k(\V_1\times\ldots\V_k; W)\) ein Vektorraum über \(\R\) bezüglich der Addition
\begin{equation*}
\begin{split}(\varphi_1+\varphi_2)(z_1,\ldots,z_k) := \varphi_1(z_1,\ldots,z_k) +
\varphi_2(z_1,\ldots,z_k),\end{split}
\end{equation*}
\sphinxAtStartPar
für \(k\)\sphinxhyphen{}lineare Abbildungen \(\varphi_1,\varphi_2\in L^k(\V_1 \times \ldots \times V_k;W)\) und der Multiplikation mit Skalaren \(\lambda \in \R\)
\begin{equation*}
\begin{split}(\lambda\varphi)(z_1,\ldots,z_k) := \lambda\big(\varphi(z_1,\ldots,z_k)\big),\quad\varphi\in L^k(\V_1 \times \ldots \times V_k;W).\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. In der Hausaufgabe zu zeigen.
\end{sphinxadmonition}

\sphinxAtStartPar
Wir wir bereits in {\hyperref[\detokenize{vektoranalysis/multilinear:ex:multilinear}]{\sphinxcrossref{Example 3.3}}} gesehen haben erhalten wir einen wichtigen Spezialfall für \(k=1\), nämlich den algebraischen Dualraum \(V^\ast = L^1(\V;\R)\).
Für diesen Vektorraum können wir eine spezielle Basis angeben, wie das folgende Lemma zeigt.
\label{vektoranalysis/multilinear:lem:dualeBasis}
\begin{sphinxadmonition}{note}{Lemma 3.3 (Duale Basis)}



\sphinxAtStartPar
Es sei \(\V\) ein \(n\)\sphinxhyphen{}dimensionaler \(\R\)\sphinxhyphen{}Vektorraum mit einer endlichen Basis \(B = (b_1,\ldots,b_n)\).
Für beliebige Vektoren \(z \in V\) bilden die Abbildungen \(\eta_j:\V\rightarrow\R\) für \(j=1,\ldots,n\) mit
\begin{equation*}
\begin{split}\eta_j(z) := \eta_j\left(\sum_{i=1}^n \alpha_i b_i\right) := \alpha_j\end{split}
\end{equation*}
\sphinxAtStartPar
eine Basis des algebraischen Dualraums \(\V^\ast\).
Diese spezielle Basis wird auch die \sphinxstylestrong{duale Basis} zur Basis \(B\) genannt.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Wir zeigen zunächst, dass \(\eta_j\in\V^\ast\) für \(j=1,\ldots,n\).
Dazu seien \(x,y\in\V\) beliebige Vektoren.
Dann existieren Koeffizienten \(\alpha_i^x,\alpha_i^y \in \R\) für \(i=1,\ldots,n\), so dass es eine eindeutige Darstellung als Linearkombination der Basisvektoren gibt mit
\begin{equation*}
\begin{split}x = \sum_{i=1}^n \alpha_i^x b_i, \qquad y = \sum_{i=1}^n \alpha_i^y b_i.\end{split}
\end{equation*}
\sphinxAtStartPar
Somit haben wir also für die Summe der Vektoren
\begin{equation*}
\begin{split}\eta_j(x+y) &= 
\eta_j\left(\sum_{i=1}^n \alpha_i^x b_i + \sum_{i=1}^n \alpha_i^y b_i\right) = 
\eta_j\left(\sum_{i=1}^n \alpha_i^x b_i + \alpha_i^y b_i\right) = 
\eta_j\left(\sum_{i=1}^n (\alpha_i^x + \alpha_i^y) b_i\right) 
\\&= \alpha_i^x + \alpha_i^y = 
\eta_j\left(\sum_{i=1}^n \alpha_i^x b_i\right)  + \eta_j\left(\sum_{i=1}^n \alpha_i^y b_i\right) = 
\eta_j(x) + \eta_j(y).\end{split}
\end{equation*}
\sphinxAtStartPar
Weiterhin gilt für beliebige Skalare \(\lambda\in\R\)
\begin{equation*}
\begin{split}\eta_j(\lambda x) = \eta_j\left(\lambda \sum_{i=1}^n \alpha_i^x b_i\right) = 
\eta_j\left(\sum_{i=1}^n (\lambda \alpha_i^x) b_i\right) =
\lambda \alpha_i^x =
\lambda \eta_j(x).\end{split}
\end{equation*}
\sphinxAtStartPar
Damit haben wir also gezeigt, dass die Elemente der dualen Basis linear sind und somit gilt \(\eta_j \in V^\ast\) für \(j=1,\ldots,n\).

\sphinxAtStartPar
Sei nun \(\phi\in \V^\ast\), dann gilt
\begin{equation*}
\begin{split}\phi(x) = \phi\left(\sum_{i=1}^n \alpha_i^x b_i\right) = \sum_{i=1}^n \alpha_i^x \phi(b_i) = 
\sum_{i=1}^n \eta_i(x) \phi(b_i),\end{split}
\end{equation*}
\sphinxAtStartPar
insbesondere gilt also \(\phi = \sum_{i=1}^n \phi(b_i) \eta_i\).

\sphinxAtStartPar
Somit bilden die Abbildungen \(\eta_j, j=1,\ldots, n\) ein Erzeugendensystem von \(V^\ast\), da jede lineare Abbildung \(\phi \in V^\ast\) als Linearkombination dargestellt werden kann.

\sphinxAtStartPar
Um zu zeigen, dass es sogar um eine Basis des algebraischen Dualraums handelt, müssen wir noch zeigen, dass das Nullelement des Vektorraums eine eindeutige Darstellung besitzt, da dies impliziert, dass die Elemente des Erzeugendensystems linear unabhängig sind.
Seien also Koeffizienten \(a_i\in\R\) gegeben, so dass \(0 = \sum_{i=1}^n a_i \eta_i\) die Nullabbildung realisiert.
Dann folgt schon für jedes \(j=1,\ldots,n\)
\begin{equation*}
\begin{split}0 = \left(\sum_{i=1}^n a_i \eta_i\right)(b_j) = \sum_{i=1}^n a_i \underbrace{\eta_i(b_j)}_{=\delta_{ij}} = a_j.\end{split}
\end{equation*}
\sphinxAtStartPar
Offensichtlich kann die Nullabbildung nur erzeugt werden, wenn für alle Koeffizienten \(a_i=0\) gilt für \(i=1,\ldots,n\) und damit ist die Aussage bewiesen.
\end{sphinxadmonition}

\sphinxAtStartPar
Folgende Bemerkungen wollen wir zum gerade diskutierten Lemma festhalten.
\label{vektoranalysis/multilinear:remark-11}
\begin{sphinxadmonition}{note}{Remark 3.3}



\sphinxAtStartPar
1. Die Aussage aus {\hyperref[\detokenize{vektoranalysis/multilinear:lem:dualeBasis}]{\sphinxcrossref{Lemma 3.3}}} zeigt insbesondere, dass im \sphinxstylestrong{endlich\sphinxhyphen{}dimensionalen} Fall \(\dim(\V) = \dim(\V^\ast)\).
Die Vektorräume sind also isomorph zueinander.

\sphinxAtStartPar
2. Die Aussage des {\hyperref[\detokenize{vektoranalysis/multilinear:lem:dualeBasis}]{\sphinxcrossref{Lemma 3.3}}} zur dualen Basis lässt sich ebenfalls auf den Fall eines \sphinxstylestrong{unendlich\sphinxhyphen{}dimensionalen} Vektorraums übertragen.
Hierfür erinnern wir daran, dass für einen Vektorraum \(V\) stets eine Basis \(B = \{b_i:i\in I\}\subset V\) existiert, wobei \(I\) eine (nicht notwendigerweise endliche) Indexmenge ist.
Insbesondere bemerken wir, dass wir hier von einer \sphinxstylestrong{Hamelbasis} sprechen, d.h., für jedes Element \(v\in V\) gibt es eindeutig bestimmte Koeffizienten \(\alpha_i, i\in I\), so dass gilt
\begin{equation*}
\begin{split}v = \sum_{i\in I} \alpha_i b_i.\end{split}
\end{equation*}
\sphinxAtStartPar
Der wichtige Punkt hierbei ist, dass nur \sphinxstylestrong{endlich viele} Koeffizienten \(\alpha_i\) ungleich null sind und die Summation somit keine eigentlich unendliche Reihe beschreibt, sondern nur eine endliche Summe.
Diese Konzept ist insbesondere verschieden vom Begriff der \sphinxhref{https://de.wikipedia.org/wiki/Schauderbasis}{Schauderbasis}
\end{sphinxadmonition}

\begin{sphinxShadowBox}
\sphinxstylesidebartitle{Georg Hamel}

\sphinxAtStartPar
\sphinxhref{https://de.wikipedia.org/wiki/Georg\_Hamel}{Georg Karl Wilhelm Hamel} (Geboren 12. September 1877 in Düren; Gestorben 4. Oktober 1954 in Landshut) war ein deutscher Mathematiker.
\end{sphinxShadowBox}

\begin{sphinxShadowBox}
\sphinxstylesidebartitle{Juliusz Schauder}

\sphinxAtStartPar
\sphinxhref{https://de.wikipedia.org/wiki/Juliusz\_Schauder}{Juliusz Paweł Schauder} (Geboren 21. September 1899 in Lemberg; Gestorben September 1943) war ein polnischer Mathematiker.
\end{sphinxShadowBox}

\sphinxAtStartPar
Wir wollen uns das Konzept der dualen Basis im Falle des Euklidischen Vektorraums klar machen im Folgenden.
\label{vektoranalysis/multilinear:example-12}
\begin{sphinxadmonition}{note}{Example 3.4 (Duale Basis)}



\sphinxAtStartPar
Sei \(V = \R^n\) der Euklidische Vektorraum ausgestattet mit der Standard Einheitsbasis \(B = (e_i)_{i=1,\ldots,n}\).
Dann lässt sich jeder Vektor \(x \in V\) eindeutig als Linearkombination der Einheitsvektoren schreiben mit
\begin{equation*}
\begin{split}x = \sum_{i=1}^n \alpha_i^x e_i = \sum_{i=1}^n x_i e_i.\end{split}
\end{equation*}
\sphinxAtStartPar
Wir sehen also ein, dass die Koeffizienten \(\alpha_i^x\) gerade die Einträge des Vektors \(x\) selbst sind.
Da die duale Basis des algebraischen Dualraums \(V^\ast\) zur Basis \(B\) nach {\hyperref[\detokenize{vektoranalysis/multilinear:lem:dualeBasis}]{\sphinxcrossref{Lemma 3.3}}} gerade die Koeffizienten \(\alpha_i^x\) liefern soll, ist klar, dass die entsprechenden linearen Abbildungen durch eine \sphinxstylestrong{Linksmultiplikation mit den transponierten Einheitsvektoren} gegeben sind, d.h., \(\eta_j(x) := e_j^T x = \langle e_j, x \rangle\), denn es gilt
\begin{equation*}
\begin{split}\eta_j(x) = 
\eta_j \left( \sum_{i=1}^n \alpha_i^x e_i \right) = 
\langle e_j, \sum_{i=1}^n x_i e_i\rangle =
\sum_{i=1}^n x_i \underbrace{\langle e_j, e_i\rangle}_{= \delta_{ij}} =  
x_j = \alpha_j^x, \quad \forall j=1,\ldots,n.\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Wir halten abschließend fest, dass sich der \sphinxstylestrong{Bidualraum} \(V^{\ast\ast} := (V^\ast)^\ast\), d.h., der duale Raum des Dualraums \(V^\ast\), im endlich\sphinxhyphen{}dimensionalen Fall leicht charakterisieren lässt.
\label{vektoranalysis/multilinear:rem:doubledual}
\begin{sphinxadmonition}{note}{Remark 3.4}



\sphinxAtStartPar
Für \(n \in \N\) sei \(\V\) ein \(n\)\sphinxhyphen{}dimensionaler reeller Vektorraum.
Dann gilt, dass die Abbildung
\begin{equation*}
\begin{split}\Psi :\V &\rightarrow \V^{\ast\ast}\\
x &\mapsto \Psi_x \quad \text{ mit } \quad \Psi_x(\varphi) := \varphi(x).\end{split}
\end{equation*}
\sphinxAtStartPar
ein Isomorphismus ist.
\end{sphinxadmonition}


\section{Tensoren und Tensorprodukte}
\label{\detokenize{vektoranalysis/tensor:tensoren-und-tensorprodukte}}\label{\detokenize{vektoranalysis/tensor::doc}}
\sphinxAtStartPar
In diesem Kapitel widmen wir uns einem für die Physik sehr wichtigen aber relativ abstrakten Thema der Vektoranalysis, nämlich \sphinxstyleemphasis{Tensoren} und \sphinxstyleemphasis{Tensorprodukten}.
Der Begriff hat sehr viele verschiedene Anschauungsmöglichkeiten (siehe \sphinxhref{https://de.wikipedia.org/wiki/Tensorprodukt}{Wikipedia}) weshalb es nicht leicht ist eine Einführung zu geben die gleichzeitig allgemein, aber auch verständlich ist. Da Tensoren aber eine wichtige Rolle in der Physik spielen werden wir uns hier damit beschäftigen.


\subsection{Motivation}
\label{\detokenize{vektoranalysis/tensor:motivation}}
\sphinxAtStartPar
Wir betrachten zunächst ein konkretes Anwendungsbeispiel aus der Physik, welches auf Tensoren zurückgreift.
Hier wird der sogenannte \sphinxstyleemphasis{Cauchy Spannungstensor} verwendet.
\label{vektoranalysis/tensor:remark-0}
\begin{sphinxadmonition}{note}{Remark 3.5 (Begriffsherkunft)}



\sphinxAtStartPar
Der Begriff Tensor wurde von Hamilton in der Mitte des 19. Jahrhunderts eingeführt. Er leitete die Bezeichnung vom lateinischen \sphinxstyleemphasis{tendere} (spannen) ab, da die ursprüngliche Anwendung derartiger Objekte in der Elastizitätstheorie Anwendung fand.
\end{sphinxadmonition}

\begin{sphinxShadowBox}
\sphinxstylesidebartitle{Augustin Cauchy}

\sphinxAtStartPar
\sphinxhref{https://de.wikipedia.org/wiki/Augustin-Louis\_Cauchy}{Augustin\sphinxhyphen{}Louis Cauchy} (Geboren 21. August 1789 in Paris; Gestorben 23. Mai 1857 in Sceaux) war ein französischer Mathematiker.
\end{sphinxShadowBox}

\sphinxAtStartPar
Mechanische Spannung ist eine physikalische Größe, die die innere Beanspruchung und Kräfte in einem Volumen \(V\subset\R^3\) angibt, welche aufgrund einer äußeren Belastungen auftreten.
Die grundlegende Idee ist das \sphinxstylestrong{Euler\sphinxhyphen{}Cauchy Spannungsprinzip}, welches beschreibt, dass auf jede Schnittfläche \(A\subset\R^2\), die ein Volumen in zwei Teile trennt, von diesen zwei Volumenteilen eine Spannung auf \(A\) ausgeübt wird, welche durch einen sogenannten \sphinxstylestrong{Spannungsvektor} \(\mathbf{T}^{(n)}\) beschrieben wird.
Der Komponenten des Spannungsvektors haben hierbei die Dimension “Kraft pro Fläche”.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[height=250\sphinxpxdimen]{{stress_vector}.png}
\caption{Visualisierung für Normal\sphinxhyphen{} und Scherspannung an einer Schnittfläche. Quelle: \sphinxhref{https://en.wikipedia.org/wiki/Cauchy\_stress\_tensor}{Wikipedia; Cauchy Stress Tensor}.}\label{\detokenize{vektoranalysis/tensor:fig-stress}}\end{figure}

\sphinxAtStartPar
Wie in \hyperref[\detokenize{vektoranalysis/tensor:fig-stress}]{Fig.\@ \ref{\detokenize{vektoranalysis/tensor:fig-stress}}} visualisiert teilt sich die Spannung in zwei Komponenten auf:

\sphinxAtStartPar
\sphinxstylestrong{Normalspannung:}

\sphinxAtStartPar
Die Normalspannung \(\sigma_n\) ist der Teil des Spannungsvektors, der in Richtung der Normalen \(\mathbf{n}\) zeigt, welche orthogonal auf der Schnittfläche steht.

\sphinxAtStartPar
\sphinxstylestrong{Scherspannung:}

\sphinxAtStartPar
Die Scherspannung \(\tau_n\) ist der Teil des Spannungstensors, der parallel zur Schnittfläche liegt.

\sphinxAtStartPar
Man erkennt nun, dass die Spannung in \(V\) nicht durch einen einzigen Vektor ausgedrückt werden kann. Einerseits hängt sie vom betrachteten Punkt \(x\in V\) ab und zudem von der Orientierung der Schnittfläche. Allerdings hat Cauchy gezeigt, dass ein linearer Operator \(\mathbf{\sigma}(x)\) existiert, so dass
\begin{equation*}
\begin{split}\mathbf{T}^{(n)}(x) = \mathbf{\sigma}(x) \cdot n,\end{split}
\end{equation*}
\sphinxAtStartPar
d.h. in jedem Punkt \(x\in V\) ist der Stressvektor linear im Normalenvektor \(n\).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[height=250\sphinxpxdimen]{{stress_tensor_comp}.png}
\caption{Quelle: \sphinxhref{https://de.wikipedia.org/wiki/Spannungstensor}{Wikipedia; Spannungstensor}.}\label{\detokenize{vektoranalysis/tensor:fig-stress-comp}}\end{figure}

\sphinxAtStartPar
Der lineare Operator \(\mathbf{\sigma}\) wird auch \sphinxstylestrong{Cauchy Spannungstensor} genannt.
Um diesen besser zu verstehen betrachtet man für einen fixen Punkt \(x\) des Volumens einen infinitesimal kleinen, freigeschnittenen Würfel wie in \hyperref[\detokenize{vektoranalysis/tensor:fig-stress-comp}]{Fig.\@ \ref{\detokenize{vektoranalysis/tensor:fig-stress-comp}}}.
Nun definieren wir für die drei verschiedenen Flächen (orthogonal zu den Einheitsvektoren \(e_1, e_2\) und \(e_3\)) die Spannungsvektoren
\begin{equation*}
\begin{split}\mathbf{T}^{(e_i)}:= \sum_{j=1}^3 \sigma_{ij} e_j, \quad i \in \lbrace 1,2,3 \rbrace.\end{split}
\end{equation*}
\sphinxAtStartPar
So setzt sich beispielsweise der Spannungsvektor \(\mathbf{T}^{(e_1)}\) zusammen aus der Summe der Normalspannung \(\sigma_{11} e_1\) und den zwei Scherspannungskomponenten \(\sigma_{12} e_2\) und \(\sigma_{13} e_3\).

\sphinxAtStartPar
Insgesamt erhält man neun Spannungskomponenten \(\sigma_{ij}\) für \(i,j=1,2,3\) welche insgesamt den Spannungszustand im Punkt \(x\) als Spannungsvektoren in Richtung der Einheitsvektoren vollständig beschreiben.
Dies liegt daran, dass wir jeden Spannungsvektor in \(x\) als Linearkombination der drei Spannungsvektoren \(\mathbf{T}^{(e_i)}, i=1,2,3\) darstellen können.

\sphinxAtStartPar
Wir führen nun eine \sphinxstyleemphasis{multilineare Abbildung} \(\otimes \colon \R^n \times \R^m \rightarrow \R^{n \times m}\) für zwei beliebige Vektoren \(x\in\R^n\) und \(y\in\R^m\) ein, die das \sphinxstylestrong{dyadische Produkt} der Vektoren genannt wird und wie folgt definiert ist
\begin{equation*}
\begin{split}x \otimes y := 
\begin{pmatrix}
x_1y_1 &\ldots &x_1 y_m\\
\vdots &\ddots & \vdots\\
x_n y_1&\ldots& x_n y_m
\end{pmatrix}.\end{split}
\end{equation*}
\sphinxAtStartPar
Fassen wir nun zeilenweise die Spannungsvektoren \(\mathbf{T}^{(e_i)}, i=1,2,3\) in einer Matrix zusammen, so erhalten wir den Cauchy Spannungstensor \(\mathbf{\sigma}\) für den Punkt \(x\) des Volumens als
\begin{equation}\label{equation:vektoranalysis/tensor:eq:cauchySpannungstensor}
\begin{split}\mathbf{\sigma} := 
\begin{pmatrix}
\sigma_{11} & \sigma_{12} & \sigma_{13} \\
\sigma_{21} & \sigma_{22} & \sigma_{23} \\
\sigma_{31} & \sigma_{32} & \sigma_{33}
\end{pmatrix} 
&= 
\begin{pmatrix}
\mathbf{T}^{(e_1)} \\
\mathbf{T}^{(e_2)} \\
\mathbf{T}^{(e_3)}
\end{pmatrix}
= 
\begin{pmatrix}
\mathbf{T}^{(e_1)} \\
0 \\
0
\end{pmatrix}
+
\begin{pmatrix}
0 \\
\mathbf{T}^{(e_2)} \\
0
\end{pmatrix}
+
\begin{pmatrix}
0 \\
0 \\
\mathbf{T}^{(e_3)} \\
\end{pmatrix}\\
&=
\sum_{i=1}^3 e_i \otimes \mathbf{T}^{(e_i)} = \sum_{i=1}^3 e_i\otimes ( \sum_{j=1}^3 \sigma_{ij} e_j) =
\sum_{i=1}^3\sum_{j=1}^3 \sigma_{ij} (e_i\otimes e_j).\end{split}
\end{equation}
\sphinxAtStartPar
Wir werden später sehen, dass man die Idee, den Operator \(\sigma\) über das dyadische Produkt zu definieren, abstrahieren kann, was auf den allgemeinen Tensorbegriff führt.
\label{vektoranalysis/tensor:remark-1}
\begin{sphinxadmonition}{note}{Remark 3.6}



\sphinxAtStartPar
In der Tat handelt es sich bei dem Operator \(\sigma \colon \R^3 \rightarrow \R^3\) in \eqref{equation:vektoranalysis/tensor:eq:cauchySpannungstensor} nicht nur um einen Tensor, sondern genauer um ein \sphinxstylestrong{Tensorfeld}, dass jedem Punkt \(x\) des Volumens einen Spannungstensor zuordnet.
\end{sphinxadmonition}


\subsection{Das Tensorprodukt}
\label{\detokenize{vektoranalysis/tensor:das-tensorprodukt}}
\sphinxAtStartPar
Wir wollen nun das Tensorprodukt von Vektorräumen abstrakt einführen und es an späterer Stelle für konkrete Realisierungen diskutieren.
Hierbei wollen wir uns zunächst auf einen Spezialfall einschränken, der lediglich \sphinxstyleemphasis{zwei Vektorräume} berücksichtigt, um die zu Grunde liegenden wichtigen Konzepte klarer herauszustellen.
Es ist wichtig zu verstehen, dass die folgenden Definitionen sich mit dem Konzept der \(k\)\sphinxhyphen{}Multilinearität in {\hyperref[\detokenize{vektoranalysis/multilinear:s-multilinearformen}]{\sphinxcrossref{\DUrole{std,std-ref}{Multilinearformen}}}} auf \(k \in \N\) verschiedene \(\R\)\sphinxhyphen{}Vektorräume direkt verallgemeinern lassen.
\label{vektoranalysis/tensor:def:tensor}
\begin{sphinxadmonition}{note}{Definition 3.4 (Tensorprodukt)}



\sphinxAtStartPar
Es seien \(V\) und \(W\) zwei reelle Vektorräume.
Ein reeller Vektorraum \(X\) heißt \sphinxstylestrong{Tensorproduktraum} falls eine bilineare Abbildung \(\otimes:V\times W\rightarrow X\) existiert, so dass die folgende \sphinxstylestrong{universelle Eigenschaft} gilt:

\sphinxAtStartPar
Für jede Bilinearform \(\phi\in L^2(V\times W; Y)\) in einen beliebigen reellen Vektorraum \(Y\), existiert eine eindeutige lineare Abbildung
\(p \in L^1(X; Y)\), so dass gilt
\begin{equation}\label{equation:vektoranalysis/tensor:eq:universell}
\begin{split}\phi(v,w) = p(v\otimes w) = p(\otimes(v,w))\quad\forall (v,w)\in V\times W.\end{split}
\end{equation}
\sphinxAtStartPar
In diesem Fall schreibt man auch \(X = V \otimes W\).
Wir nennen die bilineare Abbildung \(\otimes\) \sphinxstylestrong{Tensorprodukt} und verwenden häufig für sie die Infix\sphinxhyphen{}Schreibweise \(v\otimes w := \otimes(v,w)\).
Elemente \(x \in X\) des Tensorproduktraums \(X = V \otimes W\) nennen wir \sphinxstylestrong{Tensoren}.
\end{sphinxadmonition}

\sphinxAtStartPar
Diese Definition erscheint auf den ersten Blick abstrakt und unverständlich.
Was ist jetzt also genau ein Tensorprodukt?

\sphinxAtStartPar
\sphinxstylestrong{Das Tensorprodukt ist universell:}

\sphinxAtStartPar
Wir haben in der {\hyperref[\detokenize{vektoranalysis/tensor:def:tensor}]{\sphinxcrossref{Definition 3.4}}} das kartesische Produkt \(\times\) benutzt welches eindeutig definiert ist.
Im Gegensatz dazu gibt es jedoch nicht \sphinxstyleemphasis{ein} Tensorprodukt \(\otimes\) oder \sphinxstyleemphasis{einen} Tensorproduktraum \(V\otimes W\).
Wir haben die Freiheit \(\otimes\) zu wählen und wann immer die universelle Eigenschaft erfüllt ist, heißt dann \(X = V\otimes W\) Tensorproduktraum.
Derartige Konzepte nennt man in der Algebra \sphinxstyleemphasis{universell}.
Betrachten wir hierzu ein kurzes Beispiel für unterschiedliche Realisierungen eines Tensorproduktes.
\label{vektoranalysis/tensor:ex:tensorproduktVarianten}
\begin{sphinxadmonition}{note}{Example 3.5 (Varianten eines Tensorprodukts)}



\sphinxAtStartPar
Wir betrachten in diesem Beispiel den Euklidischen Vektorraum \(V=W=\R^2\) und zwei Vektoren \(x, y \in \R^2\).
Nehmen wir zunächst das Tensorprodukt, dass durch das \sphinxstylestrong{dyadische Produkt} \(\otimes : \R^2 \times \R^2 \rightarrow \R^{2 \times 2}\) gegeben ist mit
\begin{equation*}
\begin{split}x \otimes y \, \coloneqq \,
\begin{pmatrix}
x_1y_1 & x_1y_2 \\
x_2y_1 & x_2y_2
\end{pmatrix}.\end{split}
\end{equation*}
\sphinxAtStartPar
Man sieht ein, dass der zugehörige \sphinxstyleemphasis{Tensorproduktraum} also \(\R^{2 \times 2} = \R^2 \otimes \R^2\) sein muss.
Anderseits erhält man den gleichen Tensorproduktraum, wenn man ein \sphinxstylestrong{alternatives Tensorprodukt} \(\otimes^*\) zum dyadischen Produkt definiert, welches lediglich die Reihenfolge der Komponenten von \(y\) vertauscht mit
\begin{equation*}
\begin{split}x \otimes^* y \, \coloneqq \,
\begin{pmatrix}
x_1y_2 & x_1y_1 \\
x_2y_2 & x_2y_1
\end{pmatrix}.\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstylestrong{Was bedeutet die universelle Eigenschaft?}

\sphinxAtStartPar
Wie wir weiter unten noch genauer beschreiben werden, stellt die universelle Eigenschaft eine wichtige Beziehung zwischen dem Raum der bilinearen Abbildungen auf \(V\times W\) und dem Raum der linearen Abbildungen von \(X = V\otimes W\) nach \(Y\) für ein Tensorprodukt \(\otimes\) her.
Für den Spezialfall \(Y = \R\) ist letzterer gerade der \sphinxstyleemphasis{algebraische Dualraum} des Tensorproduktraums.
Sofern wir das Tensorprodukt gegeben haben erhalten wir alle Bilinearformen also schon über einfache Linearformen auf \(V\otimes W\).

\sphinxAtStartPar
Das folgende einfache Beispiel soll uns helfen diese Beziehung besser zu verstehen.
\label{vektoranalysis/tensor:ex:universelleEigenschaft}
\begin{sphinxadmonition}{note}{Example 3.6 (Universelle Eigenschaft)}



\sphinxAtStartPar
Im Folgenden betrachten wir wieder den Euklidischen Vektorraum \(V=W=\R^2\) und zwei Vektoren \(x, y \in \R^2\).
Wie wir in {\hyperref[\detokenize{vektoranalysis/tensor:ex:tensorproduktVarianten}]{\sphinxcrossref{Example 3.5}}} festgestellt haben realisiert das dyadische Produkt
\begin{equation*}
\begin{split}\otimes \colon \R^2 \times \R^2 \rightarrow \R^2 \otimes \R^2 = \R^{2 \times 2} =: X\end{split}
\end{equation*}
\sphinxAtStartPar
mit
\begin{equation*}
\begin{split}x \otimes y \, \coloneqq \,
\begin{pmatrix}
x_1y_1 & x_1y_2 \\
x_2y_1 & x_2y_2
\end{pmatrix}.\end{split}
\end{equation*}
\sphinxAtStartPar
ein \sphinxstyleemphasis{Tensorprodukt} der Vektorräume \(V=W=\R^2\).
Wegen der \sphinxstyleemphasis{universellen Eigenschaft} muss nun gelten, dass für jede Bilinearform \(\Phi \in L^2(V \times W; Y)\) für beliebige \(\R\)\sphinxhyphen{}Vektorräume \(Y\) eine eindeutige lineare Abbildung \(p \in L^1(X; Y)\) existiert, die äquivalent im Sinne von \eqref{equation:vektoranalysis/tensor:eq:universell} ist.

\sphinxAtStartPar
Nehmen wir also beispielsweise das Skalarprodukt \(\langle \cdot, \cdot \rangle \colon V \times W \rightarrow \R\) als eine mögliche Bilinearform \(\Phi \in L^2(V \times W; Y)\) mit
\begin{equation*}
\begin{split}\langle x, y \rangle = x^T \cdot y = x_1y_1 + x_2y_2.\end{split}
\end{equation*}
\sphinxAtStartPar
Wir müssen nun einen linearen Operator \(p \in L^1(X; Y)\) finden, der eine äquivalente Berechnung wie das Skalarprodukt auf dem Tensorproduktraum \(X = \R^{2 \times 2}\), der durch das dyadische Produkt induziert wird, durchführt.
Hierzu wählen wir die Spur \(p(A) \coloneqq \operatorname{Spur}(A)\) einer Matrix \(A \in \R^{2 \times 2}\), denn diese ist \sphinxstylestrong{linear} und es gilt:
\begin{equation*}
\begin{split}\operatorname{Spur}
\begin{pmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{pmatrix}
= a_{11} + a_{22}.\end{split}
\end{equation*}
\sphinxAtStartPar
Überprüfen wir mit dieser Wahl nun die \sphinxstylestrong{universelle Eigenschaft des dyadischen Produkts}, so erhalten wir
\begin{equation*}
\begin{split}\Phi(x,y) = \langle x, y \rangle = x_1y_1 + x_2y_2 = \operatorname{Spur}
\begin{pmatrix}
x_1y_1 & x_1y_2 \\
x_2y_1 & x_2y_2
\end{pmatrix}
 = \operatorname{Spur}(x \otimes y) = p(x \otimes y).\end{split}
\end{equation*}
\sphinxAtStartPar
Es sei angemerkt, dass wir nicht gezeigt haben, dass der Spur\sphinxhyphen{}Operator der \sphinxstyleemphasis{einzige} lineare Operator ist, der diese Äquivalenz erfüllt.
Betrachten wir statt dessen die alternative Variante \(\otimes^*\) des dyadischen Produkts aus {\hyperref[\detokenize{vektoranalysis/tensor:ex:tensorproduktVarianten}]{\sphinxcrossref{Example 3.5}}}, so bleibt der Tensorproduktraum gleich, jedoch ändert sich der eindeutig bestimmte, lineare Operator \(p \in L^1(X; Y)\).
Durch die Vertauschung der Elemente der Matrix \(x \otimes^* y\) nimmt man nicht mehr die Summe der Hauptdiagonalelemente realisiert durch den Operator \(\operatorname{Spur}(A) = a_{11} + a_{22}\), sondern die \sphinxstylestrong{Summe der Gegendiagonalelemente} realisiert durch einen linearen Operator \(\operatorname{Spur}^*(A) \coloneqq a_{21} + a_{12}\), d.h., die Diagonale von links unten nach rechts oben in der Matrix.
In diesem Fall erhält man nämlich analog
\begin{equation*}
\begin{split}\Phi(x,y) = \langle x, y \rangle = x_1y_1 + x_2y_2 = \operatorname{Spur}^*
\begin{pmatrix}
x_1y_2 & x_1y_1 \\
x_2y_2 & x_2y_1
\end{pmatrix}
 = \operatorname{Spur}^*(x \otimes^* y) = p(x \otimes^* y).\end{split}
\end{equation*}
\sphinxAtStartPar
Dies Veranschaulicht die Beziehung der involvierten Vektorräume und die zu Grunde liegende universelle Eigenschaft des Tensorprodukts.
\end{sphinxadmonition}

\begin{sphinxadmonition}{danger}{Danger:}
\sphinxAtStartPar
Wir haben in {\hyperref[\detokenize{vektoranalysis/tensor:ex:universelleEigenschaft}]{\sphinxcrossref{Example 3.6}}} lediglich die universelle Eigenschaft zur Veranschaulichung überprüft für ein konkretes Beispiel.
Wir haben jedoch \sphinxstylestrong{nicht} gezeigt, dass das dyadische Produkt die \sphinxstyleemphasis{universelle Eigenschaft} erfüllt.
Dafür hätten wir die Äquivalenz für \sphinxstylestrong{alle möglichen} Bilinearformen \(\Phi \in L^2(V \times W; Y)\) für \sphinxstylestrong{beliebige Vektorräume} \(Y\) beweisen müssen.
\end{sphinxadmonition}


\subsection{Existenz und Konstruktion des Tensorprodukts}
\label{\detokenize{vektoranalysis/tensor:existenz-und-konstruktion-des-tensorprodukts}}
\sphinxAtStartPar
Wir stellen fest, dass es für zwei beliebige \(\R\)\sphinxhyphen{}Vektorräume \(V\) und \(W\) immer ein Tensorprodukt gibt, und dass wir dieses Tensorprodukt konkret konstruieren können indem wir uns auf die Basis der Vektorräume \(V\) und \(W\) zurückziehen.
Diese Tatsache formulieren wir in der folgenden Aussage.
\label{vektoranalysis/tensor:thm:existenzTensorprodukt}
\begin{sphinxadmonition}{note}{Theorem 3.1 (Existenz des Tensorprodukts)}



\sphinxAtStartPar
Für zwei reelle Vektorräume \(V, W\) existiert stets mindestens ein Tensorprodukt \(\otimes\in L^2(V\times W; V\otimes W)\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Der folgende Beweis ist ein sogenannter \sphinxstyleemphasis{konstruktiver Beweis}, d.h., wir zeigen die Existenz eines Objekts indem wir es explizit angeben.
Im Gegensatz hierzu gibt es auch nicht\sphinxhyphen{}konstruktive Existenzbeweise.

\sphinxAtStartPar
Es sei \(B^V = \{b_i^V: i\in I^V\}\) eine Basis von \(V\) und es sei analog \(B^W = \{b_i^W: i\in I^W\}\) eine Basis von \(W\) für zwei Indexmengen \(I^V\) und \(I^W\).
Wir betrachten zunächst das kartesische Produkt der beiden Indexmengen
\begin{equation*}
\begin{split}J := I^V \times I^W = \{(i,j): i\in I^V, j\in I^W\}.\end{split}
\end{equation*}
\sphinxAtStartPar
Es sei nun \(X\) ein reeller Vektorraum dessen Basis sich durch \(J\) indizieren lässt, das heißt es existiert eine Menge
\begin{equation*}
\begin{split}B^X = \{b_{ij}^X: (i,j)\in J\},\end{split}
\end{equation*}
\sphinxAtStartPar
so dass \(B^X\) eine Hamel\sphinxhyphen{}Basis von \(X\) ist.
Man kann zeigen, dass ein solcher Vektorraum immer existiert.

\sphinxAtStartPar
Wir definieren nun eine bilineare Abbildung \(\otimes: V\times W \to X\) über
\begin{equation*}
\begin{split}\otimes (b_i^V, b_j^W) = b_i^V \otimes b_j^W := b_{ij}^X \quad \forall (i,j)\in J.\end{split}
\end{equation*}
\sphinxAtStartPar
Es sei darauf hingewiesen, dass die bilineare Abbildung \(\otimes\) durch eine Definition über die Indexmenge \(J\) eindeutig festgelegt ist.
Dies liegt daran, dass für beliebige Paare \((v,w)\in V\times W\) endlich viele Koeffizienten \(\alpha_{i_1},\ldots,\alpha_{i_n}\) und \(\beta_{j_1},\ldots, \beta_{j_m}\) existieren, so dass für die Vektoren \(v \in V\) und \(w \in W\) eine Darstellung in den jeweiligen Hamel\sphinxhyphen{}Basen existiert mit
\begin{equation*}
\begin{split}v = \sum_{k=1}^n \alpha_{i_k} b_{i_k}^V, \quad w = \sum_{l=1}^m \beta_{j_l} b_{j_l}^W.\end{split}
\end{equation*}
\sphinxAtStartPar
Durch diese Darstellung erhalten wir für die bilineare Abbildung \(\otimes: V\times W \to X\) nun eine \sphinxstylestrong{explizite Vorschrift} als
\begin{equation*}
\begin{split}\otimes(v,w) 
= 
\otimes\big(\sum_{k=1}^n \alpha_{i_k} b_{i_k}^V, \sum_{l=1}^m \beta_{j_l} b_{j_l}^W\big) = 
\sum_{k=1}^n \sum_{l=1}^m \alpha_{i_k} \beta_{j_l} \otimes\left(b_{i_k}^V, b_{j_l}^W\right) =
\sum_{k=1}^n \sum_{l=1}^m \alpha_{i_k} \beta_{j_l} b_{i_kj_l}^X.\end{split}
\end{equation*}
\sphinxAtStartPar
Wir müssen nun noch die \sphinxstylestrong{universelle Eigenschaft} der bilinearen Abbildung \(\otimes\) nachweisen, um zu zeigen, dass es sich um ein Tensorprodukt handelt.
Sei dazu \(\phi\in L^2(V\times W; Y)\) eine Bilinearform auf einen beliebigen reellen Vektorraum \(Y\).
Dann können wir eine Linearform auf \(p: X\to Y\) explizit definieren durch Angabe ihrer Wirkung auf die Basiselemente mit
\begin{equation*}
\begin{split}p(b_{ij}^X) := \phi(b_i^V, b_j^W) \quad \forall (i,j) \in J.\end{split}
\end{equation*}
\sphinxAtStartPar
Dann gilt nämlich, unter Ausnutzung der Linearität von \(p\) und der obigen Rechnung, dass gilt
\begin{equation*}
\begin{split}p(\otimes(v,w))
&= p \left( \sum_{k=1}^n \sum_{l=1}^m \alpha_{i_k} \beta_{j_l} b_{i_kj_l}^X \right)
= \sum_{k=1}^n \sum_{l=1}^m \alpha_{i_k} \beta_{j_l} p(b_{i_kj_l}^X) \\
&= \sum_{k=1}^n \sum_{l=1}^m \alpha_{i_k} \beta_{j_l} \phi\left(b_{i_k}^V, b_{j_l}^W\right)
= \phi\big(\sum_{k=1}^n \alpha_{i_k} b_{i_k}^V,\sum_{l=1}^m \beta_{j_l} b_{j_l}^W\big)
= \phi(v,w)\end{split}
\end{equation*}
\sphinxAtStartPar
Wir sehen also, dass \(\otimes\) die universelle Eigenschaft erfüllt und zwar insbesondere dadurch, dass die Linearform \(p\) durch die obige Definition eindeutig festgelegt ist.
\end{sphinxadmonition}

\sphinxAtStartPar
Als Korollar aus {\hyperref[\detokenize{vektoranalysis/tensor:thm:existenzTensorprodukt}]{\sphinxcrossref{Theorem 3.1}}} erhalten wir somit, dass eine Basis des Tensorproduktraums durch das kartesische Produkt der ursprünglichen Basen konstruiert werden kann.
Hieran sieht man den qualitativen Unterschied zwischen \(V \times W\) und \(V\otimes W\).
\label{vektoranalysis/tensor:corollary-6}
\begin{sphinxadmonition}{note}{Corollary 3.1}



\sphinxAtStartPar
Für zwei reelle Vektorräume \(V\) und \(W\) mit zugehörigen Hamel\sphinxhyphen{}Basen
\begin{equation*}
\begin{split}B^V = \{b_i^V: i\in I^V\}, \quad B^W = \{b_i^W: i\in I^W\},\end{split}
\end{equation*}
\sphinxAtStartPar
und einem Tensorprodukt \(\otimes:V\times W \to V\otimes W\) ist
\begin{equation*}
\begin{split}B^X \, \coloneqq \, \{b_i^V \otimes b_j^W: i\in I^V, j\in I^W\}\end{split}
\end{equation*}
\sphinxAtStartPar
eine Basis von \(X = V\otimes W\).
\end{sphinxadmonition}

\sphinxAtStartPar
Wir wissen nun aus {\hyperref[\detokenize{vektoranalysis/tensor:thm:existenzTensorprodukt}]{\sphinxcrossref{Theorem 3.1}}}, dass immer mindestens ein Tensorprodukt existiert.
Es stellt sich also die Frage inwiefern sich verschiedene Tensorprodukte auf den gleichen Vektorräumen \(V\) und \(W\) unterscheiden.
Hierzu liefert das folgende Lemma eine klare Einsicht.
\label{vektoranalysis/tensor:lem:isomorphismusTensorproduktraum}
\begin{sphinxadmonition}{note}{Lemma 3.4 (Isomorphie von Tensorprodukträumen)}



\sphinxAtStartPar
Es seien \(V\) und \(W\) zwei reelle Vektorräume und es seien
\begin{equation*}
\begin{split}\otimes_1 &\colon V \times W \rightarrow V \otimes_1 W,\\
\otimes_2 &\colon V \times W \rightarrow V \otimes_2 W\end{split}
\end{equation*}
\sphinxAtStartPar
zwei Tensorprodukte.
Dann existiert genau ein Isomorphismus
\begin{equation*}
\begin{split}p: V\otimes_1 W \to V\otimes_2 W,\end{split}
\end{equation*}
\sphinxAtStartPar
so dass gilt \(\otimes_2 = p\circ \otimes_1\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Seien also zunächst zwei Tensorprodukte \(\otimes_1, \otimes_2\) auf \(V\times W\) gegeben.
Wegen der \sphinxstyleemphasis{universellen Eigenschaft} des Tensorprodukts wissen wir, dass es lineare Abbildungen
\begin{equation*}
\begin{split}p_1&: V\otimes_1 W\to Y_1 \ \coloneqq \ V\otimes_2 W,\\
p_2&: V\otimes_2 W\to Y_2 \ \coloneqq \ V\otimes_1 W\end{split}
\end{equation*}
\sphinxAtStartPar
gibt, so dass gilt
\begin{equation*}
\begin{split}\otimes_2 &= p_1 \circ \otimes_1,\\
\otimes_1 &= p_2 \circ \otimes_2.\end{split}
\end{equation*}
\sphinxAtStartPar
Durch Einsetzen der Gleichungen ineinander somit
\begin{equation*}
\begin{split}\otimes_2 &= p_1\circ p_2 \circ \otimes_2,\\
\otimes_1 &= p_2\circ p_1 \circ \otimes_1.\end{split}
\end{equation*}
\sphinxAtStartPar
Aus dem Beweis von {\hyperref[\detokenize{vektoranalysis/tensor:thm:existenzTensorprodukt}]{\sphinxcrossref{Theorem 3.1}}} wissen wir, dass wir die Basis von \(V\otimes_2 W\) über die Abbildung \(\otimes_2(b_i^V, b_j^W)\) der Basiselemente von \(V\) und \(W\) charakterisieren können.
Setzen wir also das Tensorprodukt dieser Basiselemente in die erste Gleichung ein, so erhalten wir
\begin{equation*}
\begin{split}\otimes_2(b_i^V, b_j^W) = p_1\circ p_2(\otimes_2(b_i^V,b_j^W)).\end{split}
\end{equation*}
\sphinxAtStartPar
Das zeigt also, dass \(p_1\circ p_2 = \mathrm{Id}_{Y_1}\) die Identitätsabbildung auf dem Tensorproduktraum \(Y_1 = V \otimes_2 W\) sein muss.
Dies folgt, weil \(p_1\circ p_2\) als lineare Abbildung schon ganz durch seine Wirkung auf den Basiselementen festgelegt ist.
Analog kann man nun folgern, dass \(p_2\circ p_1 = \mathrm{Id}_{Y_2}\) die Identitätsabbildung im Tensorproduktraum \(Y_2 = V \otimes_1 W\) ist und somit sind die Linearformen \(p_1\) und \(p_2\) \sphinxstylestrong{Isomorphismen} und gerade die jeweiligen Umkehrfunktionen zueinander.

\sphinxAtStartPar
Insgesamt haben wir also gezeigt, dass Tensorprodukträume, die durch verschiedene Tensorprodukte auf dem gleiche kartesischen Produkraum stets isomorph zueinander sind.
\end{sphinxadmonition}

\sphinxAtStartPar
Im endlich\sphinxhyphen{}dimensionalen Fall können wir uns also immer auf den \(\R^{n \cdot m}\) zurückziehen, wie das folgende Korrolar festhält.
\label{vektoranalysis/tensor:cor:isomorphieEndlichDimensional}
\begin{sphinxadmonition}{note}{Corollary 3.2}



\sphinxAtStartPar
Betrachten wir ein Tensorprodukt \(\otimes \in L^2(V \times W; V \otimes W)\) zweier \sphinxstylestrong{endlich\sphinxhyphen{}dimensionaler} \(\R\)\sphinxhyphen{}Vektorräume \(V\) und \(W\) mit \(\operatorname{dim}(V)=n \in \N\) und \(\operatorname{dim}(W)=m \in \N\), so existiert stets die folgende Isormorphie
\begin{equation*}
\begin{split}V \otimes W \cong \R^{n \cdot m}.\end{split}
\end{equation*}
\sphinxAtStartPar
Das heißt für die Dimension des Tensorproduktraums \(V \otimes W\) gilt offensichtlich
\begin{equation*}
\begin{split}\operatorname{dim}(V \otimes W) = n\cdot m.\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Das folgende Beispiel soll noch einmal die Isomorphie zwischen verschiedenen Tensorprodukträumen illustrieren.
\label{vektoranalysis/tensor:example-9}
\begin{sphinxadmonition}{note}{Example 3.7 (Dyadisches Produkt vs. Kronecker\sphinxhyphen{}Produkt)}



\sphinxAtStartPar
Im Folgenden betrachten wir wieder den Euklidischen Vektorraum \(V=W=\R^2\) und zwei Vektoren \(x, y \in \R^2\).
Wie wir in {\hyperref[\detokenize{vektoranalysis/tensor:ex:tensorproduktVarianten}]{\sphinxcrossref{Example 3.5}}} und {\hyperref[\detokenize{vektoranalysis/tensor:ex:universelleEigenschaft}]{\sphinxcrossref{Example 3.6}}} festgestellt haben realisiert das \sphinxstylestrong{dyadische Produkt}
\begin{equation*}
\begin{split}\otimes_d \colon \R^2 \times \R^2 \rightarrow \R^2 \otimes_d \R^2 = \R^{2 \times 2} =: X_d\end{split}
\end{equation*}
\sphinxAtStartPar
mit
\begin{equation*}
\begin{split}x \otimes_d y \, \coloneqq \,
\begin{pmatrix}
x_1y_1 & x_1y_2 \\
x_2y_1 & x_2y_2
\end{pmatrix}.\end{split}
\end{equation*}
\sphinxAtStartPar
ein Tensorprodukt der Vektorräume \(V=W=\R^2\).

\sphinxAtStartPar
Betrachten wir nun ein weiteres Tensorprodukt auf dem kartesischen Produktraum \(V \times W\), nämlich das \sphinxstylestrong{Kronecker\sphinxhyphen{}Produkt} \(\otimes_K\).
Das Kronecker\sphinxhyphen{}Produkt realisiert eine Abbildung
\begin{equation*}
\begin{split}\otimes_K \colon \R^2 \times \R^2 \rightarrow \R^2 \otimes_K \R^2 = \R^{4} =: X_K,\end{split}
\end{equation*}
\sphinxAtStartPar
mit
\begin{equation*}
\begin{split}x \otimes_K y =
\begin{pmatrix}
x_1 \\ x_2
\end{pmatrix} \otimes_K 
\begin{pmatrix}
y_1 \\ y_2
\end{pmatrix}
\, = \, 
\begin{pmatrix}
x_1 \cdot \begin{pmatrix} y_1 \\ y_2 \end{pmatrix} \\ 
x_2 \cdot \begin{pmatrix} y_1 \\ y_2 \end{pmatrix}
\end{pmatrix}
= 
\begin{pmatrix}
x_1y_1\\
x_1y_2\\
x_2y_1\\
x_2y_2
\end{pmatrix}.\end{split}
\end{equation*}
\sphinxAtStartPar
Es wird nun klar, dass die Räume \(X_d = \R^{2 \times 2}\) und \(X_K = \R^4\) isomorph zueinander sind, d.h., es gilt \(X_d \cong X_K\).
Außerdem kann man Tensoren in den jeweiligen Tensorprodukträumen durch zeilenweises Ablesen bzw. Eintragen in eine Matrix eindeutig ineinander überführen.
\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstylestrong{Das Tensorprodukt?}

\sphinxAtStartPar
Die Aussage aus {\hyperref[\detokenize{vektoranalysis/tensor:lem:isomorphismusTensorproduktraum}]{\sphinxcrossref{Lemma 3.4}}} zeigt also, dass obwohl es verschiedene Arten gibt Tensorprodukte auf dem kartesischen Produktraum \(V \times W\) zu definieren, die resultierenden Tensorprodukträume stets isomorph zueinander sind.
Deshalb spricht man auch von \sphinxstylestrong{dem} Tensorprodukt \(\otimes\) und \sphinxstylestrong{dem} Tensorproduktraum \(V \otimes W\), was so klingt als gäbe es jeweils nur ein einziges Exemplar.
In der Tat gibt es zwar mehrere Tensorprodukte aber man kann diese problemlos ineinander umrechnen und die resultierenden Tensorprodukträume alle miteinander identifizieren.

\sphinxAtStartPar
Deshalb werden wir im Folgendem auch häufig von \sphinxstylestrong{dem} Tensorprodukt sprechen.


\subsection{Natürliche Homo\sphinxhyphen{} und Isomorphismen des Tensorprodukts}
\label{\detokenize{vektoranalysis/tensor:naturliche-homo-und-isomorphismen-des-tensorprodukts}}
\sphinxAtStartPar
Von vielen Operationen kennen wir bereits Eigenschaften wie \sphinxstyleemphasis{Kommutativität} und \sphinxstyleemphasis{Assoziativität}.
Derartige Eigenschaften gelten nicht direkt für das Tensorprodukt, allerdings erhalten wir Isomorphismen, welche bekannte Rechenregeln nachbilden.
Diese Isomorphismen nennt auch \sphinxstylestrong{natürlich} oder \sphinxstylestrong{kanonisch}, weil Sie jeweils auf die naheliegendste Art und Weise definiert sind.
Das folgende Lemma fasst die wichtigsten Eigenschaften des Tensorprodukts zusammen
\label{vektoranalysis/tensor:lem:natISO}
\begin{sphinxadmonition}{note}{Lemma 3.5 (Natürliche Isomorphismen des Tensorprodukts)}



\sphinxAtStartPar
Es seien \(V_1,V_2,V_3\) und \(V_4\) reelle Vektorräume.
Dann existieren für das Tensorprodukt die folgenden Isomorphismen:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(V_1\otimes V_2 \cong V_2\otimes V_1, \quad v_1\otimes v_2 \mapsto v_2\otimes v_1\) (\sphinxstylestrong{Kommutativität}),

\item {} 
\sphinxAtStartPar
\((V_1\otimes V_2)\otimes V_3 \cong V_1 \otimes (V_2 \otimes V_3),\quad (v_1\otimes v_2)\otimes v_3 \mapsto v_1 \otimes (v_2\otimes v_3)\) (\sphinxstylestrong{Assoziativität}),

\item {} 
\sphinxAtStartPar
\(\R \otimes V_1 \cong V_1,\quad a\otimes v_1 \mapsto a\,v_1\) \sphinxstylestrong{(Produkt mit Skalaren)},

\item {} 
\sphinxAtStartPar
Falls \(p_{12}:V_1\to V_2\) und \(p_{34}:V_3\to V_4\) Isomorphismen sind, so gilt (\sphinxstylestrong{Transitivität})

\end{enumerate}
\begin{equation*}
\begin{split}V_1\otimes V_3 \cong V_2\otimes V_4,\quad v_1\otimes v_3 \mapsto p_{12}(v_1)\otimes p_{34}(v_3)\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Punkt 1.\sphinxhyphen{}3. sind in der Hausaufgabe zu zeigen.

\sphinxAtStartPar
\sphinxstylestrong{Zu Punkt 4.:}

\sphinxAtStartPar
Wichtig für die Transitivitätseigenschaft ist es zunächst einzusehen, dass die Definition des Tensorprodukts sinnvoll ist, denn nicht jedes Element \(x\in V_1\otimes V_3\) lässt sich \sphinxstyleemphasis{direkt} als Tensorprodukt schreiben.
Wir wissen lediglich, dass \sphinxstyleemphasis{endlich viele} sogenannte \sphinxstylestrong{elementare} oder \sphinxstylestrong{zerfallende} Produkte \((v_1^i\otimes v_3^i)_{i=1}^n\) und Skalare \(\alpha_i\in\R, i=1,\ldots,n\), für \(n\in\N\) existieren, so dass sich jeder Vektor \(x \in V_1 \otimes V_3\) schreiben lässt als
\begin{equation*}
\begin{split}x = \sum_{i=1}^n \alpha_i (v_1^i \otimes v_3^i),\end{split}
\end{equation*}
\sphinxAtStartPar
was direkt aus der Basiskonstruktion in {\hyperref[\detokenize{vektoranalysis/tensor:thm:existenzTensorprodukt}]{\sphinxcrossref{Theorem 3.1}}} folgt.

\sphinxAtStartPar
Die angegebene Abbildung
\begin{equation*}
\begin{split}v_1\otimes v_3 \mapsto p_{12}(v_1)\otimes p_{34}(v_3)\end{split}
\end{equation*}
\sphinxAtStartPar
ist nun \sphinxstylestrong{nur} für zerfallende Produkte definiert.
Allerdings lässt sie sich eindeutig zu einer linearen Abbildung \(\Phi(V_1\otimes V_3)\to (V_2\otimes V_4)\) fortsetzen, so dass für beliebige Vektoren \(x \in V_1 \otimes V_3\) gilt
\begin{equation*}
\begin{split}\Phi(x) = \Phi(\sum_{i=1}^n \alpha_i v_1^i \otimes v_3^i) = 
\sum_{i=1}^n \alpha_i \Phi(v_1^i \otimes v_3^i) = 
\sum_{i=1}^n \alpha_i (p_{12}(v_1^i)\otimes p_{34}(v_3^i)).\end{split}
\end{equation*}
\sphinxAtStartPar
Auf analoge Art und Weise definiert man nun die lineare Abbildung \(\Psi \colon V_2 \otimes V_4 \rightarrow V_1 \otimes V_3\) mit
\begin{equation*}
\begin{split}\Psi(v_2\otimes v_4) := p_{12}^{-1}(v_2)\otimes p_{34}^{-1}(v_4)\end{split}
\end{equation*}
\sphinxAtStartPar
und erhält sofort, dass \(\Psi\circ\Phi = \mathrm{Id}\) gilt, da für beliebige Vektoren \(x \in V_1 \otimes V_3\) gilt:
\begin{equation*}
\begin{split}\Psi \circ \Phi(x) &= \Psi \circ \Phi(\sum_{i=1}^n \alpha_i v_1^i \otimes v_3^i) = \Psi \circ \sum_{i=1}^n \alpha_i (p_{12}(v_1^i)\otimes p_{34}(v_3^i)) \\
&= \sum_{i=1}^n \alpha_i \Psi(p_{12}(v_1^i)\otimes p_{34}(v_3^i)) = \sum_{i=1}^n \alpha_i (v_1^i \otimes v_3^i) = x.\end{split}
\end{equation*}
\sphinxAtStartPar
Analog gilt auch \(\Phi\circ\Psi = \mathrm{Id}\) und somit haben wir die Behauptung des Lemmas bewiesen.
\end{sphinxadmonition}

\sphinxAtStartPar
Die zweite Eigenschaft in {\hyperref[\detokenize{vektoranalysis/tensor:lem:natISO}]{\sphinxcrossref{Lemma 3.5}}} erlaubt es uns das Tensorprodukt über \(k\)\sphinxhyphen{}viele reelle Vektorräume \(V_1,\ldots, V_k\) zu bilden.
Daher können wir ab nun folgende Notation verwenden
\begin{equation*}
\begin{split}\bigotimes_{i=1}^k V_i :=V_1\otimes\ldots\otimes V_k\end{split}
\end{equation*}
\sphinxAtStartPar
und sehen, dass dieses Objekt wohldefiniert ist.
Insbesondere ist äquivalent das Tensorprodukt über \(k\) Vektorräume mit Hilfe einer \(k\)\sphinxhyphen{}Multilinearform aus {\hyperref[\detokenize{vektoranalysis/multilinear:s-k-multilinearform}]{\sphinxcrossref{\DUrole{std,std-ref}{k\sphinxhyphen{}Multilinearformen}}}} zu definieren anstatt nur einer Bilinearform wie in {\hyperref[\detokenize{vektoranalysis/tensor:def:tensor}]{\sphinxcrossref{Definition 3.4}}}.
Die folgende Bemerkung gibt die universelle Eigenschaft für solch ein Tensorprodukt an.
\label{vektoranalysis/tensor:rem:kfachesTensorprodukt}
\begin{sphinxadmonition}{note}{Remark 3.7 (\protect\(k\protect\)\sphinxhyphen{}faches Tensorprodukt)}



\sphinxAtStartPar
Es seien \(V_1,\ldots, V_k\) für \(k \in \N\) reelle Vektorräume.
Dann besitzt das \(k\)\sphinxhyphen{}fache Tensorprodukt \(\otimes \colon V_1 \times \ldots \times V_k \rightarrow \bigotimes_{i=1}^k V_i\) die folgende universelle Eigenschaft:

\sphinxAtStartPar
Für jede \(k\)\sphinxhyphen{}Multilinearform \(\phi\in L^k(V_1\times\ldots\times V_k; Y)\) in einen beliebigen reellen Vektorraum \(Y\) existiert eine eindeutige lineare Abbildung
\(p \in L^1(\bigotimes_{i=1}^k V_i; Y)\), so dass gilt
\begin{equation*}
\begin{split}\phi = p \circ \otimes.\end{split}
\end{equation*}\end{sphinxadmonition}
\label{vektoranalysis/tensor:remark-12}
\begin{sphinxadmonition}{note}{Remark 3.8 (Notation)}



\sphinxAtStartPar
Im obigen Fall interpretiert man \(\otimes: V_1\times\ldots\times V_k \rightarrow \bigotimes_{i=1}^k V_i\) als \(k\)\sphinxhyphen{}Multilinearform und benutzt die Infix\sphinxhyphen{}Notation
\begin{equation*}
\begin{split}v_1\otimes\ldots\otimes v_k := \otimes(v_1,\ldots, v_k).\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Im folgenden Abschnitt der Vorlesung wollen wir Tensoren insbesondere als Multilinearformen interpretieren.
Deshalb interessieren wir uns im Folgenden für die Eigenschaften des Tensorprodukts, wenn wir speziell \sphinxstyleemphasis{Räume von linearen Abbildungen} betrachten.
Die lineare Abbildung im folgenden Lemma stellt hierbei die zentrale Idee dar.
\label{vektoranalysis/tensor:lem:LISO}
\begin{sphinxadmonition}{note}{Lemma 3.6}



\sphinxAtStartPar
Es seien \(V_1, V_2\) sowie \(W_1, W_2\) reelle Vektorräume.
Dann ist die Abbildung
\begin{equation*}
\begin{split}p:L(V_1; V_2)\otimes L(W_1; W_2) &\rightarrow L(V_1\otimes W_1; V_2\otimes W_2)\\
(p(\eta_1\otimes\eta_2))(v_1\otimes w_1)&:= \eta_1(v_1) \otimes \eta_2(w_1).\end{split}
\end{equation*}
\sphinxAtStartPar
ein wohldefinierter \sphinxstylestrong{Homomorphismus}.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. In der Hausaufgabe zu zeigen.
\end{sphinxadmonition}

\sphinxAtStartPar
Da die Notation in {\hyperref[\detokenize{vektoranalysis/tensor:lem:LISO}]{\sphinxcrossref{Lemma 3.6}}} vielleicht etwas abstrakt wirkt, soll die folgende Bemerkung auf die einzelnen Elemente der linearen Abbildung \(p\) nochmal genauer eingehen.
\label{vektoranalysis/tensor:remark-14}
\begin{sphinxadmonition}{note}{Remark 3.9 (Funktionen als Funktionswerte)}



\sphinxAtStartPar
Die lineare Abbildung in {\hyperref[\detokenize{vektoranalysis/tensor:lem:LISO}]{\sphinxcrossref{Lemma 3.6}}} ist folgendermaßen zu verstehen:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\eta_1:V_1\rightarrow V_2\) und \(\eta_2: W_1 \rightarrow W_2\) sind lineare Abbildungen mit \(\eta_1 \in L(V_1; V_2)\) und \(\eta_2 \in L(W_1; W_2)\)

\item {} 
\sphinxAtStartPar
\(\eta_1 \otimes \eta_2\) ist dementsprechend ein Element aus dem Tensorproduktraum \(L(V_1; V_2)\otimes L(W_1; W_2)\),

\item {} 
\sphinxAtStartPar
\(p(\eta_1\otimes\eta_2)\) ist dann ein Element von \(L(V_1\otimes W_1; V_2\otimes W_2)\), also eine lineare Abbildung, welche vom Tensorproduktraum \(V_1\otimes W_1\) in den Tensorproduktraum \(V_2\otimes W_2\) abbildet,

\item {} 
\sphinxAtStartPar
\((p(\eta_1\otimes\eta_2))(v_1\otimes w_1)\) ist schließlich die Auswertung dieser Abbildung am Punkt \(v_1\otimes w_1\in V_1\otimes W_1\).

\end{itemize}

\sphinxAtStartPar
In diesem Fall notiert man auch
\begin{equation*}
\begin{split}\eta_1\otimes\eta_2 \mapsto 
\big[
v_1\otimes w_1\mapsto \eta_1(v_1) \otimes \eta_2(w_1)
\big],\end{split}
\end{equation*}
\sphinxAtStartPar
was bedeutet, dass \(\eta_1\otimes\eta_2\) auf eine \sphinxstyleemphasis{Funktion} abgebildet wird, welche wiederum \(v_1\otimes w_1\) als Argumente bekommt.
\end{sphinxadmonition}

\sphinxAtStartPar
Insbesondere können wir im \sphinxstylestrong{endlich\sphinxhyphen{}dimensionalen Fall} zeigen, dass die Abbildung \(p\) in {\hyperref[\detokenize{vektoranalysis/tensor:lem:LISO}]{\sphinxcrossref{Lemma 3.6}}} einen Isomorphismus definiert.
Hierzu formulieren wir zunächst das folgende nützliche Hilfslemma.
\label{vektoranalysis/tensor:lem:isomorphieKartesischesProdukt}
\begin{sphinxadmonition}{note}{Lemma 3.7}



\sphinxAtStartPar
Seien \(V\) und \(W\) zwei beliebige reelle Vektorräume und \(n,m \in \N\).
Dann existiert ein Isomorphismus, so dass
\begin{equation*}
\begin{split}(V \otimes W)^{n\cdot m} \cong V^n \otimes W^m.\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. In der Hausaufgabe zu zeigen.
\end{sphinxadmonition}
\label{vektoranalysis/tensor:thm:pIsomorphismus}
\begin{sphinxadmonition}{note}{Theorem 3.2}



\sphinxAtStartPar
Es seien \(V_1, W_1\) reelle \sphinxstyleemphasis{endlich\sphinxhyphen{}dimensionale} Vektorräume und \(V_2, W_2\) \sphinxstyleemphasis{beliebige} reelle Vektorräume.
Dann ist die Abbildung
\begin{equation*}
\begin{split}p:L(V_1; V_2)\otimes L(W_1; W_2) &\rightarrow L(V_1\otimes W_1; V_2\otimes W_2)\\
(p(\eta_1\otimes\eta_2))(v_1\otimes w_1)&:= \eta_1(v_1) \otimes \eta_2(w_1).\end{split}
\end{equation*}
\sphinxAtStartPar
ein Isomorphismus.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Seien \(V_1\) und \(W_1\) zwei endlich\sphinxhyphen{}dimensionale, reelle Vektorräume mit \(\operatorname{dim}(V_1) = n \in \N\) und \(\operatorname{dim}(W_1) = m \in \N\).
Nach dem \sphinxstyleemphasis{Isomorphiesatz für endlich\sphinxhyphen{}dimensionale Vektorräume} 3.20 in {[}\hyperlink{cite.references:id2}{Bur20}{]} existiert dann je ein Isomorphismus, so dass \(V_1 \cong \R^n\) und \(W_1 \cong \R^m\).
Über diesen Isomorphismus lässt sich auch zeigen, dass \(L(V_1; V_2) \cong L(\R^n; V_2)\) und \(L(W_1; W_2) \cong L(\R^m; W_2)\) gilt.
Zusammen mit der \sphinxstyleemphasis{Transitivitätseigenschaft des Tensorprodukts} aus {\hyperref[\detokenize{vektoranalysis/tensor:lem:natISO}]{\sphinxcrossref{Lemma 3.5}}} folgt dann aber schon
\begin{equation*}
\begin{split}L(V_1; V_2)\otimes L(W_1; W_2) \cong L(\R^n; V_2)\otimes L(\R^m; W_2).\end{split}
\end{equation*}
\sphinxAtStartPar
Daher reicht es, die Aussage des Theorems für den einfachen Fall \(V_1=\R^n, W_1=\R^m\) im Folgenden in zwei Schritten zu zeigen.

\sphinxAtStartPar
\sphinxstylestrong{1.Schritt:} Wir zeigen zunächst, dass die Isomorphie \(L(\R^k; Y) \cong Y^k\) gilt.

\sphinxAtStartPar
Es sei \(Y\) ein beliebiger reeller Vektorraum und es bezeichne \((e_i)_{i=1}^k\) die Standardbasis von \(\R^k\).
Wir konstruieren nun eine Abbildung \(\phi:Y^k\rightarrow L(\R^k; Y)\), so dass
\begin{equation*}
\begin{split}\phi(y_1,\ldots,y_k) = [e_i \mapsto y_i], \quad i = 1,\ldots,k\end{split}
\end{equation*}
\sphinxAtStartPar
gilt.
Die Abbildung \(\phi\) ist \sphinxstylestrong{linear}, da für alle Vektoren \(y,z \in Y^k\) und einen beliebigen Vektor \(x \in \R^k\) mit der Basisdarstellung \(x=\sum_{i=1}^k \alpha_i e_i\) gilt:
\begin{equation*}
\begin{split}\phi(y+z)(x) &= \phi(y_1+z_1,\ldots, y_k+z_k)(\sum_{i=1}^k \alpha_i e_i) = \sum_{i=1}^k \alpha_i (y_i + z_i) \\
&= \sum_{i=1}^k \alpha_i y_i + \sum_{i=1}^k \alpha_i z_i = \phi(y_1,\ldots, y_k)(\sum_{i=1}^k \alpha_i e_i) + \phi(z_1,\ldots, z_k)(\sum_{i=1}^k \alpha_i e_i) \\
&= \phi(y)(x) + \phi(z)(x)\end{split}
\end{equation*}
\sphinxAtStartPar
und für jedes Skalar \(\lambda \in \R\) gilt:
\begin{equation*}
\begin{split}\phi(\lambda y)(x) &= \phi(\lambda y_1,\ldots, \lambda y_k)(\sum_{i=1}^k \alpha_i e_i)
= \sum_{i=1}^k \alpha_i (\lambda y_i) = \lambda \sum_{i=1}^k \alpha_i y_i \\
&= \lambda \phi( y_1,\ldots, y_k)(\sum_{i=1}^k \alpha_i e_i)
= \lambda \phi(y)(x).\end{split}
\end{equation*}
\sphinxAtStartPar
Offenbar ist diese lineare Abbildung auch \sphinxstylestrong{injektiv}, denn
\begin{equation*}
\begin{split}\phi(y_1,\ldots,y_k)(e_i) = 0\quad\forall i\in{1,\ldots k} 
\qquad \Leftrightarrow \qquad
y_i = 0\quad\forall i\in{1,\ldots k}.\end{split}
\end{equation*}
\sphinxAtStartPar
Gleichzeitig ist die lineare Abbildung jedoch auch \sphinxstylestrong{surjektiv}, da jede lineare Abbildung in \(L(\R^k; Y)\) sich bereits durch seine Wirkung auf den Basiselementen \(e_i \in \R^k, i=1,\ldots,k\) eindeutig beschreiben lässt.

\sphinxAtStartPar
Wir sehen also ein, dass es sich bei der Abbildung \(\phi\) um einen Isomorphismus handelt und somit gilt also \(L(\R^k; Y) \cong Y^k\).

\sphinxAtStartPar
\sphinxstylestrong{2.Schritt:} Als Nächstes wollen wir die folgenden Isomorphien zeigen:
\begin{equation*}
\begin{split}L(\R^n; V_2) \otimes L(\R^m; W_2) \cong V_2^n \otimes W_2^m\cong L(\R^n\otimes \R^m; V_2\otimes W_2).\end{split}
\end{equation*}
\sphinxAtStartPar
Mit Schritt 1 des Beweises wissen wir bereits, dass \(L(\R^n; V_2)\cong V_2^n\) und \(L(\R^m; W_2)\cong W_2^m\) gilt.
Zusammen mit der \sphinxstyleemphasis{Transitivitätseigenschaft des Tensorprodukts} aus {\hyperref[\detokenize{vektoranalysis/tensor:lem:natISO}]{\sphinxcrossref{Lemma 3.5}}} folgt damit schon die erste Isomorphie
\begin{equation}\label{equation:vektoranalysis/tensor:eq:ersteIsormorphie}
\begin{split}L(\R^n; V_2) \otimes L(\R^m; W_2) \cong V_2^n \otimes W_2^m.\end{split}
\end{equation}
\sphinxAtStartPar
Für die zweite Isomorphie benutzen wir den Zusammenhang \(\R^n\otimes \R^m \cong \R^{n\cdot m}\) aus {\hyperref[\detokenize{vektoranalysis/tensor:cor:isomorphieEndlichDimensional}]{\sphinxcrossref{Corollary 3.2}}} und erhalten somit
\begin{equation*}
\begin{split}L(\R^n\otimes \R^m; V_2\otimes W_2) \cong L(\R^{n\cdot m}; V_2\otimes W_2).\end{split}
\end{equation*}
\sphinxAtStartPar
Nutzen wir wiederum die Isomorphie aus Schritt 1 so erhalten wir
\begin{equation*}
\begin{split}L(\R^{n\cdot m}; V_2\otimes W_2) \cong (V_2 \otimes W_2)^{n\cdot m}.\end{split}
\end{equation*}
\sphinxAtStartPar
Wegen {\hyperref[\detokenize{vektoranalysis/tensor:lem:isomorphieKartesischesProdukt}]{\sphinxcrossref{Lemma 3.7}}} wissen wir dann aber schon, dass gilt
\begin{equation*}
\begin{split}(V_2 \otimes W_2)^{n\cdot m} \cong V_2^n \otimes W_2^m.\end{split}
\end{equation*}
\sphinxAtStartPar
Zusammen mit der Isomorphie {\hyperref[\detokenize{vektoranalysis/tensor:equation-eq-ersteisormorphie}]{\sphinxcrossref{(3.3)}}} haben wir nun insgesamt gezeigt, dass
\begin{equation*}
\begin{split}L(\R^n; V_2) \otimes L(\R^m; W_2) \cong L(\R^n\otimes \R^m; V_2\otimes W_2)\end{split}
\end{equation*}
\sphinxAtStartPar
gilt, was mit unseren Vorüberlegungen die Aussage des Theorems beweist.
\end{sphinxadmonition}

\sphinxAtStartPar
Wählen wir die Zielräume der linearen Abbildungen als \(V_2 = W_2 = \R\), so erhalten wir direkt folgendes Korrolar als Anwendung des allgemeinen Resultats in {\hyperref[\detokenize{vektoranalysis/tensor:thm:pIsomorphismus}]{\sphinxcrossref{Theorem 3.2}}}.
Dies ermöglicht es uns später Tensoren als Linearformen zu interpretieren.
\label{vektoranalysis/tensor:cor:tensorenLinearformen}
\begin{sphinxadmonition}{note}{Corollary 3.3 (Isomorphie des algebraischen Dualraums des Tensorproduktraums)}



\sphinxAtStartPar
Es seien \(V\) und \(W\) beliebige endlich\sphinxhyphen{}dimensionale Vektorräume.
Dann existiert ein Isomorphismus zwischen dem Tensorproduktraum der algebraischen Dualräume von \(V\) und \(W\) und dem algebraischen Dualraum des Tensorproduktraums, d.h.,
\begin{equation*}
\begin{split}V^\ast \otimes W^\ast \cong (V\otimes W)^\ast = L^1(V \otimes W; \R).\end{split}
\end{equation*}\end{sphinxadmonition}


\subsection{Tensoren als Multilinearformen}
\label{\detokenize{vektoranalysis/tensor:tensoren-als-multilinearformen}}
\sphinxAtStartPar
Das folgende Korollar kombiniert die theoretischen Ergebnisse des letzten Abschnitts und liefert so ein mathematisches Resultat, das für die Anwendung beispielsweise in der Physik von Bedeutung ist.
Wir werden nämlich nun folgern, dass wir Tensoren als Multilinearformen auffassen können.
\label{vektoranalysis/tensor:cor:tensorMultilinearform}
\begin{sphinxadmonition}{note}{Corollary 3.4 (Tensoren als Multilinearformen)}



\sphinxAtStartPar
Seien \(V\) und \(W\) zwei reelle endlich\sphinxhyphen{}dimensionale Vektorräume und \(\otimes \colon V \times W \rightarrow V \otimes W\) das Tensorprodukt.
Dann existiert ein Isomorphismus zwischen dem Tensorproduktraum und dem Raum der Bilinearformen durch
\begin{equation*}
\begin{split}V \otimes W \cong L^2(V \times W; \R).\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Wie wir in {\hyperref[\detokenize{vektoranalysis/tensor:cor:tensorenLinearformen}]{\sphinxcrossref{Corollary 3.3}}} gesehen haben, besteht ein Isomorphismus zwischen dem Tensorproduktraum algebraischer Dualräume und dem algebraischen Dualraum des entsprechenden Tensorproduktraums mit
\begin{equation*}
\begin{split}V^\ast \otimes W^\ast \cong (V\otimes W)^\ast = L^1(V \otimes W; \R).\end{split}
\end{equation*}
\sphinxAtStartPar
Da jeder endlich\sphinxhyphen{}dimensionale, reelle Vektorraums \(V\) nach {\hyperref[\detokenize{vektoranalysis/multilinear:lem:dualeBasis}]{\sphinxcrossref{Lemma 3.3}}} isomorph zu seinem algebraischen Dualraum \(V^\ast\) ist, können wir die \sphinxstyleemphasis{Transitivitätseigenschaft des Tensorprodukts} aus {\hyperref[\detokenize{vektoranalysis/tensor:lem:natISO}]{\sphinxcrossref{Lemma 3.5}}} ausnutzen und erhalten die folgende Isomorphie
\begin{equation}\label{equation:vektoranalysis/tensor:eq:transitivIsomorphismus}
\begin{split}V \otimes W \cong V^\ast \otimes W^\ast.\end{split}
\end{equation}
\sphinxAtStartPar
Gleichzeitig besagt die \sphinxstyleemphasis{universelle Eigenschaft des Tensorprodukts} in , dass es zu jeder Bilinearform \(\Phi \in L^2(V \times W; \R)\) eine eindeutige Linearform \(p \in L^1(V \otimes W; \R)\) gibt, so dass \(\Phi = p \circ \otimes\) gilt.
Somit erhalten wir also auch einen Isomorphismus
\begin{equation*}
\begin{split}L^1(V \otimes W; \R) \cong L^2(V \times W; \R).\end{split}
\end{equation*}
\sphinxAtStartPar
Kombinieren wir diese mathematischen Resultate nun alle so ergibt sich die folgende Kette von Isomorphismen:
\begin{equation*}
\begin{split}V \otimes W \cong V^\ast \otimes W^\ast \cong L^1(V \otimes W; \R) \cong L^2(V \times W; \R),\end{split}
\end{equation*}
\sphinxAtStartPar
was die Aussage beweist.
\end{sphinxadmonition}

\sphinxAtStartPar
{\hyperref[\detokenize{vektoranalysis/tensor:cor:tensorMultilinearform}]{\sphinxcrossref{Corollary 3.4}}} besagt, dass Tensoren als Elemente des Tensorproduktraums \(V \otimes W\) als Bilinearformen auf dem kartesischen Produktraum \(V \times W\) aufgefasst werden können.
Diese Aussage lässt sich mit Hilfe von {\hyperref[\detokenize{vektoranalysis/tensor:rem:kfachesTensorprodukt}]{\sphinxcrossref{Remark 3.7}}} auch auf das \(k\)\sphinxhyphen{}fache Tensorprodukt verallgemeinern.
Hier erhält man dann das Resultat, dass sich Tensoren als \(k\)\sphinxhyphen{}Multilinearformen interpretieren lassen mit
\begin{equation*}
\begin{split}\V_1\otimes\ldots\otimes\V_k \cong L^k(\V_1\times\ldots\times\V_k;\R) \cong L(\V_1\otimes\ldots \otimes\V_k;\R).\end{split}
\end{equation*}
\sphinxAtStartPar
In {\hyperref[\detokenize{vektoranalysis/tensor:equation-eq-transitivisomorphismus}]{\sphinxcrossref{(3.4)}}} haben wir die Transitivitätseigenschaft des Tensorprodukts ausgenutzt, um \sphinxstyleemphasis{beide} Vektorräume mit ihren jeweiligen algebraischen Dualräumen zu identifizieren.
Dies muss jedoch nicht sein, denn wir hätten genauso gut \sphinxstylestrong{gemischte Tensorprodukte} der Form \(V \otimes W^\ast\) oder \(V^\ast \otimes W\) betrachten können, wenn wir die triviale Identifikation \(V \cong V\) oder \(W \cong W\) nutzen.
Daher wollen wir im Folgenden Tensoren einer allgemeineren Form betrachten, nämlich solche, die für kartesische Produkte der Form \(V^r\times (V^\ast)^s\) mit \(r+s=k\) definiert sind.
\label{vektoranalysis/tensor:def:gemischteTensoren}
\begin{sphinxadmonition}{note}{Definition 3.5 (Gemischte Tensoren)}



\sphinxAtStartPar
Es sei \(V\) ein reeller endlich\sphinxhyphen{}dimensionaler Vektorraum und \(V^\ast\) der zugehörige algebraische Dualraum.
Dann nennt man
\begin{equation*}
\begin{split}T^r_s(V) := L^k(V^r\times (V^\ast)^s; \R)\end{split}
\end{equation*}
\sphinxAtStartPar
für \(k = r+s \in \N\) die Menge der gemischten Tensoren, welche \sphinxstylestrong{kovariant} der Stufe \(r\) und \sphinxstylestrong{kontravariant} der Stufe \(s\) sind.
In manchen Kontexten spricht man auch nur von \sphinxstylestrong{gemischten Tensoren der Stufe \(k=r+s\)}.
\end{sphinxadmonition}

\sphinxAtStartPar
Die folgende Bemerkung erklärt, woher die Begriffe \sphinxstyleemphasis{Kovarianz} und \sphinxstyleemphasis{Kontravarianz} stammen.
\label{vektoranalysis/tensor:remark-20}
\begin{sphinxadmonition}{note}{Remark 3.10 (Ko\sphinxhyphen{} und Kontravarianz)}



\sphinxAtStartPar
Die Bezeichnungen “kovariant” und “kontravariant” beziehen sich auf die Koordinatendarstellungen von Tensoren.
Genauer gesagt beschreieb Sie, wie sich solche Koordinatendarstellungen bezüglich eines Basiswechsels im zugrundeliegenden Vektorraum verhalten.

\sphinxAtStartPar
Zusammenfassend kann man festhalten:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Kovariant} nennt man ein Transformationsverhalten, bei dem sich die Basisvektoren und die darin dargestellten Größen in gleicher Weise transformieren.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Kontravariant} nennt man ein Transformationsverhalten, wenn sich die Basisvektoren und die darin dargestellten Größen in unterschiedlicher Weise transformieren.

\end{itemize}
\end{sphinxadmonition}

\sphinxAtStartPar
Das folgende Beispiel gibt eine Intuition für den Begriff der Kontravarianz an Hand von Vektorkoordinaten unter Basiswechseloperationen.
\label{vektoranalysis/tensor:example-21}
\begin{sphinxadmonition}{note}{Example 3.8}



\sphinxAtStartPar
Sei \(V = \R^3\) der Euklidische Vektorraum und sei
\begin{equation*}
\begin{split}B_1 := \lbrace \begin{pmatrix}1\\ 0\\ 0\end{pmatrix}, \begin{pmatrix}0\\ 1\\ 0\end{pmatrix}, \begin{pmatrix}0\\ 0\\ 1\end{pmatrix} \rbrace\end{split}
\end{equation*}
\sphinxAtStartPar
die Standard\sphinxhyphen{}Einheitsbasis des \(\R^3\).
Sei nun \(x \in \R^3\) ein Vektor, dessen Koordinaten bezüglich der Basis \(B_1\) gegeben sind als
\begin{equation*}
\begin{split}x = \begin{pmatrix}4\\ 8\\ 2\end{pmatrix}.\end{split}
\end{equation*}
\sphinxAtStartPar
Führen wir nun einen Basiswechsel von \(B_1\) zu einer neuen Basis \(B_2\) mit
\begin{equation*}
\begin{split}B_2 := \lbrace \begin{pmatrix}2\\ 0\\ 0\end{pmatrix}, \begin{pmatrix}0\\ 2\\ 0\end{pmatrix}, \begin{pmatrix}0\\ 0\\ 2\end{pmatrix} \rbrace\end{split}
\end{equation*}
\sphinxAtStartPar
durch, so ändert sich die Koordinatendarstellung von \(x\) bezüglich dieser Transformation zu
\begin{equation*}
\begin{split}x = \begin{pmatrix}2\\ 4\\ 1\end{pmatrix}.\end{split}
\end{equation*}
\sphinxAtStartPar
Wir sehen also, dass durch die Skalierung der Basisvektoren von \(B_1\) um den Faktor \(2\) sich die entsprechende Koordinatendarstellung halbiert, d.h., sich gerade \sphinxstylestrong{gegensätzlich} zur Basistransformation verhält.
Daher sind Vektoren \sphinxstylestrong{kontravariant} bezüglich Basiswechseltransformationen.
\end{sphinxadmonition}

\sphinxAtStartPar
Wir wollen diese allgemeine Definition von gemischten Tensoren nun mit einfachen Beispielen veranschaulichen.
Beginnen wir zunächst mit dem Spezialfall von rein kovarianten Tensoren.
\label{vektoranalysis/tensor:example-22}
\begin{sphinxadmonition}{note}{Example 3.9 (Rein kovariante Tensoren)}



\sphinxAtStartPar
Sei \(V\) ein endlich\sphinxhyphen{}dimensionaler, reeller Vektorraum mit \(\operatorname{dim}(V) = n \in \N\).
Wir wollen im Folgenden Tensoren unterschiedlicher Stufen betrachten, die Multilinearformen repräsentieren.
Diese haben keine \sphinxstyleemphasis{kontravarianten Komponenten}, sind also sozusagen \sphinxstyleemphasis{rein kovariant}.

\sphinxAtStartPar
\sphinxstylestrong{Stufe 0:}
Wir betrachten Tensoren der Stufe \(r+s=0+0=0\).
Elemente der Menge \(T^0_0(V) = L^0(V^0; \R)\) sind gerade die \sphinxstylestrong{Skalare} des zu Grunde liegenden Körpers \(\R\), da der Vektorraum \(V^0\) nur das Nullelement enthält.

\sphinxAtStartPar
\sphinxstylestrong{Stufe 1:}
Wir betrachten Tensoren der Stufe \(r+s=1+0=1\).
In diesem Fall entsprechen Elemente der Menge \(T^1_0(V) = L^1(V; \R)\) gerade den \sphinxstylestrong{Linearformen} des Vektorraums \(V\).
Genauer gesagt handelt es sich um Elemente des \sphinxstyleemphasis{algebraischen Dualraums} \(V^\ast\).

\sphinxAtStartPar
\sphinxstylestrong{Stufe k:}
Wir betrachten Tensoren der Stufe \(r+s=k+0=k\) für \(k\in \N\).
Diese Tensoren entsprechen gerade den \sphinxstylestrong{\(\mathbf{k}\)\sphinxhyphen{}Multilinearformen}, da \(T^k_0(V) = L^k(V^k; \R) = L^k(V; \R)\).

\sphinxAtStartPar
\sphinxstylestrong{Stufe n:}
Wir betrachten Tensoren der Stufe \(r+s=n+0=n\).
Ein Beispiel für Elemente der Menge \(T^n_0(V) = L^n(V^n; \R)\) ist die \sphinxstylestrong{Determinante} einer \(n \times n\)\sphinxhyphen{}Matrix.
\end{sphinxadmonition}

\sphinxAtStartPar
Betrachten wir als Nächstes den Spezialfall von rein kontravarianten Tensoren.
\label{vektoranalysis/tensor:example-23}
\begin{sphinxadmonition}{note}{Example 3.10 (Rein kontravariante Tensoren)}



\sphinxAtStartPar
Sei \(V\) ein endlich\sphinxhyphen{}dimensionaler, reeller Vektorraum.
Diese besitzen keine \sphinxstyleemphasis{kovarianten Komponenten}, sind also sozusagen \sphinxstyleemphasis{rein kontravariant}.

\sphinxAtStartPar
\sphinxstylestrong{Stufe 1:}
Wir betrachten Tensoren der Stufe \(r+s=0+1=1\).
In diesem Fall entsprechen Elemente der Menge \(T^0_1(V) = L^1(V^\ast; \R)\) gerade den \sphinxstylestrong{Vektoren} des Vektorraums \(V\).
Genauer gesagt handelt es sich um Elemente des \sphinxstyleemphasis{Bidualraums} \(V^{**}\), der nach {\hyperref[\detokenize{vektoranalysis/multilinear:rem:doubledual}]{\sphinxcrossref{Remark 3.4}}} isomorph zu \(V\) ist.

\sphinxAtStartPar
\sphinxstylestrong{Stufe 2:}
Wir betrachten Tensoren der Stufe \(r+s=0+2=2\).
In diesem Fall entsprechen Elemente der Menge \(T^0_2(V) = L^2(V^\ast \times V^\ast; \R)\) sogenannten \sphinxstylestrong{Bivektoren} oder \sphinxstylestrong{Dyaden}.
Ein Beispiel hierfür sind Tensoren, die durch \sphinxstyleemphasis{dyadische Produkte} erzeugt werden.
\end{sphinxadmonition}

\sphinxAtStartPar
Abschließend betrachten wir noch ein Beispiel für echt gemischte Tensoren.
\label{vektoranalysis/tensor:example-24}
\begin{sphinxadmonition}{note}{Example 3.11 (Echt gemischte Tensoren)}



\sphinxAtStartPar
Sei \(V\) ein endlich\sphinxhyphen{}dimensionaler, reeller Vektorraum.
Wir wollen im Folgenden \sphinxstyleemphasis{echt gemischte} Tensoren diskutieren.
Diese besitzen sowohl kontravariante als auch kovariante Komponenten.

\sphinxAtStartPar
Wir betrachten echt gemischte Tensoren der Stufe \(r+s=1+1=2\).
Die Menge \(T^1_1(V) = L^2(V^\ast \times V; \R)\) enthält dann alle linearen Abbildung, die einer Linearform und einem Vektor eine reelle Zahl zuweisen.
Ein typisches Beispiel für solch einen ist die sogenannte \sphinxstylestrong{duale Paarung}
\begin{equation*}
\begin{split}\langle \cdot, \cdot \rangle \colon V^\ast \times V &\rightarrow \R,\\
(L, v) &\mapsto \langle L, v \rangle := L(v).\end{split}
\end{equation*}
\sphinxAtStartPar
Hier wird ein gegebener Vektor \(v \in V\) durch einen gegebenen linearen Operator \(L \in V^\ast\) ausgewertet.
Die duale Paarung stellt eine \sphinxstyleemphasis{Verallgemeinerung des Skalarprodukts} dar.
\end{sphinxadmonition}


\subsection{Symmetrie und Antisymmetrie von Tensoren}
\label{\detokenize{vektoranalysis/tensor:symmetrie-und-antisymmetrie-von-tensoren}}\label{\detokenize{vektoranalysis/tensor:s-symtensoren}}
\sphinxAtStartPar
Oft spielen gerade in der Physik spezielle Familien von Tensoren eine wichtige Rolle, nämlich \sphinxstyleemphasis{symmetrische} und \sphinxstyleemphasis{antisymmetrische Tensoren}.
Diese Operatoren zeichnen sich durch ihr Verhalten unter Vertauschung von Argumenten aus und werden besonders in der Quantenmechanik und Kontinuumsmechanik betrachtet.

\sphinxAtStartPar
Bevor wir die Symmetrieeigenschaften von Tensoren definieren können, benötigen wir weitere Hilfsmittel aus der Kombinatorik.
Die Vertauschung von Argumenten entspricht einer Permutationsabbildung und daher wollen wir das \sphinxstyleemphasis{Vorzeichen} solch einer Permutation betrachten, welches die Symmetrieeigenschaften von Tensoren charakterisiert.
\label{vektoranalysis/tensor:def:signumPermutation}
\begin{sphinxadmonition}{note}{Definition 3.6 (Signum einer Permutation)}



\sphinxAtStartPar
Sei \(k\in\N\) und \(\pi \colon \lbrace 1,\ldots, k\rbrace \rightarrow \lbrace 1,\ldots, k\rbrace\) eine Permutation der Indizes \(1,\ldots,k\).
Dann bezeichnen wir mit \(\operatorname{sgn}(\pi) := (-1)^{|\operatorname{inv}(\pi)|}\) das sogenannte \sphinxstylestrong{Signum der Permutation} \(\pi\), für das man die Menge der Fehlstände der Permutation \(\operatorname{inv}(\pi)\) betrachtet mit:
\begin{equation*}
\begin{split}\operatorname{inv}(\pi) := \lbrace i,j \in \lbrace 1, \ldots, k \rbrace : i < j, \pi(i) > \pi(j) \rbrace.\end{split}
\end{equation*}\end{sphinxadmonition}
\label{vektoranalysis/tensor:remark-26}
\begin{sphinxadmonition}{note}{Remark 3.11 (Signum durch Transpositionen)}



\sphinxAtStartPar
Man erhält eine äquivalente Definition indem man die Darstellung einer Permuattaion durch Transpositionen betrachtet. Eine Permuation vertauscht genau zwei Zahlen, konkret, definiert man für \(r,l\in\{1,\ldots,k\}\) die Permutation \(\tau_{rl}:\{1,\ldots,k\}\to\{1,\ldots,k\}\) wie folgt,
\begin{equation*}
\begin{split}\tau_{rl}(i) = 
\begin{cases}
l&\text{ falls } i=r,\\
r&\text{ falls } i=l,\\
i\text{ sonst}
\end{cases}.\end{split}
\end{equation*}
\sphinxAtStartPar
Jede Permutation lässt sich als Verkettung von Nachbarvertauschung darstellen, also Permutationen von benachbarten Elemneten. Konkret gilt für \(r<l\),
\begin{equation*}
\begin{split}\tau_{rl} = \underbrace{\left(\tau_{l-1,l}\circ\ldots\circ \tau_{r+1,r+2} \right)}_{\text{Element }r\text{ nach vorne durchreichen}}\circ
\underbrace{\left(\tau_{r,r+1}\circ\ldots\circ \tau_{l-1,l} \right)}_{\text{Elemnet }l\text{ nach hinten durchreichen}}\end{split}
\end{equation*}
\sphinxAtStartPar
und da jede Nachbarvertauschung einen Fehlstand produziert gilt
\begin{equation*}
\begin{split}|\operatorname{inv}\tau_{rl}| = (l-r) + (l-r-1) = 2(l-r)-1\end{split}
\end{equation*}
\sphinxAtStartPar
was stets ungerade ist und somit haben wir \(\operatorname{sgn}(\tau_{rl}) = -1\) für belibiebige Transpositionen ungleich der Identität.
Sei \(\pi\) nun eine Permutation und \(M(\pi)\) die Anzahl der Transpostionen mit welcher wir \(\pi\) darstellen können, dann gilt
\begin{equation*}
\begin{split}\operatorname{sgn}(\pi) = -1^{M(\pi)}.\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Das folgende einfache Beispiel illustriert die Berechnung des Signums einer Permutation.
\label{vektoranalysis/tensor:example-27}
\begin{sphinxadmonition}{note}{Example 3.12 (Signum zweier Permutationen)}



\sphinxAtStartPar
Wir betrachten im Folgenden zwei verschiedene Permutationen
\begin{equation*}
\begin{split}\pi_i \colon \lbrace 1, 2, 3, 4 \rbrace \rightarrow \lbrace 1, 2, 3, 4 \rbrace \quad i=1,2.\end{split}
\end{equation*}


\sphinxAtStartPar
1. Sei die Permutation \(\pi_1\) gegeben mit
\begin{equation*}
\begin{split}\pi_1(1) = 3, \quad \pi_1(2) = 2, \quad \pi_1(3) = 4, \quad \pi_1(4) = 1.\end{split}
\end{equation*}
\sphinxAtStartPar
Für die Menge der Fehlstände \(\operatorname{inv}(\pi_1)\) selektieren wir diejenigen Elemente \(i,j \in \lbrace 1,2,3,4 \rbrace\) mit \(i < j\) und \(\pi(i) > \pi(j)\).
Dies trifft auf folgende Paare von Elementen zu:
\begin{equation*}
\begin{split}\operatorname{inv}(\pi_1) = \lbrace (1,2), (1,4), (2,4), (3,4)\rbrace.\end{split}
\end{equation*}
\sphinxAtStartPar
Da die Permutation \(\pi_1\) insgesamt \(4\) Fehlstände erzeugt, gilt für das Signum der Permutation:
\begin{equation*}
\begin{split}\operatorname{sgn}(\pi_1) := (-1)^{|\operatorname{inv}(\pi_1)|} = (-1)^4 = +1.\end{split}
\end{equation*}


\sphinxAtStartPar
2. Sei die Permutation \(\pi_2\) gegeben mit
\begin{equation*}
\begin{split}\pi_1(1) = 2, \quad \pi_1(2) = 4, \quad \pi_1(3) = 1, \quad \pi_1(4) = 3.\end{split}
\end{equation*}
\sphinxAtStartPar
Für die Menge der Fehlstände \(\operatorname{inv}(\pi_2)\) selektieren wir diejenigen Elemente \(i,j \in \lbrace 1,2,3,4 \rbrace\) mit \(i < j\) und \(\pi(i) > \pi(j)\).
Dies trifft auf folgende Paare von Elementen zu:
\begin{equation*}
\begin{split}\operatorname{inv}(\pi_2) = \lbrace (1,3), (2,3), (2,4)\rbrace.\end{split}
\end{equation*}
\sphinxAtStartPar
Da die Permutation \(\pi_2\) insgesamt \(3\) Fehlstände erzeugt, gilt für das Signum der Permutation:
\begin{equation*}
\begin{split}\operatorname{sgn}(\pi_2) := (-1)^{|\operatorname{inv}(\pi_2)|} = (-1)^3 = -1.\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Nun sind wir in der Lage die Symmetrieeigenschaften von Tensoren formal zu definieren.
\label{vektoranalysis/tensor:def:symmetrieTensor}
\begin{sphinxadmonition}{note}{Definition 3.7 (Symmetrie und Antisymmetrie von Tensoren)}



\sphinxAtStartPar
Sei V ein reeller, endlich\sphinxhyphen{}dimensionaler Vektorraum und \(T \in T_k^0(V)\) ein rein kontravarianter Tensor von Stufe \(k \in \N\).

\sphinxAtStartPar
Wir nennen den Tensor \(T\) \sphinxstylestrong{symmetrisch}, wenn für alle möglichen Permutationen \(\pi \colon \lbrace 1,\ldots, k\rbrace \rightarrow \lbrace 1,\ldots, k\rbrace\) der Indizes \(1,\ldots,k\) der Wert des Tensors mit permutierten Argumenten sich nicht ändert, d.h.,
\begin{equation*}
\begin{split}T(v_1, \ldots, v_k) = T(v_{\pi(1)}, \ldots, v_{\pi(k)}).\end{split}
\end{equation*}
\sphinxAtStartPar
Wir nennen den Tensor \(T\) \sphinxstylestrong{antisymmetrisch} oder \sphinxstylestrong{schiefsymmetrisch}, wenn für alle möglichen Permutationen \(\pi \colon \lbrace 1,\ldots, k\rbrace \rightarrow \lbrace 1,\ldots, k\rbrace\) der Indizes \(1,\ldots,k\) der Wert des Tensors mit permutierten Argumenten sich \sphinxstyleemphasis{bis auf das Vorzeichen} nicht ändert und dabei folgendem Zusammenhang genügt
\begin{equation*}
\begin{split}T(v_1, \ldots, v_k) = \operatorname{sgn}(\pi) \cdot T(v_{\pi(1)}, \ldots, v_{\pi(k)}).\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
In {\hyperref[\detokenize{vektoranalysis/tensor:def:symmetrieTensor}]{\sphinxcrossref{Definition 3.7}}} haben wir die Symmetrieeigenschaften für rein kontravariante Tensoren eingeführt.
Analog lässt sich die (Anti\sphinxhyphen{})Symmetrie eines rein kovarianten Tensors \(T \in T^k_0(V)\) von Stufe \(k\) definieren.
Die Definition von Symmetrie bzw. Antisymmetrie von echt gemischten Tensoren aus {\hyperref[\detokenize{vektoranalysis/tensor:def:gemischteTensoren}]{\sphinxcrossref{Definition 3.5}}} ist hingegen wenig sinnvoll, da die Rechenvorschrift eine gemischten Tensors unter beliebigen Permutationen der Argumente nicht mehr wohldefiniert sein muss.

\sphinxAtStartPar
Im folgenden Beispiel diskutieren wir jeweils einen Vertreter für symmetrische und antisymmetrische Tensoren.

\begin{sphinxShadowBox}
\sphinxstylesidebartitle{Tullio Levi\sphinxhyphen{}Civita}

\sphinxAtStartPar
\sphinxhref{https://en.wikipedia.org/wiki/Tullio\_Levi-Civita}{Tullio Levi\sphinxhyphen{}Civita} (Geboren 29. März 1873 in Padua; Gestorben 29. Dezember 1941 in Rom) war ein italienischer Mathematiker.
\end{sphinxShadowBox}
\label{vektoranalysis/tensor:example-29}
\begin{sphinxadmonition}{note}{Example 3.13 (Symmetrieeigenschaften von Tensoren)}



\sphinxAtStartPar
Betrachten wir zunächst das \sphinxstyleemphasis{Standardskalarprodukt}
\begin{equation*}
\begin{split}\langle \cdot, \cdot \rangle \colon \R^n \times \R^n \rightarrow \R\end{split}
\end{equation*}
\sphinxAtStartPar
als rein kontravarianten Tensor zweiter Stufe.
Da das Standardskalarprodukt im \(\R^n\) eine positiv definite, symmetrische Bilinearform ist, überträgt sich die Symmetrieeigenschaft auf die Interpretation als Tensor.
Daher ist das Standardskalarprodukt ein \sphinxstylestrong{symmetrischer Tensor}.



\sphinxAtStartPar
Als zweites Beispiel betrachten wir das sogenannte \sphinxstyleemphasis{Levi\sphinxhyphen{}Civita\sphinxhyphen{}Symbol}, auch genannt \sphinxstyleemphasis{Epsilon\sphinxhyphen{}Tensor},
\begin{equation*}
\begin{split}\epsilon_{i_1,\ldots,i_n} :=
\begin{cases}
\operatorname{sgn}((i_1,\ldots,i_n))&\text{ falls }(i_1,\ldots,i_n)\text{ eine Permutation beschreibt,}\\
0&\text{ sonst,}
\end{cases}\end{split}
\end{equation*}
\sphinxAtStartPar
welcher einem Tupel von \(n\in\N\) Indizes \((i_1,\ldots,i_n) \in \N^n\) einen Wert zuordnet, je nachdem ob eine gerade oder eine ungerade Anzahl an Vertauschung benötigt wird, um die Indizes in aufsteigender Reihenfolge zu sortieren.
Wird eine gerade Anzahl an Vertauschungen benötigt, so gilt \(\epsilon_{i_1,\ldots,i_n} = +1\).
Wird eine ungerade Anzahl an Vertauschungen benötigt, so gilt \(\epsilon_{i_1,\ldots,i_n} = -1\).
Aus letzterer Vorschrift lässt sich ableiten, dass der Epsilon\sphinxhyphen{}Tensor den Wert \(0\) haben muss, wenn mindestens zwei der Indizes gleich sind.
Dies unterscheidet das Levi\sphinxhyphen{}Civita\sphinxhyphen{}Symbol vom Signum einer Permutation in {\hyperref[\detokenize{vektoranalysis/tensor:def:signumPermutation}]{\sphinxcrossref{Definition 3.6}}}, welche als Bijektion auf paarweise verschiedenen Indizes definiert ist.

\sphinxAtStartPar
Aus dieser Vorschrift lässt sich bereits direkt ableiten, dass es sich beim Levi\sphinxhyphen{}Civita\sphinxhyphen{}Symbol um einen \sphinxstylestrong{antisymmetrischen Tensor} n\sphinxhyphen{}ter Stufe handelt, da jede paarweise Vertauschung von Indizes das Vorzeichen des Tensors wechselt.
\end{sphinxadmonition}

\sphinxAtStartPar
Es stellt sich heraus, dass die Menge der (anti\sphinxhyphen{})symmetrischen Tensoren eine Vektorraumstruktur induzieren, wie das folgende Lemma zeigt.
\label{vektoranalysis/tensor:lemma-30}
\begin{sphinxadmonition}{note}{Lemma 3.8 (Vektorraum der (anti\sphinxhyphen{})symmetrischen Tensoren)}



\sphinxAtStartPar
Sei \(V\) ein endlich\sphinxhyphen{}dimensionaler, reeller Vektorraum mit \(\operatorname{dim}(V) = n \in \N\) und sei \(k \in \N\) mit \(k \leq n\).
Seien außerdem
\begin{equation*}
\begin{split}\Lambda_k(V) = \lbrace \omega \in T_k^0(V) : \omega \text{ ist antisymmetrisch} \rbrace.\end{split}
\end{equation*}
\sphinxAtStartPar
die Menge der \sphinxstyleemphasis{antisymmetrischen Tensoren} der Stufe \(k\) auf \(V\) und
\begin{equation*}
\begin{split}\mathcal{S}_k(V) = \lbrace \omega \in T_k^0(V) : \omega \text{ ist symmetrisch} \rbrace.\end{split}
\end{equation*}
\sphinxAtStartPar
die Menge der \sphinxstyleemphasis{symmetrischen Tensoren} der Stufe \(k\) auf \(V\).

\sphinxAtStartPar
Dann bilden \(\Lambda_k(V)\) und \(\mathcal{S}_k(V)\) bezüglich der Addition von Tensoren und der skalaren Multiplikation in \(\R\) einen reellen Vektorraum.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. In der Hausaufgabe zu zeigen.
\end{sphinxadmonition}

\sphinxAtStartPar
Abschließend wollen wir uns in diesem Abschnitt noch einem nützlichen mathematischen Werkzeug widmen, das es erlaubt beliebige Tensoren symmetrisch bzw. antisymmetrisch zu machen.
Hierzu definieren wir die folgenden Projektionsabbildungen.
\label{vektoranalysis/tensor:def:fermionischeProjektion}
\begin{sphinxadmonition}{note}{Definition 3.8 (Fermionische und bosonische Projektion)}



\sphinxAtStartPar
Sei \(V\) ein beliebiger, reeller Vektorraum und \(k \in \N\).
Wir definieren zunächst die sogenannte \sphinxstylestrong{fermionische Projektion}
\begin{equation*}
\begin{split}\Pi_- \colon T_k^0(V) &\rightarrow \Lambda_k(V), \\
T(v_1, \ldots, v_k) &\mapsto (\Pi_- T)(v_1, \ldots, v_k) := \frac{1}{k!} \sum_{\pi \in S_k} \operatorname{sgn}(\pi) \, T(v_{\pi(1)}, \ldots, v_{\pi(k)}).\end{split}
\end{equation*}
\sphinxAtStartPar
Diese Projektionsabbildung weist jedem Tensor \(T\in T_k^0\) der Stufe \(k\) einen antisymmetrischen Tensor \(\Pi_-(T) \in \Lambda_k(V)\) zu.

\sphinxAtStartPar
Analog definieren wir die sogenannte \sphinxstylestrong{bosonische Projektion}
\begin{equation*}
\begin{split}\Pi_+ \colon T_k^0(V) &\rightarrow \mathcal{S}_k(V), \\
T(v_1, \ldots, v_k) &\mapsto (\Pi_+ T)(v_1, \ldots, v_k) := \frac{1}{k!} \sum_{\pi \in S_k} T(v_{\pi(1)}, \ldots, v_{\pi(k)}).\end{split}
\end{equation*}
\sphinxAtStartPar
Diese Projektionsabbildung weist jedem Tensor \(T\in T_k^0\) der Stufe \(k\) einen symmetrischen Tensor \(\Pi_+(T) \in \mathcal{S}_k(V)\) zu.
\end{sphinxadmonition}
\label{vektoranalysis/tensor:remark-32}
\begin{sphinxadmonition}{note}{Remark 3.12}



\sphinxAtStartPar
Die Bezeichnung \sphinxstylestrong{fermionisch} und \sphinxstylestrong{bosonisch} in {\hyperref[\detokenize{vektoranalysis/tensor:def:fermionischeProjektion}]{\sphinxcrossref{Definition 3.8}}} stammen daher, dass symmetrische Tensorprodukte \sphinxstyleemphasis{identische Bosonen} in der Quantenmechanik beschreiben, wohingegen antisymmetrische Tensorprodukte \sphinxstyleemphasis{identischen Fermionen} zugeordnet werden. Weitere Informationen findet man beispielsweise unter \sphinxhref{https://de.wikipedia.org/wiki/Ununterscheidbare\_Teilchen\#Ununterscheidbarkeit\_in\_der\_Quantenmechanik}{Ununterscheidbarkeit von Teilchen in der Quantenmechanik}.
\end{sphinxadmonition}


\subsection{Grassmann\sphinxhyphen{}Algebra}
\label{\detokenize{vektoranalysis/tensor:grassmann-algebra}}
\sphinxAtStartPar
Im letzten Abschnitt haben wir gesehen, dass die Menge der antisymmetrischen Tensoren von Stufe zusammen mit der Addition von Tensoren der gleichen Stufe einen Vektorraum \(\Lambda_k(V)\) bildet.
Im Folgenden werden wir sehen, dass wir sogar noch mehr Struktur in Form einer Algebra erhalten, wenn wir den Vektorraum mit einer verträglichen Multiplikation von Tensoren erweitern.

\sphinxAtStartPar
Zunächst wollen wir das äußere Produkt zweier Tensoren definieren.
\label{vektoranalysis/tensor:def:aeusseresProduktTensoren}
\begin{sphinxadmonition}{note}{Definition 3.9 (Äußeres Produkt von Tensoren)}



\sphinxAtStartPar
Sei \(V\) ein endlich\sphinxhyphen{}dimensionaler, reeller Vektorraum und seien \(r,r',s,s' \in \N\).
Sei außerdem \(T \in T^r_s(V)\) ein Tensor, der kovariant von Stufe \(r\) und kontravariant von Stufe \(s\) ist und sei \(T' \in T^{r'}_{s'}(V)\) ein Tensor, der kovariant von Stufe \(r'\) und kontravariant von Stufe \(s'\) ist.

\sphinxAtStartPar
Dann wird das \sphinxstylestrong{äußere Tensorprodukt} von \(T\) und \(T'\) (manchmal auch \sphinxstylestrong{Tensormultiplikation} genannt) als folgende Abbildung definiert:
\begin{equation*}
\begin{split}(T \otimes T')(v_1,\ldots,v_r,v'_1,\ldots,v'_{r'},&w_1,\ldots,w_s,w'_1,\ldots,w'_{s'}) := \\
&T(v_1,\ldots,v_r,w_1,\ldots,w_s)\cdot T'(v'_1,\ldots,v'_{r'},w'_1,\ldots,w'_{s'}).\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Wir sehen also, dass das Tensorprodukt von Tensoren unterschiedlicher Stufe eine Abbildung induziert, die per Definition einen Tensor höherer Stufe liefert, d.h.,
\begin{equation*}
\begin{split}\otimes : T^r_s(V) \times T^{r'}_{s'}(V) \rightarrow T^{r+r'}_{s+s'}(V),\end{split}
\end{equation*}
\sphinxAtStartPar
Mit Hilfe des äußeren Produkts von Tensoren in {\hyperref[\detokenize{vektoranalysis/tensor:def:aeusseresProduktTensoren}]{\sphinxcrossref{Definition 3.9}}} sind wir nun in der Lage ein äußeres Produkt für antisymmetrische Tensoren zu definieren.
\label{vektoranalysis/tensor:def:aeusseresProdukt}
\begin{sphinxadmonition}{note}{Definition 3.10 (Äußeres Produkt von antisymmetrischen Tensoren)}



\sphinxAtStartPar
Sei \(V\) ein endlich\sphinxhyphen{}dimensionaler, reeller Vektorraum mit \(\operatorname{dim}(V) = n\) und seien \(\Lambda_k(V), \Lambda_l(V)\) jeweils die Vektorräume der \sphinxstyleemphasis{antisymmetrischen Tensoren} der Stufe \(k\in\N\) und \(l\in\N\).
Wir definieren das sogenannte \sphinxstylestrong{äußere Produkt} als die folgende Abbildung
\begin{equation*}
\begin{split}\wedge : \Lambda_k(V) \times \Lambda_l(V) &\rightarrow \Lambda_{k+l}(V),\\
(\omega, \eta) &\mapsto \wedge(\omega,\eta) = \frac{(k+l)!}{k! \, l!} \Pi_-(\omega \otimes \eta).\end{split}
\end{equation*}
\sphinxAtStartPar
Häufig wird für das äußere Produkt die Infix\sphinxhyphen{}Notation verwendet, d.h., \(\omega \wedge \eta :=  \wedge(\omega,\eta)\).
\end{sphinxadmonition}

\sphinxAtStartPar
Das folgende Lemma fasst die wichtigsten Eigenschaften des äußeren Produkts von antisymmetrischen Tensoren zusammen.
\label{vektoranalysis/tensor:lemma-35}
\begin{sphinxadmonition}{note}{Lemma 3.9 (Eigenschaften des äußeren Produkts)}



\sphinxAtStartPar
Sei \(V\) ein endlich\sphinxhyphen{}dimensionaler, reeller Vektorraum und \(\lambda \in \R\) ein Skalar.
Seien außerdem folgende antisymmetrische Tensoren gegeben: \(\omega, \omega' \in \Lambda_k(V), \eta \in \Lambda_l(V), \tau \in \Lambda_m(V)\).

\sphinxAtStartPar
Dann besitzt das äußere Produkt \(\wedge\) von antisymmetrischen Tensoren die folgenden Eigenschaften:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\((\omega \wedge \eta) \wedge \tau = \omega \wedge (\eta \wedge \tau), \qquad \) (\sphinxstylestrong{Assoziativität})

\item {} 
\sphinxAtStartPar
\((\omega + \lambda \omega') \wedge \eta = \omega \wedge \eta + \lambda \omega' \wedge \eta\quad\) und analog im 2. Argument, (\sphinxstylestrong{Bilinearität})

\item {} 
\sphinxAtStartPar
\(\omega \wedge \eta = (-1)^{kl} \eta \wedge \omega. \qquad\) (\sphinxstylestrong{Antikommutativität})

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. In der Hausaufgabe zu zeigen.
\end{sphinxadmonition}

\sphinxAtStartPar
Mit Hilfe der obigen Eigenschaften, insbesondere der Assoziativität, lässt sich das äußere Produkt für \(k \in \N\) Tensoren verallgemeinern, wie folgende Bemerkung festhält.
\label{vektoranalysis/tensor:remark-36}
\begin{sphinxadmonition}{note}{Remark 3.13 (\protect\(k\protect\)\sphinxhyphen{}faches äußeres Produkt)}



\sphinxAtStartPar
Sei \(V\) ein endlich\sphinxhyphen{}dimensionaler, reeller Vektorraum und seien \(\omega_i \in \Lambda_{n_i}(V), i=1,\ldots,k\) antisymmetrische Vektoren der Stufe \(n_i \in \N\).

\sphinxAtStartPar
Dann gilt für das \(k\)\sphinxhyphen{}fache äußere Produkt von antisymmetrischen Tensoren,
\begin{equation}\label{equation:vektoranalysis/tensor:eq:kfachesProdukt}
\begin{split}\omega_1 \wedge \ldots \wedge \omega_k = \frac{(n_1 + \ldots + n_k)!}{n_1!\cdot \ldots \cdot n_k!} \Pi_-(\omega_1 \otimes \ldots \otimes \omega_k).\end{split}
\end{equation}\end{sphinxadmonition}

\sphinxAtStartPar
Das folgende Theorem erweist sich als nützliche Einsicht, die im Laufe der Vorlesung noch von Bedeutung sein wird.
Es besagt, dass das äußere Produkt von Linearformen mittels einer Determinante berechnet werden kann.
\label{vektoranalysis/tensor:theorem-37}
\begin{sphinxadmonition}{note}{Theorem 3.3 (Äußeres Produkt von Linearformen)}



\sphinxAtStartPar
Sei \(V\) ein endlich\sphinxhyphen{}dimensionaler, reeller Vektorraum und \(k \in \N\).
Seien außerdem \(\omega_1, \ldots, \omega_k \in V^\ast\) Linearformen auf \(V\) und \(v_1, \ldots, v_k \in V\) beliebige Vektoren.

\sphinxAtStartPar
Dann lässt sich der antisymmetrische, rein kovariante Tensor \(k\)\sphinxhyphen{}ter Stufe, der durch das äußere Produkt \(\omega_1 \wedge \ldots \wedge \omega_k \in \Lambda_k(V)\) gegeben ist berechnen als
\begin{equation*}
\begin{split}(\omega_1 \wedge \ldots \wedge \omega_k)(v_1, \ldots, v_k) = \operatorname{det}
\begin{pmatrix}
\omega_1(v_1) & \cdots & \omega_k(v_1)\\
\vdots & & \vdots \\
\omega_1(v_k) & \cdots & \omega_k(v_k)
\end{pmatrix}.\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Seien \(v_1,\ldots,v_k \in V\) beliebige Vektoren.
Dann gilt nach der Definition des \(k\)\sphinxhyphen{}fachen äußeren Produkts in {\hyperref[\detokenize{vektoranalysis/tensor:equation-eq-kfachesprodukt}]{\sphinxcrossref{(3.5)}}} folgender Zusammenhang
\begin{equation*}
\begin{split}(\omega_1 \wedge \ldots \wedge \omega_k)(v_1, \ldots, v_k) &= \frac{(1+\ldots+1)!}{1!\cdot\ldots\cdot1!} \cdot \Pi_-(\omega_1 \otimes \ldots \otimes \omega_k)(v_1,\ldots,v_k) \\
&= k! \cdot \Pi_-(\omega_1 \otimes \ldots \otimes \omega_k)(v_1,\ldots,v_k) \\
&= k! \frac{1}{k!} \sum_{\pi\in \mathcal{S}_k}\operatorname{sgn}(\pi) (\omega_1 \otimes \ldots \otimes \omega_k)(v_{\pi(1)},\ldots,v_{\pi(k)}) \\
&= \sum_{\pi\in \mathcal{S}_k}\operatorname{sgn}(\pi) \, \omega_1(v_{\pi(1)})\cdot \ldots \cdot \omega_k(v_{\pi(k)}) \\
&= \operatorname{det}
\begin{pmatrix}
\omega_1(v_1) & \cdots & \omega_k(v_1)\\
\vdots & & \vdots \\
\omega_1(v_k) & \cdots & \omega_k(v_k)
\end{pmatrix}.\end{split}
\end{equation*}
\sphinxAtStartPar
Bei der letzten Gleichung haben wir den \sphinxstylestrong{Determinantenproduktsatz} aus Satz 3.40 in {[}\hyperlink{cite.references:id2}{Bur20}{]} verwendet.
\end{sphinxadmonition}

\sphinxAtStartPar
Das folgende Lemma weist auf eine interessante Eigenschaft des Vektorraums der antisymmetrischen Tensoren hin, für den Fall, dass die Stufe der zugehörigen Tensoren größer als die Dimension des zu Grunde liegenden Vektorraums \(V\) ist.
\label{vektoranalysis/tensor:lem:tensorStufe}
\begin{sphinxadmonition}{note}{Lemma 3.10}



\sphinxAtStartPar
Sei \(V\) ein endlich\sphinxhyphen{}dimensionaler, reeller Vektorraum mit \(\operatorname{dim}(V) = n \in \N\).
Sei außerdem \(\Lambda_k(V)\) der Vektorraum der antisymmetrischen Tensoren der Stufe \(k\in\N\) mit \(k > n\).
Dann gilt schon \(\Lambda_k(V) = \lbrace 0 \rbrace\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Da \(V\) ein endlich\sphinxhyphen{}dimensionaler Vektorraum mit \(\operatorname{dim}(V)=n \in \N\) ist, wissen wir, dass eine Basis \(B\) von \(V\) aus \(n\) Vektoren \(B := \lbrace b_1,\ldots,b_n \rbrace \in V\) existiert.
Dies bedeutet insbesondere, dass die Vektoren von \(B\) ein maximales System von linear unabhängigen Vektoren sind, die gleichzeitig noch ein Erzeugendensystem bilden.
Jeder weitere Vektor \(v \in V\), den wir zu diesem System hinzunehmen lässt sich somit als Linearkombination der Basisvektoren von \(B\) darstellen.

\sphinxAtStartPar
Sei nun \(\omega \in \Lambda_k(V)\) ein antisymmetrischer, rein kovarianter Tensor der Stufe \(k > n\).
Da dieser insbesondere eine \(k\)\sphinxhyphen{}Multilinearform darstellt, können wir für beliebige Vektoren \(v_1, \ldots, v_k \in V\) schreiben:
\begin{equation}\label{equation:vektoranalysis/tensor:eq:antisymmetrischerTensor}
\begin{split}\omega(v_1, \ldots, v_k) &= \omega(\sum_{i=1}^n \alpha_i^1 b_i, \ldots, \sum_{i=1}^n \alpha_i^k b_i) = \sum_{j_1=1}^n \alpha_{j_1}^1 \omega(b_{j_1}, \sum_{i=1}^n \alpha_i^2 b_i, \ldots, \sum_{i=1}^n \alpha_i^k b_i) \\
&= \sum_{j_1=1}^n \ldots \sum_{j_k=1}^n \alpha_{j_1}^1 \ldots \alpha_{j_k}^k \cdot \omega(b_{j_1}, \ldots, b_{j_k}).\end{split}
\end{equation}
\sphinxAtStartPar
Wir sehen also, dass der Tensor sich auf die Wirkung der Basisvektoren von \(B\) zurückzuführen lässt und alle Summanden die Form \(\omega(b_{j_1}, \ldots, b_{j_k})\) besitzen.
Da wir \(k > n\) angenommen haben, müssen mindestens zwei Basisvektoren gleich sein für jeden dieser Summanden.

\sphinxAtStartPar
Betrachten wir nun einen einzelnen Summanden für den wir ohne Beschränkung der Allgemeinheit annehmen, dass der der \(s\)\sphinxhyphen{}te und \(t\)\sphinxhyphen{}te Eintrag gleich sind für \(1 \leq s \neq t \leq n\), d.h., \(b_{j_s}=b_{j_t}\).
Da der Tensor \(\omega\) antisymmetrisch ist, gilt jedoch:
\begin{equation*}
\begin{split}\omega(b_{j_1}, \ldots, b_{j_s}, \ldots, b_{j_t}, \ldots, b_{j_k}) &= (-1) \cdot \omega(b_{j_1}, \ldots, b_{j_t}, \ldots, b_{j_s}, \ldots, b_{j_k}) \\
&= - \omega(b_{j_1}, \ldots, b_{j_s}, \ldots, b_{j_t}, \ldots, b_{j_k}) = 0.\end{split}
\end{equation*}
\sphinxAtStartPar
Da also jeder Summand in {\hyperref[\detokenize{vektoranalysis/tensor:equation-eq-antisymmetrischertensor}]{\sphinxcrossref{(3.6)}}} Null ist, handelt es sich also bei dem antisymmetrischen Tensor \(\omega\) um den \sphinxstyleemphasis{Nulltensor}, der alle Tupel \((x_1, \ldots, x_k) \in V^k\) auf die Null abbildet.
Hieraus folgt nun die Behauptung, denn es gilt \(\Lambda_k(V) = \lbrace 0 \rbrace\) für \(k > n =\operatorname{dim}(V)\).
\end{sphinxadmonition}

\sphinxAtStartPar
Mit der Aussage aus {\hyperref[\detokenize{vektoranalysis/tensor:lem:tensorStufe}]{\sphinxcrossref{Lemma 3.10}}} wird klar, dass wenn wir die \sphinxstylestrong{direkte Summe} der Vektorräume von antisymmetrischen Tensoren der Stufe \(k\) bilden, wir nur bis zur Stufe \(k = n = \operatorname{dim}(V)\) gehen müssen, da anschließend nur Nullvektorräume hinzugefügt werden.
Das heißt insbesondere, dass für den \(\R\)\sphinxhyphen{}Vektorraum der durch die direkte Summe gebildet wird gilt:
\begin{equation*}
\begin{split}\Lambda(V) := \bigoplus_{k=1}^\infty \Lambda_k(V) = \bigoplus_{k=1}^n \Lambda_k(V).\end{split}
\end{equation*}
\sphinxAtStartPar
Mit dieser Erkenntnis lässt sich die sogenannte Grassmann\sphinxhyphen{}Algebra für antisymmetrische Tensoren definieren, wie folgende Bemerkung festhält.
\label{vektoranalysis/tensor:remark-39}
\begin{sphinxadmonition}{note}{Remark 3.14 (Grassmann\sphinxhyphen{}Algebra)}



\sphinxAtStartPar
Die Menge
\begin{equation*}
\begin{split}\Lambda(V) := \bigoplus_{k=1}^n \Lambda_k(V) = \Lambda_1(V) \times \ldots \times \Lambda_n(V)\end{split}
\end{equation*}
\sphinxAtStartPar
bildet zusammen mit den Verknüpfungen der \sphinxstyleemphasis{Tensoraddition} “\(+\)” und der \sphinxstyleemphasis{skalaren Multiplikation} “\(\cdot\)” in \(\R\) als direkte äußere Summe von Vektorräumen wiederum einen \sphinxstylestrong{reellen Vektorraum} \((\Lambda(V), +, \cdot)\).

\sphinxAtStartPar
Erweitert man diesen um die bilineare Verknüpfung, die durch das \sphinxstyleemphasis{äußere Produkt} \(\wedge\) in {\hyperref[\detokenize{vektoranalysis/tensor:def:aeusseresProdukt}]{\sphinxcrossref{Definition 3.10}}} beschrieben wird, so erhält man eine Algebra \((\Lambda(V), +, \cdot, \wedge)\).
Diese wird auch \sphinxstylestrong{Grassmann\sphinxhyphen{}Algebra} oder \sphinxstylestrong{äußere Algebra} genannt.
\end{sphinxadmonition}


\section{Differentialformen auf Mannigfaltigkeiten}
\label{\detokenize{vektoranalysis/diffformen:differentialformen-auf-mannigfaltigkeiten}}\label{\detokenize{vektoranalysis/diffformen::doc}}
\sphinxAtStartPar
In diesem Kapitel der Vektoranalysis werden wir nun \sphinxhref{https://de.wikipedia.org/wiki/Differentialform}{Differentialformen} einführen.
Die entscheidende Neuerung im Vergleich zum vorangegangen Kapitel über Tensoren ist, dass wir zusätzlich zur Vektorraumstruktur nun ein Konzept von Räumlichkeit einführen.
Außerdem werden wir im Folgenden mit \sphinxstyleemphasis{glatten Funktion} arbeiten, d.h., mit Funktionen aus dem Raum \(C^\infty(U,\R^n)\).

\sphinxAtStartPar
Um Differentialformen vernünftig einführen zu können benötigen wir allerdings einige zusätzliche mathematische Konzepte, die bisher noch nicht behandelt wurden.
Wir definieren zunächst den Begriff des topologischen Raums als Verallgemeinerung von metrischen Vektorräumen.
Anschließend sind wir in der Lage Mannigfaltigkeiten als spezielle topologische Räume zu definieren, die lokal dem Euklidischen Raum \(\R^n\) ähneln, jedoch global verschieden sein können.
Schließlich werden wir Tensorfelder und Differentialformen diskutieren.


\subsection{Topologische Räume}
\label{\detokenize{vektoranalysis/diffformen:topologische-raume}}
\sphinxAtStartPar
Wir haben bisher immer Mathematik auf \sphinxstylestrong{metrischen} oder gar \sphinxstylestrong{normierten Vektorräumen} betrieben, da uns diese Struktur für alle erklärten Konzepte am dienlichsten war (siehe Kapitel 4 \& 5 in {[}\hyperlink{cite.references:id2}{Bur20}{]} und \sphinxhref{https://fau-ammn.github.io/MathDataScience2/normierte\_raeume/normierte\_raeume.html}{MP\sphinxhyphen{}2 Skript}).
Als Vorbereitung für {\hyperref[\detokenize{vektoranalysis/diffformen:s-mannigfaltigkeiten}]{\sphinxcrossref{\DUrole{std,std-ref}{Mannigfaltigkeiten}}}} wollen wir von den metrischen Räumen zu allgemeineren Strukturen wechseln \sphinxhyphen{} den sogenannten \sphinxstylestrong{topologischen Räumen}.

\sphinxAtStartPar
Das zentrale Konzept topologischer Räume ist die folgende Definition der \sphinxstyleemphasis{offene Mengen}.
\label{vektoranalysis/diffformen:definition-0}
\begin{sphinxadmonition}{note}{Definition 3.11 (Offene Mengen und topologischer Raum)}



\sphinxAtStartPar
Sei \(\M\) eine Menge und \(\tau \subset \mathcal{P}(M)\) eine Teilmenge der Potenzmenge.
Wir nennen das Tupel \((\M,\tau)\) \sphinxstylestrong{topologischer Raum}, falls die folgenden Eigenschaften erfüllt sind,
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\emptyset, \M \in \tau\),

\item {} 
\sphinxAtStartPar
für eine beliebige (insbesondere auch \sphinxstyleemphasis{unendlich große}) Indexmenge \(\mathcal{I}\) seien \(U_i\in\tau, i\in \mathcal{I}\). Dann gilt auch schon \(\bigcup_{i\in I} U_i \in \tau\),

\item {} 
\sphinxAtStartPar
für \sphinxstyleemphasis{endlich viele} \(U_j\in\tau, j=1,\ldots, k\) gilt auch schon \(\bigcap_{j=1}^k U_j \in \tau\).

\end{itemize}

\sphinxAtStartPar
Wir bezeichnen mit \(\tau\) die \sphinxstylestrong{Topologie} des Raumes und dessen Elemente \(U\in\tau\) heißen \sphinxstylestrong{offene Mengen}.
Für jeden Punkt \(x\in \M\) nennen wir eine offene Menge \(U(x) \in \tau\) \sphinxstylestrong{Nachbarschaft} oder \sphinxstylestrong{Umgebung} um \(x\), falls \(x\in U(x)\).

\sphinxAtStartPar
Analog zur Definition auf metrischen Räumen bezeichnen wir das Komplement \(\M \setminus U\) \textbackslash{}einer offenen Menge \(U\) als \sphinxstylestrong{abgeschlossen}.
\end{sphinxadmonition}

\sphinxAtStartPar
Es gibt viele interessante topologische Räume, die den Namen ihrer Entdecker tragen, wie zum Beispiel der \sphinxhref{https://de.wikipedia.org/wiki/Arens-Fort-Raum}{Arens\sphinxhyphen{}Fort\sphinxhyphen{}Raum}, der \sphinxhref{https://de.wikipedia.org/wiki/Cantor-Raum}{Cantor\sphinxhyphen{}Raum}, oder der \sphinxhref{https://de.wikipedia.org/wiki/Hilbertw\%C3\%BCrfel}{Hilbertwürfel}.
Im Folgenden wollen wir ein relativ generisches Beispiel für einen topologischen Raum betrachten.
\label{vektoranalysis/diffformen:ex:diskreteTopologie}
\begin{sphinxadmonition}{note}{Example 3.14 (Diskrete Topologie)}



\sphinxAtStartPar
Es sei \(M\) eine beliebige Menge.
Dann können wir eine Topologie \(\tau\) auf \(\M\) definieren, in dem wir alle Teilmengen von \(\M\) als offen definieren.
In diesem Beispiel folgt trivialerweise, dass \(\tau = \mathcal{P}(\M)\) gilt.
Dann ist \((\M, \tau)\) ein topologischer Raum.
Diese Topologie nennt man \sphinxstylestrong{diskrete Topologie}, da für jeden diskreten Punkt \(x \in \M\) die Menge \(\lbrace x \rbrace\) offen ist.

\sphinxAtStartPar
Die diskrete Topologie wird durch eine spezielle Metrik erzeugt, wie man im Folgenden einsieht.
Seien \(x,y \in M\) Punkte der Menge und \(d \colon \M \times \M \rightarrow \R^+_0\) eine Metrik auf \(\M\) mit
\begin{equation*}
\begin{split}d(x,y) := \begin{cases} 0, \quad \text{ falls } x=y,\\ 1, \quad \text{ falls } x\neq y. \end{cases}\end{split}
\end{equation*}
\sphinxAtStartPar
Über diese Metrik kann man nun \sphinxstyleemphasis{offene Umgebungen} von Punkten \(x \in \M\) wie folgt konstruieren,
\begin{equation*}
\begin{split}B_1(x) := \lbrace y \in \M : d(x,y) < 1 \rbrace = \lbrace x \rbrace.\end{split}
\end{equation*}
\sphinxAtStartPar
Dies führt dazu, dass alle Teilmengen, die nur einen Punkt der Menge enthalten, offen sind.
Über beliebige Vereinigung dieser Punktmengen, lassen sich dann alle Teilmengen der Potenzmenge \(\mathcal{P}(\M)\) als offen definieren und man erhält somit die diskrete Topologie.
\end{sphinxadmonition}
\label{vektoranalysis/diffformen:remark-2}
\begin{sphinxadmonition}{note}{Remark 3.15 (Notation von topologischen Räumen)}



\sphinxAtStartPar
Häufig spielt die konkrete Wahl einer Topologie \(\tau \subset \mathcal{P}(\M)\) keine Rolle für die mathematischen Aussagen, die man treffen möchte.
Da wir jede beliebige Menge \(\M\) mit der diskreten Topologie aus {\hyperref[\detokenize{vektoranalysis/diffformen:ex:diskreteTopologie}]{\sphinxcrossref{Example 3.14}}} zu einem topologischen Raum \((\M, \tau)\) ausstatten können, wird die Angabe der konkreten Topologie \(\tau\) häufig ausgelassen.
In solchen Fällen identifiziert man den topologischen Raum einfach mit der zu Grunde liegenden Menge \(\M\), d.h., wir nennen \(\M\) einen topologischen Raum, wenn die konkrete Topologie im gewählten Kontext eindeutig ist oder keine Rolle spielt.
\end{sphinxadmonition}

\sphinxAtStartPar
Viele mathematische Konzepte lassen sich von metrischen oder normierten Räumen auf topologische Räume übertragen, wie zum Beispiel der Begriff einer stetigen Funktion.
\label{vektoranalysis/diffformen:def:stetigkeitTopologie}
\begin{sphinxadmonition}{note}{Definition 3.12 (Stetige Funktionen auf topologischen Räumen)}



\sphinxAtStartPar
Seien \((\M_1, \tau_1)\) und \((\M_2, \tau_2)\) topologische Räume und \(f\) eine Funktion mit
\begin{equation*}
\begin{split}f \colon (\M_1, \tau_1) \rightarrow (\M_2, \tau_2).\end{split}
\end{equation*}
\sphinxAtStartPar
Wir nennen \(f\) \sphinxstylestrong{stetig}, wenn die Urbilder offener Mengen in \(\tau_2\) unter \(f\) wieder offene Mengen in \(\tau_1\) ergeben, d.h.,
\begin{equation*}
\begin{split}f \ \text{ stetig } \quad \Leftrightarrow \quad \forall \, O \in \tau_2 : f^{-1}(O) \in \tau_1.\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Das folgende Diagramm zeigt die Relationen zwischen verschiedenen mathematischen Konzepten innerhalb einer hierarchischen Struktur.
\begin{equation*}
\begin{split}\begin{gathered}
\text{Skalarprodukt (Euklidischer / Unitärer Vektorraum)}\\
\downarrow \text{induziert}\\
\text{Norm (Normierter Vektorraum)}\\
\downarrow \text{induziert}\\             
\text{Metrik (Metrischer Vektorraum)}\\
\downarrow \text{induziert}\\                 
\text{Topologie (Topologischer Vektorraum)}
\end{gathered}\end{split}
\end{equation*}

\subsection{Mannigfaltigkeiten}
\label{\detokenize{vektoranalysis/diffformen:mannigfaltigkeiten}}\label{\detokenize{vektoranalysis/diffformen:s-mannigfaltigkeiten}}
\sphinxAtStartPar
In diesem Abschnitt führen wir das grundlegende Konzept von \sphinxhref{https://de.wikipedia.org/wiki/Mannigfaltigkeit}{Mannigfaltigkeiten} als Spezialfall eines topologischen Raums ein, der lokal mit dem Euklidischen Raum \(\R^n\) identifiziert werden kann.
Mannigfaltigkeiten spielen insbesondere im mathematischen Teilgebiet der \sphinxhref{https://de.wikipedia.org/wiki/Differentialgeometrie}{Differentialgeometrie} eine zentrale Rolle.


\subsubsection{Motivation}
\label{\detokenize{vektoranalysis/diffformen:motivation}}
\sphinxAtStartPar
Das wohl verständlichste Bild einer Mannigfaltigkeit ist die Oberfläche einer dreidimensionalen Kugel
\begin{equation*}
\begin{split}\mathbb{S}^2 := \lbrace (x,y,z)\in\R^3 : x^2 + y^2 + z^2 = 1 \rbrace,\end{split}
\end{equation*}
\sphinxAtStartPar
wie sie zum Beispiel genutzt wird um die Erdoberfläche zu modellieren.
Möchte man Mathematik auf solch einer Oberfläche betreiben, so benötigt man vollkommen andere Konzepte als in offenen Teilmengen des \(\R^n\).
Möchte man beispielsweise berechnen, wie weit man reisen muss, um von einem Punkt auf der Oberfläche zu einem anderen Punkt zu kommen, so benötigt man einen angepassten Abstandsbegriff, da die Euklidische Norm nur die direkte Entfernung messen würde, welche die Kugeloberfläche jedoch durchschneidet.
Dies ist in folgender Abbildung visualisiert.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[height=300\sphinxpxdimen]{{mannigfaltigkeit}.png}
\caption{Visualisierung zweier unterschiedlicher Abstandsbegriffe für Punkte auf der Kugeloberfläche \(\mathbb{S}^2\).}\label{\detokenize{vektoranalysis/diffformen:fig-kugel}}\end{figure}

\sphinxAtStartPar
Aus dieser Anschauung wird klar, dass unser bisheriges Konzept von Differenzierbarkeit im Mehrdimensionalen aus dem \sphinxhref{https://fau-ammn.github.io/MathDataScience2/ableitungen/ableitungen.html}{MP\sphinxhyphen{}2 Skript} nicht ausreicht, um auf diesem Objekt geeignet Funktionen abzuleiten.
Da man in vielen Bereichen der Physik und der Mathematik nicht nur auf offenen Teilmengen des \(\R^n\) ableiten möchte, benötigen wir ein analoges Prinzip für topologische Räume \(\M := (\M, \tau)\).

\sphinxAtStartPar
\sphinxstylestrong{Wie können wir den Ableitungsbegriff auf topologische Räume übertragen?}

\sphinxAtStartPar
Die grundlegende Idee ist es, den topologischen Raum \(\M\) lokal mit einer Teilmenge des \(\R^n\) zu identifizieren.
Für eine beliebige offene Teilmenge \(U\subset \M\) betrachten wir also eine Abbildung
\begin{equation*}
\begin{split}\phi:U\rightarrow \R^n.\end{split}
\end{equation*}
\sphinxAtStartPar
Wir wollen fordern, dass es sich bei \(\phi\) um eine \sphinxstyleemphasis{injektive Abbildung} handelt, so dass eine inverse Abbildung \(\phi^{-1}\) existiert.
Diese Umkehrabbildung müssen wir jedoch auf das Bild \(\phi(U) \subset \R^n\) einschränken, damit sie wohldefiniert ist.
Damit erhalten wir eine \sphinxstyleemphasis{lokale Bijektion} \(\phi^{-1}:\phi(U)\rightarrow U\).

\sphinxAtStartPar
Betrachten wir nun eine Funktion \(f \colon \M \rightarrow \R^m\), die Punkte des topologischen Raumes auf Punkte des \(\R^m\) abbildet.
Wenn wir diese Funktion differenzieren möchten, so sehen wir ein, dass die Verknüpfung
\begin{equation*}
\begin{split}f \circ \phi^{-1} : \phi(U) \subset \R^n \to \R^m\end{split}
\end{equation*}
\sphinxAtStartPar
es uns erlaubt, das Problem der Ableitung in topologischen Räumen auf das Konzept der mehrdimensionalen Differentiation im \(\R^n\) zurückzuführen.


\subsubsection{Karten und Atlanten auf topologischen Räumen}
\label{\detokenize{vektoranalysis/diffformen:karten-und-atlanten-auf-topologischen-raumen}}
\sphinxAtStartPar
Um den Ableitungsbegriff auf topologischen Räumen \(\M\) formal definieren zu können, benötigen wir zusätzlich zur Bijektivität der Abbildung \(\phi \colon U \rightarrow \phi(U) \subset \R^n\) die Bedingung, dass für jede Teilmenge \(U \subset \M\) gilt,
\begin{equation*}
\begin{split}\phi(U)\text{ ist offen} \ \Leftrightarrow \ U \text{ ist offen}.\end{split}
\end{equation*}
\sphinxAtStartPar
Diese Forderung bedeutet, dass offene Teilmengen in \(U \subset \M\) gerade mit offenen Teilmengen in \(\phi(U) \subset \R^n\) identifiziert werden.
Wir wollen im Folgenden beide Implikationsrichtungen diskutieren.

\sphinxAtStartPar
1. \(\phi(U)\) ist offen \(\Rightarrow U \) ist offen.

\sphinxAtStartPar
Diese Implikation ist äquivalent zur Forderung, dass Urbilder offener Mengen selbst wieder offen sind.
Mit {\hyperref[\detokenize{vektoranalysis/diffformen:def:stetigkeitTopologie}]{\sphinxcrossref{Definition 3.12}}} bedeutet dies wiederum, dass die Abbildung \(\phi\) stetig ist.

\sphinxAtStartPar
2. \(\phi(U)\) ist offen \(\Leftarrow U \) ist offen.

\sphinxAtStartPar
Analog zur obigen Überlegung sehen wir ein, dass diese Bedingung gerade aussagt, dass \(\phi^{-1}\) stetig ist.
Diese Forderung ist nicht immer trivialerweise erfüllt.

\sphinxAtStartPar
Das folgende Beispiel zeigt, dass es tatsächlich stetige bijektive Abbildung \(\phi\) gibt, für die gilt, dass die Umkehrabbildung \(\phi^{-1}\) \sphinxstyleemphasis{nicht stetig} ist.
\label{vektoranalysis/diffformen:ex:nonho}
\begin{sphinxadmonition}{note}{Example 3.15}



\sphinxAtStartPar
Wir betrachten in diesem Beispiel die Funktion
\begin{equation*}
\begin{split}\phi:[0,2\pi)&\to\R^2,\\
t &\mapsto \phi(t):= (\cos(t), \sin(t)).\end{split}
\end{equation*}
\sphinxAtStartPar
Wir erkennen, dass \(\phi([0,2\pi)) = \S^1\) gerade der Einheitskreis ist, und dass \(\phi:[0,2\pi)\to\S^1\) bijektiv und stetig ist.
Allerdings stellen wir fest, dass die Umkehrabbildung nicht stetig ist.
Sei dazu \((x_i)_{i\in\N}\) eine Folge von Punkten auf dem Einheitskreis \(\S^1\), deren \(y\)\sphinxhyphen{}Koordinate negativ ist und die gegen den Punkt \(x = (1,0) \in \S^1\) konvergieren, d.h.,
\begin{equation*}
\begin{split}\lim_{i\rightarrow\infty} x_i =: x = (1,0) \in \S^1.\end{split}
\end{equation*}
\sphinxAtStartPar
Betrachten wir jedoch den Grenzwert der Folge von Funktionswerten \((\phi^{-1}(x_i))_{i\in I}\), so sehen wir, dass
\begin{equation*}
\begin{split}\lim_{i\to\infty} \phi^{-1} (x_i) = 2\pi \neq 0 = \phi^{-1}(x)\end{split}
\end{equation*}
\sphinxAtStartPar
und somit ist \(\phi^{-1}\) offensichtlich nicht stetig.
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[height=450\sphinxpxdimen]{{nonhomöo}.jpg}
\caption{Visualisierung einer unstetigen Umkehrabbildung für das {\hyperref[\detokenize{vektoranalysis/diffformen:ex:nonho}]{\sphinxcrossref{Example 3.15}}}.}\label{\detokenize{vektoranalysis/diffformen:fig-nonh}}\end{figure}

\sphinxAtStartPar
Insgesamt fordern wir also, dass \(\phi:U\rightarrow\phi(U)\) bijektiv ist und zusätzlich, dass sowohl \(\phi\) als auch die Umkehrabbildung \(\phi^-1\) stetig sind.
Eine solche Abbildung definiert man unter dem Begriff \sphinxstyleemphasis{Homöomorphismus}.
\label{vektoranalysis/diffformen:definition-5}
\begin{sphinxadmonition}{note}{Definition 3.13 (Homöomorphismus)}



\sphinxAtStartPar
Seien \(X\) und \(Y\) topologische Räume.
Dann nennen wir eine Abbildung \(f \colon X \rightarrow Y\) einen \sphinxstylestrong{Homöomorphismus}, wenn sie folgende Eigenschaften erfüllt:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(f\) ist bijektiv

\item {} 
\sphinxAtStartPar
\(f\) ist stetig

\item {} 
\sphinxAtStartPar
die Umkehrfunktion \(f^{-1}\) ist ebenfalls stetig.

\end{enumerate}
\end{sphinxadmonition}

\sphinxAtStartPar
Speziell im Kontext von Mannigfaltigkeiten \(\M\), als Spezialfall topologischer Räume (wie wir noch sehen werden), nennt man eine offene Menge zusammen mit einem Homöomorphismus eine \sphinxstylestrong{Karte} auf \(\M\).
\label{vektoranalysis/diffformen:definition-6}
\begin{sphinxadmonition}{note}{Definition 3.14 (Karte)}



\sphinxAtStartPar
Es sei \(\M\) ein topologischer Raum und \(U\subset\M\) eine offene Menge.
Sei außerdem \(\phi:U\rightarrow \phi(U)\subset \R^n\) ein Homöomorphismus.
Dann heißt das Tupel \((U,\phi)\) \sphinxstylestrong{Karte} auf \(\M\).
\end{sphinxadmonition}

\sphinxAtStartPar
Um einen Ableitungsbegriff für Funktionen \(f:\M\to\R^m\) über eine Karte \((U,\phi)\) und der Verknüpfung \(f\circ \phi^{-1}\) zu definieren benötigen wir noch ein zusätzliches Konzept.
Denn in der Situation, dass \((V,\psi)\) eine zweite Karte ist, deren offene Menge \(V\) einen nichtleeren Schnitt mit der offenen Menge \(U\) hat, d.h., \(U\cap V \neq \emptyset\), erhalten wir genau auf dem Schnitt dieser Mengen zwei unterschiedliche Parametrisierungen,
\begin{equation*}
\begin{split}f\circ \phi^{-1} = (f\circ\psi^{-1})\circ(\psi\circ \phi^{-1}),\\
f\circ \psi^{-1} = (f\circ\phi^{-1})\circ(\phi\circ \psi^{-1}).\end{split}
\end{equation*}
\sphinxAtStartPar
Um von einer Karte zur nächsten Karte zu kommen benötigen wir eine geeignete Abbildung.
\label{vektoranalysis/diffformen:definition-7}
\begin{sphinxadmonition}{note}{Definition 3.15 (Kartenwechsel)}



\sphinxAtStartPar
Es sei \(\M\) ein topologischer Raum und es seien \((U,\phi)\) und \((V,\psi)\) zwei Karten auf \(\M\) mit nicht\sphinxhyphen{}leerem Schnitt, d.h., \(U\cap V\neq \emptyset\).
Dann nennt man die Abbildung
\begin{equation*}
\begin{split}\psi\circ\phi^{-1}: \phi(U\cap V)\rightarrow \psi(U\cap V)\end{split}
\end{equation*}
\sphinxAtStartPar
einen \sphinxstylestrong{Kartenwechsel} von \((U,\phi)\) nach \((V,\psi)\).
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[height=450\sphinxpxdimen]{{chartchange}.jpg}
\caption{Kartenwechsel.}\label{\detokenize{vektoranalysis/diffformen:fig-chartchange}}\end{figure}

\sphinxAtStartPar
Wir erkennen also, dass Umparametrisierungen der Form \(\psi\circ \phi^{-1}\) entscheidend sind, um von einer lokalen Identifikation des topologischen Raums zur nächsten zu gelangen.
Wäre nun der Kartenwechsel \(\psi\circ \phi^{-1}\) und respektive \(\phi\circ \psi^{-1}\) differenzierbar, so könnte man die jeweiligen Ableitungen leicht durch die Kettenregel ineinander umrechnen.
Allerdings existieren durchaus Beispiele, in denen sowohl \(f\circ\phi^{-1}\) als auch \(f\circ\psi^{-1}\) differenzierbar sind, aber der Kartenwechsel \(\psi\circ\phi^{-1}\) nicht.
Deshalb führt man zusätzlich noch den folgenden Begriff ein.
\label{vektoranalysis/diffformen:definition-8}
\begin{sphinxadmonition}{note}{Definition 3.16 (Atlas)}



\sphinxAtStartPar
Es sei \(\M\) ein topologischer Raum.
Eine Familie von Karten \(\mathcal{A} = (U_i,\phi_i)_{i\in I}\) indiziert durch die Indexmenge \(I\) heißt \sphinxstylestrong{Atlas}, falls die Vereinigung aller offenen Mengen eine Überdeckung des topologischen Raums darstellt, d.h., es gilt
\begin{equation*}
\begin{split}\M = \bigcup_{i\in I} U_i.\end{split}
\end{equation*}
\sphinxAtStartPar
Wir nennen einen Atlas \(k\)\sphinxhyphen{}mal \sphinxstylestrong{differenzierbar} oder von der Klasse \(C^k\), falls jeder Kartenwechsel \(\phi_i\circ\phi_j^{-1}, i,j\in I\) \(k\)\sphinxhyphen{}mal stetig differenzierbar ist.
\end{sphinxadmonition}

\sphinxAtStartPar
Die Begriffe \sphinxstyleemphasis{Karte} und \sphinxstyleemphasis{Atlas} stammen in der Tat aus mathematischen Überlegungen in der Kartographie.
Man kann Teile der Erdoberfläche mit einer Karte auf eine Ebene \(\R^2\) abbilden.
Nähert man sich dem Rand einer Karte, so möchte man zu einer anderen Karte wechseln, die das angrenzende Gebiet darstellt.

\sphinxAtStartPar
So kann eine Mannigfaltigkeit durch einen vollständigen Satz von Karten vollständig beschrieben werden; man braucht dabei Regeln, wie sich beim Kartenwechsel die Karten überlappen.


\subsubsection{Differenzierbare Mannigfaltigkeiten}
\label{\detokenize{vektoranalysis/diffformen:differenzierbare-mannigfaltigkeiten}}
\sphinxAtStartPar
Für einen topologischen Raum \(\M\) können mehrere Atlanten \(\mathcal{A}\) existieren, weshalb es sinnvoll ist Äquivalenzklassen von Atlanten zu betrachten.
\label{vektoranalysis/diffformen:definition-9}
\begin{sphinxadmonition}{note}{Definition 3.17 (\protect\(C^k\protect\)\sphinxhyphen{}differenzierbare Struktur)}



\sphinxAtStartPar
Für einen Index \(k\in \N \cup \{\infty\}\) heißen zwei differenzierbare Atlanten \(\mathcal{A}_1, \mathcal{A}_2\) der Klasse \(C^k\) \sphinxstylestrong{\(k\)\sphinxhyphen{}äquivalent}, falls ihre Vereinigung \(\mathcal{A}_1\cup \mathcal{A}_2\) wieder ein Atlas der Klasse \(C^k\) ist.
Dies bedeutet insbesondere, dass die Kartenwechsel durch die Vereinigung der beiden Atlanten weiterhin \(k\)\sphinxhyphen{}mal stetig differenzierbar bleiben.
In diesem Fall notieren wir \(\mathcal{A}_1\sim_k \mathcal{A}_2\).
Die Äquivalenzklasse \([\mathcal{A}]_{\sim_k}\) nennt man eine \sphinxstylestrong{\(C^k\)\sphinxhyphen{}differenzierbare Struktur}.
\end{sphinxadmonition}

\begin{sphinxShadowBox}
\sphinxstylesidebartitle{}

\sphinxAtStartPar
\sphinxhref{https://de.wikipedia.org/wiki/Felix\_Hausdorff}{Felix Hausdorff} (geboren am 8. November 1868 in Breslau; gestorben am 26. Januar 1942 in Bonn) war ein deutscher Mathematiker.
\end{sphinxShadowBox}

\sphinxAtStartPar
Bisher haben wir \(\M\) als allgemeinen topologischen Raum betrachtet.
In vielen Anwendungen benötigt man aber weitere nützliche Eigenschaften des Raumes.
Insbesondere wenn man \sphinxhref{https://de.wikipedia.org/wiki/Testfunktion}{glatte Testfunktionen} und \sphinxhref{https://en.wikipedia.org/wiki/Partition\_of\_unity}{die Zerlegung der Eins} benutzen möchte braucht man folgende zwei zusätzliche Eigenschaften.

\sphinxAtStartPar
Wir definieren zunächst die Eigenschaft eines Hausdorff\sphinxhyphen{}Raums.
\label{vektoranalysis/diffformen:definition-10}
\begin{sphinxadmonition}{note}{Definition 3.18 (Hausdorff\sphinxhyphen{}Raum)}



\sphinxAtStartPar
Ein topologischer Raum \(\M\) heißt \sphinxstylestrong{Hausdorff\sphinxhyphen{}Raum}, falls für je zwei unterschiedliche Punkte \(x,y\in \M, x\neq y\) offene Umgebungen \(U(x), U(y) \subset \M\) existieren, welche disjunkt sind, d.h., \(U(x)\cap U(y) = \emptyset\).
Man nennt \(\M\) dann auch einen \sphinxstylestrong{separierten Raum}.
\end{sphinxadmonition}

\sphinxAtStartPar
Als zweite nützliche Eigenschaft fordern wir, dass unser topologischer Raum \(\M\) das zweite Abzählbarkeitsaxiom erfüllen soll.
\label{vektoranalysis/diffformen:definition-11}
\begin{sphinxadmonition}{note}{Definition 3.19 (Zweites Abzählbarkeitsaxiom)}



\sphinxAtStartPar
Ein toplogischer Raum \((\M, \tau)\) erfüllt das \sphinxstylestrong{zweite Abzählbarkeitsaxiom}, falls \sphinxstyleemphasis{abzählbar} viele offene Mengen \((V_i)_{i\in\N} \in \tau\) existieren, so dass für jeden Punkt \(x\in \M\) und jede offene Umgebung \(U(x) \in \tau\) von \(x\) mindestens ein Index \(k\in\N\) existiert mit \(V_k \subset U(x)\).
Man nennt \((\M, \tau)\) dann auch \sphinxstylestrong{zweitabzählbar}.
\end{sphinxadmonition}

\sphinxAtStartPar
Diese zwei Bedingung wirken zunächst abstrakt.
Glücklicherweise werden sie jedoch von vielen üblichen topologischen Räumen erfüllt, wie zum Beispiel dem Euklidischen Raum \(\R^n\).
\label{vektoranalysis/diffformen:remark-12}
\begin{sphinxadmonition}{note}{Remark 3.16}



\sphinxAtStartPar
Falls der Begriff eines zweitabzählbaren Hausdorff\sphinxhyphen{}Raums zu unhandlich erscheint, kann man für die meisten Anwendungen in der Physik auch einfach \sphinxstylestrong{metrische Räume} betrachten, die diese beiden Eigenschaften implizieren.
\end{sphinxadmonition}

\sphinxAtStartPar
Nun haben wir alle nötigen Voraussetzungen geschaffen um den Begriff einer Mannigfaltigkeit formal einzuführen.
\label{vektoranalysis/diffformen:definition-13}
\begin{sphinxadmonition}{note}{Definition 3.20 (Differenzierbare Mannigfaltigkeit)}



\sphinxAtStartPar
Es sei \(\M\) ein zweitabzählbarer Hausdorff\sphinxhyphen{}Raum und für \(k\in\N\cup \{\infty\}\) sei \([\mathcal{A}]_{\sim_k}\) eine \(C^k\)\sphinxhyphen{}differenzierbare Struktur.
Dann nennen wir \((\M,[\mathcal{A}]_{\sim_k})\) eine \(k\)\sphinxhyphen{}\sphinxstylestrong{mal differenzierbare Mannigfaltigkeit}.
Für den Spezialfall \(k=\infty\) sprechen wir auch von einer \sphinxstylestrong{glatten Mannigfaltigkeit}.

\sphinxAtStartPar
Falls alle Karten auf \(\M\) nach \(\R^n\) abbilden, so nennt man die Mannigfaltigkeit \sphinxstyleemphasis{\(n\)\sphinxhyphen{}dimensional}.
\end{sphinxadmonition}

\sphinxAtStartPar
Ähnlich wie bei topologischen Räumen spricht man in den meisten Fällen nur von der Mannigfaltigkeit \(\M\); die differenzierbare Struktur \([\mathcal{A}]_{\sim_k}\) wird dabei implizit vorausgesetzt.

\sphinxAtStartPar
Basierend auf einer differenzierbaren Mannigfaltigkeit \(\M\) können wir nun differenzierbare Funktionen auf \(\M\) definieren.
\label{vektoranalysis/diffformen:definition-14}
\begin{sphinxadmonition}{note}{Definition 3.21 (Differenzierbare Funktion auf einer Mannigfaltigkeit)}



\sphinxAtStartPar
Sei \(\M\) eine \(k\)\sphinxhyphen{}mal differenzierbare Mannigfaltigkeit \(\mathcal{A}\) ein Atlas auf \(\M\).
Dann nennen wir eine Abbildung \(f:\M\to\R^m\) \sphinxstylestrong{\(k\)\sphinxhyphen{}mal differenzierbar}, falls für jeden Punkt \(x\in\M\) eine differenzierbare Karte \((U(x),\phi)\in\mathcal{A}\) existiert, so dass \(f\circ\phi^{-1} \in C^k(\phi(U(x)); \R^m)\).
Insbesondere schreiben wir in diesem Fall \(f\in C^k(\M; \R^m)\).
\end{sphinxadmonition}

\sphinxAtStartPar
In vielen Anwendungen beschränkt man sich nur auf \sphinxstyleemphasis{glatte Mannigfaltigkeiten} und \sphinxstyleemphasis{glatte Funktionen} in \(C^\infty(\M; \R^m)\).
Wir werden im Folgenden der Einfachheit\sphinxhyphen{}halber auch dazu übergehen.
\label{vektoranalysis/diffformen:lemma-15}
\begin{sphinxadmonition}{note}{Lemma 3.11}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit.
Dann ist \(C^\infty(\M; \R^m)\) ein reeller Vektorraum mit den Verknüpfungen
\begin{equation*}
\begin{split}(\lambda \cdot f)(x) := \lambda\cdot f(x)\text{ für } f\in C^\infty(\M; \R^m), \lambda\in\R,\\
(f + g)(x) := f(x) + g(x)\quad\text{ für } f,g\in C^\infty(\M; \R^m).\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. In der Hausaufgabe zu zeigen.
\end{sphinxadmonition}

\sphinxAtStartPar
Die Eigenschaft der Differenzierbarkeit einer Funktion auf einer Mannigfaltigkeit ist kartenunabhängig, wie folgendes Lemma feststellt.
\label{vektoranalysis/diffformen:lem:differenzierbarkeitKartenunabhaengig}
\begin{sphinxadmonition}{note}{Lemma 3.12}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit und \(\mathcal{A}\) ein Atlas auf \(\M\).
Außerdem sei \(f:\M \to \R^m\) eine Funktion, \((U,\phi)\in \mathcal{A}\) eine Karte und \(x \in U\) ein Punkt in der offenen Menge \(U\).
Ist \(f\circ\phi^{-1}\) differenzierbar in \(x\), so ist \(f\circ\psi^{-1}\) auch differenzierbar in \(x\) für jede Karte \((V,\psi) \in \mathcal{A}\) mit \(x\in V\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. In der Hausaufgabe zu zeigen.
\end{sphinxadmonition}


\subsubsection{Tangentialräume an Mannigfaltigkeiten}
\label{\detokenize{vektoranalysis/diffformen:tangentialraume-an-mannigfaltigkeiten}}
\sphinxAtStartPar
Aus dem Kapitel {\hyperref[\detokenize{odestability/ruhelagen:s-linearisierung-ruhelage}]{\sphinxcrossref{\DUrole{std,std-ref}{Linearisierung um Ruhelage}}}} ist bereits das Konzept der \sphinxstyleemphasis{Linearisierung} bekannt.
Anschaulich gesprochen haben wir eine differenzierbare Funktion \(f\) durch ihre Linearisierung ersetzt um ein einfacheres Problem zu erhalten.
Dieses Konzept soll nun auf glatte Mannigfaltigkeiten übertragen werden.

\sphinxAtStartPar
Wir haben bereits erkannt, wie wir den Begriff der Differenzierbarkeit einer Funktion auf einer Mannigfaltigkeit definieren.
Und obwohl die Frage nach der Differenzierbarkeit einer Funktion nach {\hyperref[\detokenize{vektoranalysis/diffformen:lem:differenzierbarkeitKartenunabhaengig}]{\sphinxcrossref{Lemma 3.12}}} kartenunabhängig ist, so stellt sich heraus, dass der tatsächliche \sphinxstyleemphasis{Wert der Ableitung} einer Verknüpfung \(f \circ\phi^{-1}\) noch immer von der konkreten Wahl des Homöomorphismus \(\phi\) abhängt.
Um auch hier die gewünschte Kartenunabhängigkeit zu erreichen, brauchen wir einen anderen Begriff der Differenzierbarkeit.
Hierbei wird uns der sogenannte \sphinxstylestrong{Tangentialraum} helfen.
Man kann ihn als eine Linearisierung der Mannigfaltigkeit \(\M\) an einem Punkt \(p\in\M\) interpretieren.

\sphinxAtStartPar
Das folgende Beispiel erklärt anschaulich den Tangentialraum an eine Mannigfaltigkeit.
\label{vektoranalysis/diffformen:example-17}
\begin{sphinxadmonition}{note}{Example 3.16}



\sphinxAtStartPar
Wir betrachten zunächst den Einheitskreis \(\M = \mathbb{S}^1\) und den Punkt \(p = (1, 0)^T \in \mathbb{S}^1\).
Der Tangentialraum \(T_p\M\) an \(\M\) im Punkt \(p\) ist der eindimensionale Unterraum
\begin{equation*}
\begin{split}T_p\M = \lbrace \lambda \cdot (0, 1)^T : \lambda \in \R \rbrace \subset \R^2.\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Es gibt in der Literatur zwei verschiedene, jedoch äquivalente Arten den Tangentialraum zu definieren.
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Geometrischer Tangentialraum}: Bei diesem Ansatz wählt man eine geometrisch Anschauung und definiert den Tangentialraum durch Richtungsvektoren, die am Punkt \(p\in\M\) anliegen.
Der Vorteil dieser Definition ist es, dass sie intuitiv und geometrisch anschaulich ist.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Algebraische Defnition}: Bei diesem Ansatz führt man den Tangentialraum mittels spezieller linearer Abbildungen, genannt Derivationen, zurück.
Man verliert hierbei zwar die geometrische Anschauung, allerdings ist das Konzept relativ einfach zu formulieren und hilft die Sachverhalte auf algebraische Zusammenhänge zurückzuführen.

\end{itemize}

\sphinxAtStartPar
In der Praxis (und in vielen Mathematikbüchern) werden beide Definitionen nebeneinander verwendet und die jeweilige Interpretation geht dann aus dem Kontext hervor.
Da sich die beiden Konzepte somit schlecht voneinander trennen lassen werden wir im Folgenden den geometrischen Tangentialraum \(T^{\text{geo}}_p\M\) und den algebraischen Tangentialraum \(T^{\text{alg}}_p\M\) explizit einführen und anschließend eine Isomorphie
\begin{equation*}
\begin{split}T^{\text{geo}}_p\M\cong T^{\text{alg}}_p\M\end{split}
\end{equation*}
\sphinxAtStartPar
zwischen den beiden Tangentialräumen zeigen.

\begin{sphinxadmonition}{danger}{Danger:}
\sphinxAtStartPar
In der Literatur wird diese explizite Unterscheidung oft nicht vorgenommen.
Stattdessen wird der Tangentialraum einfach nur \(T_p\M\) genannt.
Elemente dieses Raums sind dann je nach Kontext geometrisch oder algebraisch zu interpretieren.
\end{sphinxadmonition}


\paragraph{Geometrische Definition}
\label{\detokenize{vektoranalysis/diffformen:geometrische-definition}}
\sphinxAtStartPar
Von der Differentiation im Mehrdimensionalen ist bereits das Konzept der \sphinxstylestrong{Richtungsableitung} bekannt (siehe Kapitel 6.2.2 in {[}\hyperlink{cite.references:id12}{Ten21}{]}).
Hierbei betrachtet man für eine Funktion \(F:\R^n\to\R\) den Strahl \(\gamma(t):= x + t\cdot v\), wobei \(x,v\in\R^n\) und den Grenzwert
\begin{equation*}
\begin{split}\lim_{t\to 0} \frac{F(\gamma(t)) - F(\gamma(0))}{t} = \frac{F(x + t\cdot v) - F(x))}{t}.\end{split}
\end{equation*}
\sphinxAtStartPar
Wir werden dieses Konzept nun auf glatte \(n\)\sphinxhyphen{}dimensionale Mannigfaltigkeiten \(\M\) verallgemeinern, indem wir anstatt von Strahlen differenzierbare \sphinxstyleemphasis{Kurven} auf der Mannigfaltigkeit betrachten.
\label{vektoranalysis/diffformen:definition-18}
\begin{sphinxadmonition}{note}{Definition 3.22 (Differenzierbare Kurve)}



\sphinxAtStartPar
Sei \(\M\) eine glatte Mannigfaltigkeit und sei
\begin{equation*}
\begin{split}\gamma \colon (-1,1) \rightarrow \M\end{split}
\end{equation*}
\sphinxAtStartPar
eine Kurve auf der Mannigfaltigkeit \(\M\).
Wir nennen \(\gamma\) \sphinxstylestrong{differenzierbar} im Punkt \(0\in(-1,1)\), falls die Kurve \sphinxstyleemphasis{stetig} ist und falls eine Karte \((U,\phi)\) von \(\M\) existiert, so dass für genügend kleines \(\varepsilon\) auch \(\gamma((-\varepsilon,\varepsilon))\subset U\) gilt und die Verknüpfung
\begin{equation*}
\begin{split}\phi \circ \gamma:(-\varepsilon,\varepsilon)\to\R^n\end{split}
\end{equation*}
\sphinxAtStartPar
differenzierbar in \(0\) ist .
\end{sphinxadmonition}

\sphinxAtStartPar
Wir werden im Folgenden ausschließlich die Ableitung der Kurve im Punkt \(t=0\) betrachten und sprechen deshalb verkürzt einfach nur von \sphinxstyleemphasis{differenzierbaren} Kurven.
Zusätzlich sei zu bemerken, dass die obige Definition \sphinxstylestrong{nicht} von der Wahl der Karte abhängt.
\label{vektoranalysis/diffformen:example-19}
\begin{sphinxadmonition}{note}{Example 3.17}



\sphinxAtStartPar
Es sei \(\M=\S^2\) die Einheitssphäre und \(f:\M\to\R\) beschreibe eine Wärmeverteilung auf deren Oberfläche.
Betrachtet man nun die Bahn eines Partikels auf der Oberfläche beschrieben durch die Kurve \(\gamma:(-t, t)\to \M\) so erhalten wir eine eindimensionale Abbildung
\begin{equation*}
\begin{split}f\circ\gamma:(-t,t)\to \R,\end{split}
\end{equation*}
\sphinxAtStartPar
die zu jedem Zeitpunkt die Temperatur des Ortes, an dem sich der Partikel befindet, beschreibt.
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=350\sphinxpxdimen,height=300\sphinxpxdimen]{{velocity}.jpg}
\caption{Visualisierung einer Kurve auf der oberen Hälfte der Einheitssphäre im \(\R^3\).}\label{\detokenize{vektoranalysis/diffformen:fig-velocity}}\end{figure}

\sphinxAtStartPar
Mit Hilfe von differenzierbaren Kurven auf Mannigfaltigkeiten können wir im Folgenden die Richtungsableitung an einer Mannigfaltigkeit definieren.
\label{vektoranalysis/diffformen:def:direcdiv}
\begin{sphinxadmonition}{note}{Definition 3.23 (Richtungsableitung an Mannigfaltigkeit)}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit, \(\gamma:(-1,1)\to\M\) eine differenzierbare Kurve mit \(\gamma(0)=p\in\M\) und \(f \in C^\infty(\M)\) eine glatte Funktion.
Dann nennen wir die Abbildung
\begin{equation*}
\begin{split}D_\gamma : C^\infty(\M) &\to \R\\
f &\mapsto D_\gamma(f):=\frac{d}{dt}(f\circ \gamma)\big\rvert_{t=0}\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{Richtungsableitung} von \(f\) durch \(\gamma\) im Punkt \(p\).
\end{sphinxadmonition}

\sphinxAtStartPar
Betrachten wir nun eine differenzierbare Kurve \(\gamma \colon (-1, 1) \rightarrow \M\) mit \(\gamma(0)=p \in \M\) und eine glatte Funktion \(f \in \C^\infty(\M)\) definiert auf einer glatten Mannigfaltigkeit \(\M\).
Dann können wir die Richtungsableitung \(D_\gamma(f)\) mit Hilfe der \sphinxstylestrong{Kettenregel für die Differentiation} darstellen als
\begin{equation*}
\begin{split}D_\gamma(f) = \frac{d}{dt}(f\circ \gamma)\big\rvert_{t=0} = \frac{d}{dt}\big( (f\circ \phi^{-1}) (\phi \circ \gamma) \big)\rvert_{t=0} = 
\big(D(f\circ \phi^{-1})\big)(\phi(p))\cdot \frac{d}{dt}(\phi \circ \gamma)\rvert_{t=0}\end{split}
\end{equation*}
\sphinxAtStartPar
und für eine weitere differenzierbare Kurve \(\eta \colon (-1, 1) \rightarrow \M\) mit \(\eta(0)=p\) erhalten wir analog
\begin{equation*}
\begin{split}D_\eta(f) = \frac{d}{dt}(f\circ \eta)\big\rvert_{t=0} = 
\big(D(f\circ \phi^{-1})\big)(\phi(p))\cdot \frac{d}{dt}(\phi \circ \eta)\rvert_{t=0}.\end{split}
\end{equation*}
\sphinxAtStartPar
Wir erkennen also, dass der Wert der Richtungsableitung in der Tat von der Kurve \(\gamma\) abhängt.
Dies führt auf einen natürlichen Äquivalenzbegriff von Kurven, wie die folgende Bemerkung beschreibt.
\label{vektoranalysis/diffformen:rem:tang}
\begin{sphinxadmonition}{note}{Remark 3.17 (Tangentialvektoren)}



\sphinxAtStartPar
Es sei \(\M\) eine glatte \(n\)\sphinxhyphen{}dimensionale Mannigfaltigkeit, \(p\in\M\) ein Punkt auf der Mannigfaltigkeit und \((U,\phi)\) eine Karte von \(\M\), für die gilt, dass \(p\in U\) ist.
Für zwei differenzierbare Kurven \(\gamma, \eta:(-1,1) \to U\) mit \(\gamma(0) = \eta(0) = p\) ist die Relation
\begin{equation*}
\begin{split}\gamma \sim_p \eta
\qquad \Leftrightarrow \qquad
\frac{d}{dt}(\phi \circ \gamma)\rvert_{t=0} = \frac{d}{dt}(\phi \circ \eta)\rvert_{t=0}\in \R^n\end{split}
\end{equation*}
\sphinxAtStartPar
eine Äquivalenzrelation (siehe Kapitel 2.1.1 in {[}\hyperlink{cite.references:id2}{Bur20}{]}).
Insbesondere ist die Äquivalenzklasse unabhängig von der Wahl des Homöomorphismus \(\phi\).
\end{sphinxadmonition}

\sphinxAtStartPar
Mittels der oben beschriebenen Äquivalenzrelation sind wir in der Lage den Begriff der \sphinxstyleemphasis{Tangentialvektoren} und des \sphinxstyleemphasis{Tangentialraums} zu definieren.
\label{vektoranalysis/diffformen:definition-22}
\begin{sphinxadmonition}{note}{Definition 3.24 (Geometrische Tangentialvektoren und Tangentialraum)}



\sphinxAtStartPar
Es sei \(\M\) eine glatte \(n\)\sphinxhyphen{}dimensionale Mannigfaltigkeit, \(p\in\M\) ein Punkt auf der Mannigfaltigkeit und \((U,\phi)\) eine Karte von \(\M\), für die gilt, dass \(p\in U\) ist.

\sphinxAtStartPar
Die Äquivalenzklasse \(\gamma^\prime(0):=[\gamma]_{\sim_p}\) wird als \sphinxstylestrong{geometrischer Tangentialvektor} an \(\M\) im Punkt \(p\) bezeichnet.
Der Raum der (geometrischen) Tangentialvektoren
\begin{equation*}
\begin{split}T_p^{\text{geo}}\M := \{\gamma^\prime(0): \gamma\text{ ist differenzierbare Kurve mit }\gamma(0)=p\}\end{split}
\end{equation*}
\sphinxAtStartPar
heißt \sphinxstylestrong{geometrischer Tangentialraum} der Mannigfaltigkeit \(\M\) am Punkt \(p \in \M\).
\end{sphinxadmonition}

\sphinxAtStartPar
Der Tangentialraum induziert sogar eine Vektorraumstruktur wie folgende Bemerkung festhält.
\label{vektoranalysis/diffformen:remark-23}
\begin{sphinxadmonition}{note}{Remark 3.18}



\sphinxAtStartPar
Es sei \(\M\) eine glatte \(n\)\sphinxhyphen{}dimensionale Mannigfaltigkeit, \(p\in\M\) ein Punkt auf der Mannigfaltigkeit und \((U,\phi)\) eine Karte von \(\M\), für die gilt, dass \(p\in U\) ist.
Sei außerdem \(\gamma \colon (-1,1) \rightarrow \M\) eine differenzierbare Kurve auf \(\M\) mit \(\gamma(0) = p\).
Wir definieren nun die folgende Bijektion auf dem Tangentialraum
\begin{equation*}
\begin{split}d\phi\rvert_p \colon T^{\text{geo}}_p\M &\rightarrow \R^n,\\
[\gamma]_{\sim_p} &\mapsto d\phi\rvert_p (\gamma^\prime(0)) := (\phi \circ \gamma)^\prime (0).\end{split}
\end{equation*}
\sphinxAtStartPar
Basierend auf dieser Abbildung lassen sich die folgenden Operationen für den Punkt \(p \in \M\) definieren
\begin{equation*}
\begin{split}\gamma^\prime(0) +_{p} \eta^\prime(0) \ &:= \
(d\phi\rvert_p)^{-1}\big[d\phi\rvert_p(\gamma^\prime(0)) + d\phi\rvert_p(\eta^\prime(0))\big]\\
\lambda \cdot_p \gamma^\prime(0) \ &:= \ (d\phi\rvert_p)^{-1} (\lambda \cdot d\phi\rvert_p(\gamma^\prime(0))\end{split}
\end{equation*}
\sphinxAtStartPar
Insgesamt ergibt somit das Tripel \((T_p^{\text{geo}}\M, +_p, \cdot_p)\) einen reellen Vektorraum.
Man bemerke, dass die oben definierten Abbildungen erneut \sphinxstylestrong{unabhängig} von der Wahl des Homöomorphismus \(\phi\) sind.
\end{sphinxadmonition}


\paragraph{Algebraische Definition}
\label{\detokenize{vektoranalysis/diffformen:algebraische-definition}}
\sphinxAtStartPar
Alternativ zur geometrischen Herleitung lässt sich der Tangentialraum auch algebraisch definieren über sogenannte \sphinxstyleemphasis{Derivationen}.
Hierbei beschreiben wir Tangentialvektoren nun nicht mehr als Kurven, sondern als spezielle Funktionale, welche durch ihre Wirkung auf \(C^\infty(\M)\) charakterisiert sind.
Die Motivation hierbei soll die Richtungsableitung aus {\hyperref[\detokenize{vektoranalysis/diffformen:def:direcdiv}]{\sphinxcrossref{Definition 3.23}}} sein und speziell die im folgenden Lemma beschriebenen Eigenschaften.
\label{vektoranalysis/diffformen:lemma-24}
\begin{sphinxadmonition}{note}{Lemma 3.13}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit und \(p\in\M\) und \(\gamma:[-1,1]\to\M\) eine glatte Kurve durch \(p\).
Dann gilt für die Richtungsableitung \(D_\gamma:C^\infty(\M)\to\R\),
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(D_\gamma\in (C^\infty(\M))^\ast\),

\item {} 
\sphinxAtStartPar
Für \(f,g\in C^\infty(\M)\) gilt: \(\ D_\gamma(fg) = D_\gamma(f) g(p) + f(p) D_\gamma(g)\).

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Siehe Übung.
\end{sphinxadmonition}

\sphinxAtStartPar
Die zweite Eigenschaft wird auch \sphinxstylestrong{Produktregel} oder \sphinxstylestrong{Leibnizregel} genannt.
Wir wollen nun im Folgenden nicht nur Richtungsableitungen betrachten, sondern allgemeine Funktionale, die diese Eigenschaft erfüllen.
\label{vektoranalysis/diffformen:definition-25}
\begin{sphinxadmonition}{note}{Definition 3.25 (Derivation und algebraischer Tangentialraum)}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit und \(p\in\M\) ein Punkt der Mannigfaltigkeit.
Wir nennen eine lineare Abbildung \(D: C^\infty(\M) \to \R\) eine \sphinxstylestrong{Derivation} an \(p\), falls sie die folgende Produktregel erfüllt,
\begin{equation*}
\begin{split}D(fg) = D(f) g(p) + f(p) D(g).\end{split}
\end{equation*}
\sphinxAtStartPar
Der Raum der Derivationen an \(p\)
\begin{equation*}
\begin{split}T^{\text{alg}}_p\M := \{D\in C^\infty(\M)^\ast: D\text{ ist Derivation an }p\}\end{split}
\end{equation*}
\sphinxAtStartPar
wird als \sphinxstylestrong{algebraischer Tangentialraum} bezeichnet.
\end{sphinxadmonition}

\sphinxAtStartPar
Über die Menge der Derivation erhalten wir auf natürliche Art einen Vektorraum da per Definition
\begin{equation*}
\begin{split}T^{\text{alg}}_p\M \subset (C^\infty(\M))^\ast\end{split}
\end{equation*}
\sphinxAtStartPar
gilt.
Somit erbt der algebraischer Tangentialraum die Vektorraumoperationen von \(C^\infty(\M)^\ast\) und es muss lediglich nachgeprüft werden, dass diese Teilmenge noch immer ein Vektorraum, also inbesondere abgeschlossen ist.
\label{vektoranalysis/diffformen:lemma-26}
\begin{sphinxadmonition}{note}{Lemma 3.14}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit und \(p\in\M\) ein Punkt der Mannigfaltigkeit.
Dann ist \(T^{\text{alg}}_p\M\) ein reeller Vektorraum.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Siehe Übung.
\end{sphinxadmonition}

\sphinxAtStartPar
Wie der Name schon erkennen lässt haben Derivationen gewisse Eigenschaften, die von der Ableitungsoperation bekannt sind.
So bildet zum Beispiel jede Derivation konstante Funktionen auf \(0\) ab, wie das folgende Lemma zeigt.
\label{vektoranalysis/diffformen:lem:constder}
\begin{sphinxadmonition}{note}{Lemma 3.15 (Derivation konstanter Funktionen)}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit und \(p\in\M\) ein Punkt der Mannigfaltigkeit.
Außerdem sei \(f\in C^\infty(\M)\) eine konstante Funktion, d.h., es existiert eine Konstante \(c\in\R\), so dass
\begin{equation*}
\begin{split}f(q) = c\quad\forall q\in\M.\end{split}
\end{equation*}
\sphinxAtStartPar
Dann gilt schon \(D(f)=0\) für alle Derivationen \(D\in T^{\text{alg}}_p\M\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Es sei \(D\in T^{\text{alg}}_p\M\) eine beliebige Derivation an den Punkt \(p \in \M\).
Wir betrachten zunächst die konstante Einsfunktion
\begin{equation*}
\begin{split}g:\M &\to \R\\
q &\mapsto g(x) := 1.\end{split}
\end{equation*}
\sphinxAtStartPar
Dann gilt mit der Produktregel für Derivationen
\begin{equation*}
\begin{split}D(g) = D(g\cdot g) = D(g)\,g(p) + g(p)\, D(g) = 2\,D(g)\end{split}
\end{equation*}
\sphinxAtStartPar
und somit muss schon \(D(g) = 0\) gelten.
Wir können die konstante Funktion \(f\) nun darstellen als \(f= c\,g\) und unter Ausnutzung der Linearität von \(D\) erhalten wir schon
\begin{equation*}
\begin{split}D(f) = D(c\,g) = c\,D(g) = 0.\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Wir haben nun zwei verschiedene Arten gesehen den Tangentialraum einzuführen.
Tatsächlich sind diese Definitionen äquivalent in dem Sinn, dass ein Isomorphismus zwischen dem geometrischen und algebraischen Tangentialraum existiert.
\label{vektoranalysis/diffformen:theorem-28}
\begin{sphinxadmonition}{note}{Theorem 3.4 (Isomorphie zwischen alg. und geom. Tangentialraum)}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit und \(p\in\M\) ein Punkt der Mannigfaltigkeit.
Dann gilt die folgende Isomorphie
\begin{equation*}
\begin{split}T^{\text{geom}}_p\M \ \cong \ T^{\text{alg}}_p\M.\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Siehe z.B. Kapitel 2.3 in {[}\hyperlink{cite.references:id14}{Janich03}{]}.
\end{sphinxadmonition}


\paragraph{Basis des algebraische Tangentialraums}
\label{\detokenize{vektoranalysis/diffformen:basis-des-algebraische-tangentialraums}}\label{\detokenize{vektoranalysis/diffformen:sec-tpbasis}}
\sphinxAtStartPar
Wir wollen in diesem Abschnitt eine Basis des algebraischen Tangentialraums konstruieren.
Im Euklidischen Raum können wir auf natürliche Art die Koordinatenrichtungen als Kurven wählen, also Funktionen der Form
\begin{equation*}
\begin{split}t \mapsto t e_i\end{split}
\end{equation*}
\sphinxAtStartPar
für \(i=1,\ldots,n\), wobei \(e_i\) den \(i\)\sphinxhyphen{}ten Einheitsvektor in \(\R^n\) bezeichnet.
Um diese Idee auf Mannigfaltigkeiten zu übertragen wählen wir eine Karte \(\varphi:\M\to\R^n\), wobei man hier auch von
\begin{equation*}
\begin{split}\varphi = (\varphi_1,\ldots,\varphi_n) =: (x^1,\ldots,x^n)\end{split}
\end{equation*}
\sphinxAtStartPar
als einem \sphinxstylestrong{lokalen Koordinatensystem} spricht.
Wir erhalten somit Kurven
\begin{equation*}
\begin{split}\gamma_{x^i}(t):= \varphi^{-1}(\varphi(p) + t e_i)\end{split}
\end{equation*}
\sphinxAtStartPar
und mithilfe der Richtungsableitung aus {\hyperref[\detokenize{vektoranalysis/diffformen:def:direcdiv}]{\sphinxcrossref{Definition 3.23}}} die Derivationen
\begin{equation*}
\begin{split}\partial_{x^i}^p: C^\infty(\M) &\to \R\\
f &\mapsto \partial_{x^i}^p(f) := \frac{d}{dt} (f\circ \gamma_{x^i}(t)).\end{split}
\end{equation*}\label{vektoranalysis/diffformen:definition-29}
\begin{sphinxadmonition}{note}{Definition 3.26 (Partielle Derivation)}



\sphinxAtStartPar
Sei \(\M\) eine glatte \(n\)\sphinxhyphen{}dimensionale Mannigfaltigkeit für \(n\in\N\) und sei \(f \in C^\infty(\M)\) eine glatte Funktion.
Dann bezeichnen wir die Derivationen
\begin{equation*}
\begin{split}\partial_{x^i}^p (f) := \frac{d}{dt} (f\circ \gamma_{x^i}(t)), \quad i=1,\ldots,n\end{split}
\end{equation*}
\sphinxAtStartPar
als \sphinxstylestrong{partielle Derivationen} von \(f\) im Punkt \(p \in \M\).
\end{sphinxadmonition}

\sphinxAtStartPar
Wir interpretieren also im Folgenden das Symbol \(\partial_{x^{i}}^p\) als Derivation an \(p\in\M\), d.h., insbesondere als lineare Abbildung von \(C^\infty(\M)\) nach \(\R\).
Diese partiellen Derivationen folgen der Intuition, dass die partielle Ableitung in eine Richtung auch nur Änderungen in diese Richtung respektiert.
Wir formalisieren diese Anschauung in folgendem Lemma.
\label{vektoranalysis/diffformen:lem:partderkron}
\begin{sphinxadmonition}{note}{Lemma 3.16}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit, \(p\in\M\) ein Punkt der Mannigfaltigkeit und \((U,\varphi)\) sei eine Karte mit \(p\in U\).
Dann gilt für die partielle Derivation
\begin{equation*}
\begin{split}\partial_{x^i}^p(\varphi_j) = \delta_{ij},\end{split}
\end{equation*}
\sphinxAtStartPar
wobei \(\delta_ij\) das \sphinxstyleemphasis{Kronecker\sphinxhyphen{}Delta} bezeichnet.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Wir betrachten zunächst die Funktion \(\varphi_j \circ \gamma_{x^i}\) und erhalten für \(t\in [-1,1]\)
\begin{equation*}
\begin{split}\varphi_j \circ \gamma_{x^i}(t)
&= \varphi_j \circ \varphi^{-1}(\varphi(p) + t e_i)\\
&= (\varphi(p) + t e_i)_j\\ 
&=
\begin{cases}
\varphi(p) + t e_i &\text{ für } i=j,\\
\varphi_j(p)&\text{ sonst}.
\end{cases}\end{split}
\end{equation*}
\sphinxAtStartPar
Somit gilt schon für die partielle Derivation
\begin{equation*}
\begin{split}\partial_{x^i}^p(\varphi_j)=
\frac{d}{dt} (\varphi_j \circ \gamma_{x^i}(t)) = 
\begin{cases}
1&\text{ für } i=j,\\
0&\text{ sonst}.
\end{cases}\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Das folgende Hauptresultat dieses Abschnitts erlaubt es uns beliebige Derivationen mithilfe der partiellen Derivationen darzustellen, da diese eine Basis des algebraischen Tangentialraums bilden.
\label{vektoranalysis/diffformen:thm:tanbasis}
\begin{sphinxadmonition}{note}{Theorem 3.5}



\sphinxAtStartPar
Es sei \(\M\) eine \(n\)\sphinxhyphen{}dimensionale glatte Mannigfaltigkeit.
Dann bildet die Menge
\begin{equation*}
\begin{split}\{\partial_{x^1}^p,\ldots,\partial_{x^n}^p\}\end{split}
\end{equation*}
\sphinxAtStartPar
eine Basis des algebraischen Vektorraums \(T^{\text{alg}}_p\).
Insbesondere gilt
\begin{equation*}
\begin{split}\dim(T^{\text{alg}}_p)=\dim(T^{\text{geom}}_p)=n\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Es sei \((U,\varphi)\) eine Karte der Mannigfaltigkeit \(\M\) und wir nehmen ohne Beschränkung der Allgemeinheit an, dass \(\varphi(p)=0 \in \R^n\) gilt, was stets durch eine entsprechende Translation des Koordinatensystems erreicht werden kann.
Zusätzlich wählen wir einen Radius \(r>0\) klein genug, so dass \(B_r(0) \subset \varphi(U)\) gilt und betrachten als Karte \(\tilde{\varphi} := \varphi\rvert_{\tilde{U}}\), d.h., die Einschränkung von \(\varphi\) auf \(\tilde{U}:= \varphi^{-1}(B_r(0))\).
Wir können die Karte \(\tilde{\varphi}\) wegen der Kartenunabhängigkeit des Tangentialraums und der Tatsache, dass \((\tilde{U},\tilde{\varphi})\) auch eine Karte der Mannigfaltigkeit \(\M\) mit \(p\in \tilde{U}\) ist, betrachten.
Da das Bild von \(\tilde{\varphi}\) nun der gesamte Ball \(B_r(0) \subset \R^n\) ist, können wir nun Strecken von \(0\) zu einem beliebigen Punkt in \(B_r(0)\) betrachten, welche selbst ganz im Bild von \(\tilde{\varphi}\) enthalten sind.

\sphinxAtStartPar
Sei nun \(f\in C^\infty(\M)\) eine beliebige glatte Funktion.
Dann definieren wir die Funktion \(g:= f\circ \tilde{\varphi}^{-1}\) für die insbesondere \(g\in C^\infty(\R^n)\) gilt.
Für einen beliebigen Punkt \(q\in\tilde{U}\) erhalten wir einen Richtungsvektor \(z:=\tilde{\varphi}(q)\in B_r(0)\) und können somit die Einschränkung von \(g\) auf die eindimensionale Strecke zwischen \(0\) und \(z\) in \(\R^n\) betrachten, d.h.,
\begin{equation*}
\begin{split}\tilde{g}:[0,1] &\to\R\\
t&\mapsto g(t\cdot z).\end{split}
\end{equation*}
\sphinxAtStartPar
Hierbei sieht man erneut ein, dass \(\tilde{g}\in C^\infty([0,1])\) gilt.
Dies bedeutet insbesondere, dass wir den \sphinxstyleemphasis{Hauptsatz der Differential\sphinxhyphen{} und Integralrechnung} (vgl. Theorem 5.3 in {[}\hyperlink{cite.references:id12}{Ten21}{]}) anwenden können und somit erhalten wir
\begin{equation*}
\begin{split}\tilde{g}(1) = \tilde{g}(0) + \int_{0}^1 \tilde{g}^\prime(t)\,\mathrm{d}t.\end{split}
\end{equation*}
\sphinxAtStartPar
Wir berechnen die Ableitung im Integral als Richtungsableitung und erhalten,
\begin{equation*}
\begin{split}\int_{0}^1 \tilde{g}^\prime(t) \,\mathrm{d}t
=\int_{0}^1 \langle \nabla g (t\cdot z), z \rangle \,\mathrm{d}t
=\sum_{i=1}^{n} \int_{0}^1  \partial_i g (t\cdot z) \cdot z_i \,\mathrm{d}t.\end{split}
\end{equation*}
\sphinxAtStartPar
Da per Definition
\begin{equation*}
\begin{split}\tilde{g}(1) = g(z)=f(q)\end{split}
\end{equation*}
\sphinxAtStartPar
und
\begin{equation*}
\begin{split}\tilde{g}(0) = g(0) = g(\varphi(p))=f(p)\end{split}
\end{equation*}
\sphinxAtStartPar
gilt, folgt daraus
\begin{equation*}
\begin{split}f(q) = 
f(p) + 
\sum_{i=1}^{n} \varphi_i(q)\ \cdot \underbrace{\int_{0}^1  \partial_i (f\circ \varphi^{-1})(t\cdot \varphi(q)) \, \mathrm{d}t}_{:=F_i(q)}.\end{split}
\end{equation*}
\sphinxAtStartPar
An diesem Punkt bemerken wir, dass \(f\circ \varphi^{-1} \in C^\infty(\R^n)\) eine klassisch differenzierbare Funktion ist, wobei \(f\) eine glatte Funktion auf der Mannigfaltigkeit \(\M\) darstellt.
Wenden wir nun die \(j\)\sphinxhyphen{}te partielle Derivation auf \(f\) an, erhalten wir unter Ausnutzung der Linearität der Abbildung \(\partial_{x^j}^p\)
\begin{equation*}
\begin{split}\partial_{x^j}^p (f) = 
\underbrace{\partial_{x^j}^p (f(p))}_{=0} + 
\sum_{i=1}^{n} \partial_{x^j}^p(\varphi_i \cdot F_i) = 
\sum_{i=1}^{n} \partial_{x^j}^p(\varphi_i \cdot F_i)\end{split}
\end{equation*}
\sphinxAtStartPar
wobei wir {\hyperref[\detokenize{vektoranalysis/diffformen:lem:constder}]{\sphinxcrossref{Lemma 3.15}}} und die Tatsache, dass \(\varphi_i, F_i\in C^\infty(\M)\) gilt, benutzt haben.
Weiterhin gilt wegen der Leibnizregel
\begin{equation*}
\begin{split}\partial_{x^j}^p(\varphi_i \cdot F_i(q)) = 
\underbrace{\partial_{x^j}^p(\varphi)}_{=\delta_{ij}} F_i(p)+ \underbrace{\varphi_i(p)}_{=0} \partial_{x^j}^p(F_i),\end{split}
\end{equation*}
\sphinxAtStartPar
wobei wir {\hyperref[\detokenize{vektoranalysis/diffformen:lem:partderkron}]{\sphinxcrossref{Lemma 3.16}}} und \(\varphi(p)=0\) verwendet haben.
Somit folgt schon
\begin{equation*}
\begin{split}\partial_{x^j}^p (f) = F_j(p)\end{split}
\end{equation*}
\sphinxAtStartPar
und damit insbesondere
\begin{equation*}
\begin{split}f = f(p) + \sum_{i=1}^{n} \varphi_i \partial_{x^i}^p(f).\end{split}
\end{equation*}
\sphinxAtStartPar
Dies bedeutet aber schon, dass die partiellen Derivationen ein \sphinxstylestrong{Erzeugendensystem} des algebraischen Tangentialraums bilden, denn sei \(D\in T^{\text{alg}}_p\) eine beliebige Derivation, dann gilt
\begin{equation*}
\begin{split}D(f) = \underbrace{D(f(p))}_{=0} + \sum_{i=1}^n D(\varphi_i) \partial_{x^i}^p(f).\end{split}
\end{equation*}
\sphinxAtStartPar
Dies bedeutet, dass jede Derivation \(D\) über eine Linearkombination aus partiellen Derivationen dargestellt werden kann, wobei die Koeffizienten durch \(D(\varphi_i)\) gegeben sind.

\sphinxAtStartPar
Es bleibt die Eindeutigkeit der Darstellung zu zeigen.
Seien dazu Koeffizienten \(\alpha_i \in \R, i=1,\ldots,n\) gegeben, so dass für jede Funktion \(f\in C^\infty(\M)\) gilt
\begin{equation*}
\begin{split}D:= \sum_{i=1}^n \alpha_i \partial_{x^i}^p(f) = 0.\end{split}
\end{equation*}
\sphinxAtStartPar
Durch erneute Anwendung von {\hyperref[\detokenize{vektoranalysis/diffformen:lem:partderkron}]{\sphinxcrossref{Lemma 3.16}}} erhalten wir aber, dass
\begin{equation*}
\begin{split}0 = D(\varphi_j) = \alpha_j \end{split}
\end{equation*}
\sphinxAtStartPar
für alle \(j=1,\ldots,n\) und somit haben wir die \sphinxstylestrong{lineare Unabhängigkeit} bewiesen.

\sphinxAtStartPar
Insgesamt bilden also die partiellen Deriviationen eine Basis des algebraischen Tangentialraums und es gilt
\begin{equation*}
\begin{split}\dim(T^{\text{alg}}_p)=\dim(T^{\text{geom}}_p)=n.\end{split}
\end{equation*}\end{sphinxadmonition}


\paragraph{Kotangentialraum}
\label{\detokenize{vektoranalysis/diffformen:kotangentialraum}}
\sphinxAtStartPar
Da wir den Tangentialraum \(T^{\text{alg}}_p\) als Vektorraum identifiziert haben, können wir auch dessen algebraischen Dualraum in der folgenden Definition betrachten.
\label{vektoranalysis/diffformen:definition-32}
\begin{sphinxadmonition}{note}{Definition 3.27 (Kotangentialraum)}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit.
Dann bezeichnen wir mit
\begin{equation*}
\begin{split}T_p^\ast\M:= (T_p^{\text{alg}}\M)^\ast\end{split}
\end{equation*}
\sphinxAtStartPar
den algebraischen Dualraum des Tangentialraums, welcher häufig \sphinxstylestrong{Kotangentialraum} genannt wird.
\end{sphinxadmonition}
\label{vektoranalysis/diffformen:remark-33}
\begin{sphinxadmonition}{note}{Remark 3.19}



\sphinxAtStartPar
Ein Element \(\delta\in T_p^\ast\M\) ist also eine lineare Abbildung
\begin{equation*}
\begin{split}\delta: T_p^{\text{alg}}\M \to \R,\end{split}
\end{equation*}
\sphinxAtStartPar
die eine Derivation \(D\in C^\infty(\M)^\ast\) auf eine reelle Zahl \(\delta(D)\in\R\) abbildet.
\end{sphinxadmonition}

\sphinxAtStartPar
Die folgende Definition beschreibt ein wichtiges Element des Kotangentialraums.
\label{vektoranalysis/diffformen:definition-34}
\begin{sphinxadmonition}{note}{Definition 3.28 (Totales Differential)}



\sphinxAtStartPar
Sei \(f\in\C^\infty(\M)\) eine beliebige glatte Funktion auf einer Mannigfaltigkeit \(\M\).
Dann bezeichnen wir das Element \(\mathrm{d}f_p \in T_p^\ast\M\) mit
\begin{equation*}
\begin{split}\mathrm{d}f_p: T_p^{\text{alg}}\M &\to\R\\
D_p &\mapsto \mathrm{d}f_p(D):= D_p(f).\end{split}
\end{equation*}
\sphinxAtStartPar
als \sphinxstylestrong{totales Differential} der Funktion \(f\) im Punkt \(p \in \M\).
\end{sphinxadmonition}

\sphinxAtStartPar
Insbesondere können wir das totale Differential \(df\) mit einer glatten Funktion aus \(C^\infty(M)\) identifizieren, was den Zusammenhang von \(T^\ast_p \M\) als Bidualraum von \(C^\infty(\M)\) unterstreicht.

\sphinxAtStartPar
Die Basis von \(T^\ast_p\) wird kanonisch als duale Basis (siehe {\hyperref[\detokenize{vektoranalysis/multilinear:lem:dualeBasis}]{\sphinxcrossref{Lemma 3.3}}}) gewählt.
Jeder Vektor \(v\in T_p^{\text{alg}}\M\) hat somit eine eindeutige Darstellung
\begin{equation*}
\begin{split}v = \sum_{i=1}^n \alpha_i \partial_{x^i}.\end{split}
\end{equation*}
\sphinxAtStartPar
Wir wählen nun Abbildungen \(\mathrm{d}x^i\in T^\ast_p\M, i=1,\ldots,n\) gerade so, dass
\begin{equation*}
\begin{split}\mathrm{d}x^i(v) = \alpha_i\end{split}
\end{equation*}
\sphinxAtStartPar
gilt.
Das folgende Lemma zeigt, dass es sich hierbei um eine Basis von \(T^\ast_p\M\) handelt.
\label{vektoranalysis/diffformen:lemma-35}
\begin{sphinxadmonition}{note}{Lemma 3.17}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit und \(p\in\M\).
Dann ist die Menge
\begin{equation*}
\begin{split}\{\mathrm{d}x^1,\ldots, \mathrm{d}x^n\}\end{split}
\end{equation*}
\sphinxAtStartPar
eine Basis von \(T_p^\ast\M\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Die Aussage folgt direkt aus {\hyperref[\detokenize{vektoranalysis/multilinear:lem:dualeBasis}]{\sphinxcrossref{Lemma 3.3}}}.
\end{sphinxadmonition}


\subsubsection{Tangentialbündel}
\label{\detokenize{vektoranalysis/diffformen:tangentialbundel}}
\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Im Folgenden bezeichne \(T_p\M\in\{T^{\text{alg}}_p\M, T^{\text{geom}}_p\M \}\) entweder den \sphinxstyleemphasis{algebraischen} oder den \sphinxstyleemphasis{geometrischen Tangentialraum}.
Die konkrete Wahl wird an den entsprechenden Stellen (wenn nötig) spezifiziert.
\end{sphinxadmonition}

\sphinxAtStartPar
Bisher haben wir für eine \(n\)\sphinxhyphen{}dimensionale glatte Mannigfaltigkeit \(\M\) für jeden einzelnen Punkt \(p\in\M\) den zugehörigen Tangentialraum \(T_p\M\) betrachtet, welcher wiederum wegen {\hyperref[\detokenize{vektoranalysis/diffformen:thm:tanbasis}]{\sphinxcrossref{Theorem 3.5}}} isomorph zum \(\R^n\) ist.
Wir interessieren uns jetzt dafür, wie sich Tangentialräume für verschiedene Punkte \(p,q\in \M\) in Beziehung setzen lassen.
Darüber hinaus wollen wir eine globale Struktur definieren welche alle Tangentialräume (d.h. für jedes \(p\in\M\)) zusammenfasst.

\sphinxAtStartPar
In diesem Kontext spricht man von der Mannigfaltigkeit häufig als dem \sphinxstylestrong{Basisraum} \(B=\M\), da die Punkte \(p \in \M\), welche die Vektorräume erzeugen, aus diesem Raum entnommen werden.
Ein erster Ansatz für eine globale Struktur ist die Vereinigung
\begin{equation*}
\begin{split}\bigcup_{p\in\M} T_p\M.\end{split}
\end{equation*}
\sphinxAtStartPar
Wir wollen diese Idee im folgenden Beispiel veranschaulichen.
\label{vektoranalysis/diffformen:ex:tangentialS1}
\begin{sphinxadmonition}{note}{Example 3.18 (Tangentialräume an Einheitskreis)}



\sphinxAtStartPar
Sei als zu Grunde liegende Mannigfaltigkeit der Einheitskreis \(\M = \mathbb{S}^1\subset\R^2\) gegeben.
Wir wählen als Repräsentanten für jeden Punkt
\begin{equation*}
\begin{split}p=(\cos(\alpha), \sin(\alpha))\in\M, \quad \alpha\in (0,2\pi) \setminus \{\pi\}\end{split}
\end{equation*}
\sphinxAtStartPar
die Kurve
\begin{equation*}
\begin{split}\gamma_p(t) := p - t \cdot\big(1, \frac{\cos(\alpha)}{\sin(\alpha)}\big),\end{split}
\end{equation*}
\sphinxAtStartPar
und somit erhalten wir anschaulich die in \hyperref[\detokenize{vektoranalysis/diffformen:fig-bundlea}]{Fig.\@ \ref{\detokenize{vektoranalysis/diffformen:fig-bundlea}}} für einige Punkte visualisierte Menge.

\sphinxAtStartPar
Es fällt auf, dass sich zwar einzelne Kurven schneiden können, jedoch die Kurven selbst und die assoziierten Vektorräume nicht gleich sind.
Um diese Tatsache zu verdeutlichen ist es praktisch die \sphinxstyleemphasis{disjunkte Vereinigung}
\begin{equation*}
\begin{split}\bigsqcup_{p\in\M} T_p\M := \bigcup_{p\in\M} \{p\} \times T_p\M \cong \bigcup_{p\in\M} \{p\} \times \R\end{split}
\end{equation*}
\sphinxAtStartPar
zu betrachten.
Für den Einheitskreis erhalten wir durch die Isomorphie \(T_p\M \cong \R\) so den Zylinder in \hyperref[\detokenize{vektoranalysis/diffformen:fig-bundleb}]{Fig.\@ \ref{\detokenize{vektoranalysis/diffformen:fig-bundleb}}}.
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[height=300\sphinxpxdimen]{{bundlea}.jpg}
\caption{Visualisierung der Tangentialräume einiger Punkte am Einheitskreises.}\label{\detokenize{vektoranalysis/diffformen:fig-bundlea}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[height=300\sphinxpxdimen]{{bundleb}.jpg}
\caption{Visualisierung der disjunkt vereinigten Tangentialräume einiger Punkte am Einheitskreises.}\label{\detokenize{vektoranalysis/diffformen:fig-bundleb}}\end{figure}

\sphinxAtStartPar
Wir wollen diese globale Struktur der disjunkten Vereinigung formal definieren.
\label{vektoranalysis/diffformen:definition-37}
\begin{sphinxadmonition}{note}{Definition 3.29 (Tangentialbündel)}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit.
Dann heißt die Menge
\begin{equation*}
\begin{split}T\M := \bigsqcup_{p\in\M}  T_p\M = \bigcup_{p\in\M} \{p\} \times T_p\M\end{split}
\end{equation*}
\sphinxAtStartPar
zusammen mit der Projektion
\begin{equation*}
\begin{split}\pi:T\M &\to \M\\
\{p\}\times T_p\M &\mapsto p\end{split}
\end{equation*}
\sphinxAtStartPar
das \sphinxstylestrong{Tangentialbündel} von \(\M\).
\end{sphinxadmonition}

\sphinxAtStartPar
Insbesondere erkennen wir, dass wir mit Hilfe der Projektion \(\pi\) jedem Element des Tangentialbündels eindeutig den zu Grunde liegenden Punkt \(p\in\M\) zuordnen können, der den entsprechenden Tangentialraum erzeugt hat.

\sphinxAtStartPar
Im Folgenden wollen wir uns zwei Beispiele für Tangentialbündel an Mannigfaltigkeiten ansehen.
\label{vektoranalysis/diffformen:example-38}
\begin{sphinxadmonition}{note}{Example 3.19 (Tangentialbündel)}





\sphinxAtStartPar
1. Sei \(\M=\R^n\).
Dann ist das Tangentialbündel gerade gegeben durch
\begin{equation*}
\begin{split}T\M = \R^n\times\R^n = \R^{2n}.\end{split}
\end{equation*}


\sphinxAtStartPar
2. Wie bereits in {\hyperref[\detokenize{vektoranalysis/diffformen:ex:tangentialS1}]{\sphinxcrossref{Example 3.18}}} gesehen erhalten wir für \(\M=\mathbb{S}^1\) als Tangentialbündel den unendlich hohen Zylinder
\begin{equation*}
\begin{split}T\M = \mathbb{S}^1\times \R.\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
In den bisher betrachten Beispielen haben wir als Tangentialbündel jeweils eine Menge der Form \(\M\times \R^n\) erhalten.
Dies ist jedoch nicht immer der Fall wie wir sehen werden.
Tatsächlich bilden Tangentialbündel von dieser Form eine spezielle Unterklasse.
\label{vektoranalysis/diffformen:definition-39}
\begin{sphinxadmonition}{note}{Definition 3.30 (Triviale Tangentialbündel und parallelisierbare Mannigfaltigkeiten)}



\sphinxAtStartPar
Sei \(\M\) eine glatte \(n\)\sphinxhyphen{}dimesnionale Mannigfaltigkeit.
Das Tangentialbündel \(T\M\) heißt \sphinxstylestrong{trivial}, falls gilt
\begin{equation*}
\begin{split}T\M\cong \M\times\R^n.\end{split}
\end{equation*}
\sphinxAtStartPar
In diesem Fall nennt man die Mannigfaltigkeit \(\M\) auch \sphinxstylestrong{parallelisierbar}.
\end{sphinxadmonition}
\label{vektoranalysis/diffformen:remark-40}
\begin{sphinxadmonition}{note}{Remark 3.20}



\sphinxAtStartPar
Es lässt sich zeigen, dass \(\mathbb{S}^1, \mathbb{S}^3,\mathbb{S}^7\) die \sphinxstyleemphasis{einzigen} paralleslisierbaren Sphären sind (siehe {[}\hyperlink{cite.references:id15}{Lee03}{]}).
Die Tatsache, dass \(\mathbb{S}^2\) nicht parallelisierbar ist wird beim Satz vom gekämmten Igel in \sphinxcode{\sphinxupquote{prf:ref}}\{TODO\} erneut auftauchen.
\end{sphinxadmonition}

\sphinxAtStartPar
Wir wollen uns nun mit der Frage beschäftigen, wie sich die Tangentialräume für unterschiedliche Punkte \(p,q\in B\) des Basisraums zueinander verhalten, insbesondere wenn \(p\) und \(q\) nahe beieinander liegen.
Hierbei hilft es das abstraktee Konzept eines \sphinxstylestrong{Vektorbündels} zu betrachten.
\label{vektoranalysis/diffformen:definition-41}
\begin{sphinxadmonition}{note}{Definition 3.31 (Vektorbündel)}



\sphinxAtStartPar
Es seien \(\M\) (der sog. Basisraum) und \(E\) (der sog. Totalraum) zwei glatte Mannigfaltigkeiten und \(\pi:E\to \M\) sei glatt und bijektiv. Weiterhin gelte
Außerdem sei \(\pi:E\to \M\) eine glatte und bijektive Abbildung.
Weiterhin gelte
\begin{itemize}
\item {} 
\sphinxAtStartPar
für jeden Punkt \(p\in \M\) sei die sogenannte \sphinxstylestrong{Faser} \(E_p:= \pi^{-1}(p)\) ein \(n\)\sphinxhyphen{}dimensionaler Vektorraum,

\item {} 
\sphinxAtStartPar
für jeden Punkt \(p\in \M\) existiere eine offene Umgebung \(U\subset \M\) und ein Diffeomorphimus \(\Psi: \pi^{-1}(U)\to U\times\R^n\), so dass für alle \(x\in U\) gilt

\end{itemize}
\begin{equation*}
\begin{split}\text{pr}_U(\Psi(x)) &= \pi(x)\quad\forall x\in \pi^{-1}(U)\\
\Psi\rvert_{E_q}&: \pi^{-1}(q) \to \{q\}\times \R^n \text{ ist ein Isomorphismus, für alle }q\in U.\end{split}
\end{equation*}
\sphinxAtStartPar
Dann heißt \((E,\M,\pi)\) \sphinxstylestrong{Vektorbündel} vom Rang \(n\).
Hierbei bezeichnet \(\text{pr}_U(q, z):= q\) die Projektion auf die \(U\)\sphinxhyphen{}Komponente eines Vektors \((q,z)\in U\times\R^n\).
\end{sphinxadmonition}
\label{vektoranalysis/diffformen:remark-42}
\begin{sphinxadmonition}{note}{Remark 3.21 (Bündel\sphinxhyphen{}Notation)}



\sphinxAtStartPar
Anstatt das Vektorbündel \((E,\M,\pi)\) als Tripel aufzuschreiben, ist es üblich von einem Bündel \(E\overset{\pi}{\to}\M\) oder sogar \(E\to\M\) zu sprechen.
Die Abbildung \(\pi\) wird im zweiten Fall nur \sphinxstyleemphasis{implizit} vorausgesetzt.
\end{sphinxadmonition}

\sphinxAtStartPar
Die Funktion \(\Psi\) nennt man in diesem Kontext \sphinxstylestrong{lokale Trivialisierung}, denn sie erlaubt es uns den Totalraum \(E\) lokal als Produktraum darzustellen.
Analog zum Tangentialbündel nennen wir ein Vektorbündel \sphinxstylestrong{trivial}, falls eine Trivialsierung \(\Psi:E\to \M\times\R^n\) existiert, so dass gilt
\begin{equation*}
\begin{split}E \cong \M\times\R^n.\end{split}
\end{equation*}\label{vektoranalysis/diffformen:example-43}
\begin{sphinxadmonition}{note}{Example 3.20}



\sphinxAtStartPar
Möbius\sphinxhyphen{}Band.
\end{sphinxadmonition}

\sphinxAtStartPar
Wir wollen nun zeigen, dass das Tangentialbündel ein Vektorbündel ist.
Dazu benötigen wir zunächst die Hilfsaussage des folgenden Lemmas, dass das Tangentialbündel \(T\M\) selbst eine glatte Mannigfaltigkeit ist.
\label{vektoranalysis/diffformen:lem:tanman}
\begin{sphinxadmonition}{note}{Lemma 3.18}



\sphinxAtStartPar
Es sei \(\M\) eine glatte \(n\)\sphinxhyphen{}dimensionale Mannigfaltigkeit.
Dann ist das Tangentialbündel \(T\M\) eine glatte \(2n\)\sphinxhyphen{}dimensionale Mannigfaltigkeit.
Insbesondere ist
\begin{equation*}
\begin{split}\pi:T\M &\to \M\\
\{p\}\times T_p\M &\mapsto p\end{split}
\end{equation*}
\sphinxAtStartPar
eine glatte und bijektive Abbildung.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Wir werden lediglich die Idee skizzieren, für den vollständingen Beweis siehe Proposition 3.18 in {[}\hyperlink{cite.references:id15}{Lee03}{]}.
Wir benutzen hier die algebraische Definition des Tangentialraums.

\sphinxAtStartPar
Es sei \((U,\varphi)\) eine Karte.
Wir betrachten die Menge \(\pi^{-1}(U)\subset T\M\) und die Abbildung
\begin{equation*}
\begin{split}\psi:\pi^{-1}(U) \to \phi(U)\times \R^{n}\subset\R^{2n}\\
(p,v) &\mapsto (\varphi(p), v(\varphi)),\end{split}
\end{equation*}
\sphinxAtStartPar
wobei wir für \(v\in T_p\M\subset (C^\infty(\M))^\ast\) die Notation
\begin{equation*}
\begin{split}v(\varphi) := (v(\varphi_1),\ldots, v(\varphi_n))\end{split}
\end{equation*}
\sphinxAtStartPar
benutzt haben.
Es stellt sich dann heraus, dass so definierte Abbildungen \(\psi\) Karten auf \(T\M\) und somit tatsächlich auch eine Mannigfaltigkeit definieren.
Insbsondere ist ein so definiertes \(\psi\) ein Diffeomorphismus.
\end{sphinxadmonition}

\sphinxAtStartPar
Mithilfe der obigen Aussage können wir nun zeigen, dass \(T\M\) ein Vektorbündel ist.
\label{vektoranalysis/diffformen:lemma-45}
\begin{sphinxadmonition}{note}{Lemma 3.19}



\sphinxAtStartPar
Es sei \(\M\) eine glatte \(n\)\sphinxhyphen{}dimensionale Mannigfaltigkeit mit dem Tangentialraum
\begin{equation*}
\begin{split}T\M:= \bigsqcup_{p\in\M}  T_p\M = \bigcup_{p\in\M} \{p\} \times T_p\M\end{split}
\end{equation*}
\sphinxAtStartPar
und der Abbildung
\begin{equation*}
\begin{split}\pi:T\M\to \M\\
\{p\}\times T_p\M\mapsto p.\end{split}
\end{equation*}
\sphinxAtStartPar
Dann ist \((T\M, \M, \pi)\) ein Vektorbündel vom Rang \(n\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Es sei \((U,\varphi)\) eine Karte für \(\M\).
Dann definieren wir die Abbildung
\begin{equation*}
\begin{split}\Psi: \pi^{-1}(U) &\to U\times \R^n\\
(p,v) &\mapsto (p, v(\varphi)).\end{split}
\end{equation*}
\sphinxAtStartPar
Wir erkennen sofort, dass \(\Psi\) linear ist und dass \((\text{pr}_U\circ\Psi)(p,v) = p = \pi(p,v)\) gilt.
Da \(\phi\) ein Diffeomorphismus ist, ist
\begin{equation*}
\begin{split}\phi\times\text{Id}:U\times \R^n &\to \phi(U)\times\R^n\\
(p,z) &\mapsto (\phi(p), z)\end{split}
\end{equation*}
\sphinxAtStartPar
ebenfalls ein Diffeomorphismus.
Hierbei bemerken wir aber, dass gilt
\begin{equation*}
\begin{split}\big((\phi\times\text{Id})\circ \Psi\big)(p,v) = (\phi\times\text{Id})(p, v(\varphi)) = (\phi(p), v(\varphi)).\end{split}
\end{equation*}
\sphinxAtStartPar
Somit entspricht \((\phi\times\text{Id})\circ \Psi\) gerade der Karte aus dem Beweis von {\hyperref[\detokenize{vektoranalysis/diffformen:lem:tanman}]{\sphinxcrossref{Lemma 3.18}}} und ist somit auch ein Diffeomorphismus.
Daraus folgt aber, dass \(\Psi\) schon ein Diffeomorphismus sein muss.
\end{sphinxadmonition}


\subsubsection{Vektorfelder}
\label{\detokenize{vektoranalysis/diffformen:vektorfelder}}
\sphinxAtStartPar
Wir führen zunächst sogenannte Schnitte auf Bündeln ein. Anschaulich abstrahieren wir hier das Konzept der Graphen von Funktionen.

\sphinxAtStartPar
Es sei \(f:\M\to\R^n\) eine Funktion\$, dann ist ihr Graph gegeben durch
\begin{equation*}
\begin{split}\{(p,f(p)): p\in\M\}\subset \M\times\R^n.\end{split}
\end{equation*}
\sphinxAtStartPar
Hierbei sehen wir, dass \(\M\times\R^n\overset{\pi}{\to}\M\) ein triviales Bündel ist mit
\begin{equation*}
\begin{split}\pi(p,(f(p))) = p.\end{split}
\end{equation*}
\sphinxAtStartPar
Verallgemeinert betrachten führt diese Überlegung auf folgende Definition.
\label{vektoranalysis/diffformen:definition-46}
\begin{sphinxadmonition}{note}{Definition 3.32}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit und \(E\overset{\pi}{\to}\M\) ein Vektorbündel. Für \(U\subset\M\) offen, heißt eine glatte Abbildung
\begin{equation*}
\begin{split}\sigma: U\to E\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{lokaler glatter Schnitt}, falls
\begin{equation*}
\begin{split}\pi(\sigma(p)) = p\quad\text{ für alle }p\in U.\end{split}
\end{equation*}
\sphinxAtStartPar
Die Menge der glatten Schnitte auf \(U\) wird mit \(\Gamma(E\rvert_U)\) bezeichnet. Für \(U=\M\) heißt \(\sigma\) \sphinxstylestrong{glatter Schnitt} und wir definieren
\(\Gamma(E):=\Gamma(E\rvert_\M)\).
\end{sphinxadmonition}

\sphinxAtStartPar
Für offenen Mengen im euklidischen kennen wir bereits den Begriff \sphinxstylestrong{Vektorfeld}, nämlich eine Funktion
\begin{equation*}
\begin{split}F:U\to\R^n\end{split}
\end{equation*}
\sphinxAtStartPar
wobei \(U\subset\R^n\) offen ist. Wir nehmen also Punkte \(x\in\R^n\) und ordnen ihnen Vektoren \(F(x)\in\R^n\) aus dem gleichen Raum zu. Betrachten wir statt offenen Mengen \(U\subset\R^n\) nun glatte Mannigfaltigkeiten \(\M\) so stellt sich a priori die Frage in welchen Raum Vektorfelder abbilden sollen. Hierbei hilft uns nun der Tangentialraum \(T\M\), welcher die richtige Wahl des Zielraums darstellt. Somit können wir Vektorfelder verallgemeinern indem wir als Schnitte des Tangenialraums auffassen.
\label{vektoranalysis/diffformen:definition-47}
\begin{sphinxadmonition}{note}{Definition 3.33}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit, ein glatter Schnitt
\begin{equation*}
\begin{split}X:\M\to T\M\end{split}
\end{equation*}
\sphinxAtStartPar
heißt glattes Vektorfeld. Das Argument von \(X\) wird hierbei meist als subskript notiert, d.h., \(X_p = X(p)\).
\end{sphinxadmonition}

\sphinxAtStartPar
Für Tangentialbündel haben wir die Abbildung \(\pi:T\M\to\M\) durch
\begin{equation*}
\begin{split}\pi(p,v):= p\quad\text{ für } (p,v)\in\{p\}\times T_p\M\end{split}
\end{equation*}
\sphinxAtStartPar
definiert. Ist \(X\) nun ein glattes Vektorfeld, so gilt
\begin{equation*}
\begin{split}\pi(X(p)) = p\end{split}
\end{equation*}
\sphinxAtStartPar
und somit insbesondere \(X_p\in T_p\M\). Ein Vektorfeld ordnet also jedem Punkt \(p\in\M\) ein Element seines Tangentialraums zu. Falls \(\M\) eine offene Menge in \(\R^n\) ist, ist dies insbesondere konsistent zur bekannten Definition von Vektorfeldern.


\paragraph{Wirkung von Vektorfeldern}
\label{\detokenize{vektoranalysis/diffformen:wirkung-von-vektorfeldern}}
\sphinxAtStartPar
Von der algebraischen Definition des Tangentialraums ist das totale Differential \(df_p\in T^\ast_p\M\) bekannt, welches für \(D\in T^{\text{alg}}_p\M\) definiert ist durch
\begin{equation*}
\begin{split}df_p(D):= D(f)\end{split}
\end{equation*}
\sphinxAtStartPar
für eine Funktion \(f\in C^\infty(M)\). Mithilfe dieses Konzepts können wir die Wirkung eines Vektorfelds definieren.
\label{vektoranalysis/diffformen:definition-48}
\begin{sphinxadmonition}{note}{Definition 3.34 (Wirkung von Vektorfeldern)}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit und \(X\in\Gamma(T\M)\), die \sphinxstylestrong{Wirkung} von \(X\) auf \(C^\infty\) ist definiert durch
\begin{equation*}
\begin{split}X(\cdot):C^\infty(M)\to C^\infty(\M)\\
f\mapsto [p\mapsto X_p(f) := df_p(X)].\end{split}
\end{equation*}\end{sphinxadmonition}


\paragraph{Lokale Basis von Vektorfeldern}
\label{\detokenize{vektoranalysis/diffformen:lokale-basis-von-vektorfeldern}}
\sphinxAtStartPar
Aus \hyperref[\detokenize{vektoranalysis/diffformen:sec-tpbasis}]{Section \ref{\detokenize{vektoranalysis/diffformen:sec-tpbasis}}} wissen wir bereits, dass wir für \(p\in\M\) Tangentialvektoren \(v\in T_p\M\) durch die Vektoren \(\partial_{x^i}^p\) darstellen können. Im Kontext von Tangentialbündeln stellt sich auf natürliche Art die Frage, wie sich diese Vektoren verändern, wenn der Punkt \(p\) variiert wird. Hierzu definieren wir folgende Abbildungen.
\label{vektoranalysis/diffformen:definition-49}
\begin{sphinxadmonition}{note}{Definition 3.35}



\sphinxAtStartPar
Es sei \(\M\) eine glatte \(n\)\sphinxhyphen{}dimesnionale Mannigfaltigkeit und \((U,\phi)\) eine Karte, dann definieren wir die lokalen Koordinatenfelder
für \(i=1,\ldots,n\) durch
\begin{equation*}
\begin{split}\partial_{x^{i}}&:\M\to T\M\\
\partial_{x^{i}}(p)&:= \partial_{x^{i}}\rvert_p\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Mithilfe dieser lokalen Koordiantenfelder können wir nun Vektorfelder lokal darstellen.
\label{vektoranalysis/diffformen:lem:localsections}
\begin{sphinxadmonition}{note}{Lemma 3.20}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit und \((U,\phi)\) sei eine Karte, dann gilt für \(X\in\Gamma(T\M\rvert_U)\) und die Koeffizientfunktionen \(X^i:=X(\phi_i)\in C^\infty(U)\)
\begin{equation*}
\begin{split}X = \sum_{i=1}^n X^i \partial_{x^{i}}.\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Es sei \(p\in\M\), dann haben wir wegen  {\hyperref[\detokenize{vektoranalysis/diffformen:thm:tanbasis}]{\sphinxcrossref{Theorem 3.5}}} die Darstellung
\begin{equation*}
\begin{split}X_p = \sum_{i=1}^n X_p(\phi_i) \partial_{x^i}^p.\end{split}
\end{equation*}
\sphinxAtStartPar
Mit der Defintion der Wirkung von Vektorfeldern folgt dann
\begin{equation*}
\begin{split}X = \sum_{i=1}^n X(\phi_i) \partial_{x^i}.\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Aus dieser Darstellung folgt auch, dass lokal für eine Karte \((U,\phi)\) die Wirkung auf \(f\in C^\infty(U)\) geschrieben werden kann als
\begin{equation*}
\begin{split}X(f) := \sum_{i=1}^n X^i \frac{\partial f}{\partial_{x^i}}.\end{split}
\end{equation*}

\subsubsection{Tensorfelder}
\label{\detokenize{vektoranalysis/diffformen:tensorfelder}}
\sphinxAtStartPar
Als natürliche Verallgemeinerung wollen wir nun das Konzept der Felder auf Mannigfaltigkeiten von Vektoren auf Tensoren übertragen. Hierbei benutzt man oft auch das Kotangentialbündel, welches direkt über den Kotangentialraum definiert werden kann.
\label{vektoranalysis/diffformen:definition-51}
\begin{sphinxadmonition}{note}{Definition 3.36}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit, dann ist das \sphinxstylestrong{Kotangentialbündel} \(\pi^\ast (T\M)^\ast\to\M\) mit der Menge
\begin{equation*}
\begin{split}(T\M)^\ast := \bigsqcup_{p\in\M} T_p\M\end{split}
\end{equation*}
\sphinxAtStartPar
und der Abbildung
\begin{equation*}
\begin{split}\pi^{\ast}(p , v):= T_p^\ast\M = (T_p\M)^\ast\end{split}
\end{equation*}
\sphinxAtStartPar
definiert.
\end{sphinxadmonition}

\sphinxAtStartPar
Auch in diesem Fall erhält man ein Vektorbündel.
\label{vektoranalysis/diffformen:lemma-52}
\begin{sphinxadmonition}{note}{Lemma 3.21}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit, dann ist das Kotangentialbündel \(\pi^\ast (T\M)^\ast\to\M\) ein Vektorbündel.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Siehe Übung.
\end{sphinxadmonition}

\sphinxAtStartPar
Um ein Tensorfeld definieren zu können müssen wir zunächst klären, wie das Tensorprodukt von Tangentialbündeln aussehen soll. Für zwei Vektorbündel \(E\overset{\pi_E}{\to}{\M}, F\overset{\pi_F}{\to}{\M}\) wissen wir, dass für jedes \(p\in\M\) die Fasern \(E_p, F_p\) endlichdimensionale Vektorräume sind. Insbeonsdere können wir also das Tensorprodukt
\begin{equation*}
\begin{split}E_p\otimes F_p\end{split}
\end{equation*}
\sphinxAtStartPar
betrachten und damit ein Bündel auf dem Totalraum
\begin{equation*}
\begin{split}E\otimes F:= \bigsqcup_{p\in\M} E_p\otimes F_p\end{split}
\end{equation*}
\sphinxAtStartPar
betrachten. Die entsprechende Projektion \(\pi_{E\otimes F}:E\otimes F\to\M\) ist gegeben durch
\begin{equation*}
\begin{split}\pi_{E\otimes F}^{-1}(p):= E_p\otimes F_p := (E\otimes F)_p.\end{split}
\end{equation*}\label{vektoranalysis/diffformen:lem:tensorbundle}
\begin{sphinxadmonition}{note}{Lemma 3.22}



\sphinxAtStartPar
Es sei \(E\overset{\pi_E}{\to}{\M}\) ein Vektorbündel vom Rang \(k\) und \(F\overset{\pi_F}{\to}{\M}\) ein Vektorbündel vom Rang \(l\), dann ist
\begin{equation*}
\begin{split}\pi_{E\otimes F}:(E\otimes F)\to \M\end{split}
\end{equation*}
\sphinxAtStartPar
ein Vektorbündel vom Rang \(kl\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Siehe Übung.
\end{sphinxadmonition}

\sphinxAtStartPar
Die Definition des Tensorbündels lässt sich direkt auf mehrfache Tensorprodukte übertragen und führt uns direkt auf gemischte Tensorbündel.
\label{vektoranalysis/diffformen:definition-54}
\begin{sphinxadmonition}{note}{Definition 3.37}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit, und \(r,s\in\N_0\), s.d. \(r+s>0\), dann heißt
\begin{equation*}
\begin{split}T^r_s\M := \bigsqcup_{p\in\M} T^r_s(T_p\M) \to \M\end{split}
\end{equation*}
\sphinxAtStartPar
Tensorbündel der Stufe \((r,s)\).
\end{sphinxadmonition}

\sphinxAtStartPar
Mit den vorherigen Überlegungen können wir direkt Schlussfolgern, dass wir hier erneut ein Vektorbündel definiert haben.
\label{vektoranalysis/diffformen:corollary-55}
\begin{sphinxadmonition}{note}{Corollary 3.5}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit, und \(r,s\in\N_0\), s.d. \(r+s>0\), dann ist \(\pi:T^r_s\M\to\M\) mit der kanonisch nach {\hyperref[\detokenize{vektoranalysis/diffformen:lem:tensorbundle}]{\sphinxcrossref{Lemma 3.22}}} definierten Abbildung \(\pi\) ein Vektorbündel.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Folgt direkt aus {\hyperref[\detokenize{vektoranalysis/diffformen:lem:tensorbundle}]{\sphinxcrossref{Lemma 3.22}}}.
\end{sphinxadmonition}

\sphinxAtStartPar
Da wir die Struktur eines Vektorbündels definiert haben können wir nun auf natürliche Weise auch \sphinxstylestrong{Tensorfelder} als glatte Schnitte definieren.
\label{vektoranalysis/diffformen:definition-56}
\begin{sphinxadmonition}{note}{Definition 3.38 (Tensorfelder)}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit, und \(r,s\in\N_0\), s.d. \(r+s>0\), ein \sphinxstylestrong{Tensorfeld} ist ein glatter Schnitt \(A\in \Gamma(T^r_s\M)\).
\end{sphinxadmonition}

\sphinxAtStartPar
Dank der lokalen Darstellung von Vektorbündeln in {\hyperref[\detokenize{vektoranalysis/diffformen:lem:localsections}]{\sphinxcrossref{Lemma 3.20}}} können wir die recht abstrakten Tensorfelder lokal sehr konkret Darstellen.
\label{vektoranalysis/diffformen:corollary-57}
\begin{sphinxadmonition}{note}{Corollary 3.6}



\sphinxAtStartPar
Es sei \(\M\) eine glatte \(n\)\sphinxhyphen{}dimensionale Mannigfaltigkeit, \((U,\varphi)\) eine Karte mit lokalen Koordinaten \(\varphi=(x^1,\ldots,x^n)\). Für \(r,s\in\N_0\), s.d. \(r+s>0\) und \(A\in \Gamma(T^r_s\M)\) ein Tensorfeld existieren glatte Koeffizientenfunktionen \(A^{i_1,\ldots, i_r}_{j_1,\ldots,j_s}\in C^\infty(\M)\) für \(i_1,\ldots, i_r, j_1,\ldots, j_s\in \{1,\ldots,n\}\), s.d.,
\begin{equation*}
\begin{split}A = A^{i_1,\ldots,i_r}_{j_1,\ldots,j_s} \partial_{x_{i_1}}\otimes\ldots\otimes \partial_{x_{i_r}}\otimes dx^{j_1}\otimes\ldots\otimes dx^{j_s}.\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Folgt aus {\hyperref[\detokenize{vektoranalysis/diffformen:lem:localsections}]{\sphinxcrossref{Lemma 3.20}}}.
\end{sphinxadmonition}

\sphinxAtStartPar
Ähnlich zu den Überlegungen in \hyperref[\detokenize{vektoranalysis/tensor:s-symtensoren}]{Section \ref{\detokenize{vektoranalysis/tensor:s-symtensoren}}} können wir auch hier das Tensorprodukt von Tensorfeldern betrachten.
\label{vektoranalysis/diffformen:lemma-58}
\begin{sphinxadmonition}{note}{Lemma 3.23}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit, für \(r,l\in \N\) seien \(A\in \Gamma(T^r_0\M), B\in \Gamma(T^l_0\M)\) zwei Tensorfelder und \(f\in C^\infty(\M)\), dann sind \(fA\) und \(A\otimes B\) Tensorfelder mit lokalen Koeffezienten
\begin{equation*}
\begin{split}(fA)_{i_1,\ldots i_{k}} = f A_{i_1,\ldots, i_k}\\
(A\otimes B)_{i_1,\ldots,i_{l+r}} = A_{i_1,\ldots, i_l} B_{i_{l+1},\ldots, i_{l+k}}.\end{split}
\end{equation*}\end{sphinxadmonition}


\subsection{Differentialformen}
\label{\detokenize{vektoranalysis/diffformen:differentialformen}}
\sphinxAtStartPar
In Kapitel ?? haben wir symmetrische und antisymmetrische Tensoren kennengelernt. Dieses Konzept werden wir nun auf Tensorfelder übetragen um somit Differntialformen zu erhalten. Hierfür betrachten wir für eine glatte Mannigfaltigkeit die Menge
\begin{equation*}
\begin{split}\Lambda^k T^\ast\M := \bigsqcup_{p\in\M} \Lambda^k (T^\ast_p\M)\end{split}
\end{equation*}
\sphinxAtStartPar
der alternierenden Tensorfelder. Antisymmetrische Tensoren bilden direkt eine Teilmenge aller Tensoren und es bleibt lediglich zu zeigen, dass die Vektorraumstruktur erhalten bleibt. Die Situation hier ist nun anders, man benötigt den abstrakten Begriff des \sphinxstylestrong{Untervektorbündels}.
\label{vektoranalysis/diffformen:definition-59}
\begin{sphinxadmonition}{note}{Definition 3.39}



\sphinxAtStartPar
Es seien \(\pi_E:E\to B\) und \(\pi_D:D\to B\) zwei Vektorbündel, wobei für jedes \(p\in\M\) die Untervektorraumrelation
\begin{equation*}
\begin{split}\pi_D^{-1}(p) = D_p\subset E_p = \pi_E^{-1}(p)\end{split}
\end{equation*}
\sphinxAtStartPar
gelte, dann heißt \(D\) Untervektorbündel von \(E\).
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[height=300\sphinxpxdimen]{{subbundle}.png}
\caption{Visualisierung eines Untervektorbündels, siehe {[}\hyperlink{cite.references:id15}{Lee03}{]} Kapitel 10.}\label{\detokenize{vektoranalysis/diffformen:fig-subbundle}}\end{figure}

\sphinxAtStartPar
In diesem Fall erhält man also ein Untervektorbündel.
\label{vektoranalysis/diffformen:lemma-60}
\begin{sphinxadmonition}{note}{Lemma 3.24}



\sphinxAtStartPar
Sei \(\M\) eine glatte \(n\)\sphinxhyphen{}dimesnionale Mannigfaltigkeit, dann ist \(\Lambda^k T^\ast\M\) ein glattes Untervektorbündel vom Rang \(\begin{pmatrix} n k \end{pmatrix}\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. ToDo.
\end{sphinxadmonition}

\sphinxAtStartPar
Dank der Bündelstruktur können wir erneut glatte Schnitte betrachten, welche nun auf das Konzept der Diffentialform führen.
\label{vektoranalysis/diffformen:definition-61}
\begin{sphinxadmonition}{note}{Definition 3.40}



\sphinxAtStartPar
Es sei \(\M\) eine glatte Mannigfaltigkeit, dann nennt man einen glatten Schnitt
\begin{equation*}
\begin{split}\omega\in \Gamma(\Lambda^k T^\ast\M)\end{split}
\end{equation*}
\sphinxAtStartPar
eine \(k\)\sphinxhyphen{}Differentialform oder auch \(k\)\sphinxhyphen{}Form. Den Vektorraum der Differntialformen notieren wir durch
\begin{equation*}
\begin{split}\Omega^k(\M) := \Gamma(\Lambda^k T^\ast\M).\end{split}
\end{equation*}\end{sphinxadmonition}


\subsubsection{Das äußere Produkt}
\label{\detokenize{vektoranalysis/diffformen:das-auszere-produkt}}
\sphinxAtStartPar
Eine Differentialform \(\omega\) auf \(U\subseteq\R^n\) ist eine von Ort zu Ort variierende äußere Form, deren Variation wir als glatt voraussetzen.

\sphinxAtStartPar
Wir schreiben eine allgemeine \sphinxstyleemphasis{\(k\)–Form} \(\omega\) in der \sphinxstyleemphasis{Grundform}
\begin{equation*}
\begin{split}\omega = \sum_{1\leq i_1<\ldots<i_k\leq n}\omega_{i_1\ldots i_k}
dx_{i_1}\wedge\ldots\wedge dx_{i_k}\in\Omega^k(U),\end{split}
\end{equation*}
\sphinxAtStartPar
wobei
\begin{itemize}
\item {} 
\sphinxAtStartPar
die \(\omega_{i_1\ldots i_k}\in \Omega^0(U):=C^\infty(U,\R)\), also glatte reelle Funktionen auf \(U\) sind,

\item {} 
\sphinxAtStartPar
und die \(dx_i\) den Koordinatenfunktionen \(x_i:\R^n\to\R\) zugeordnete \(1\)–Differentialformen sind (\(dx_i\in\Omega^1(\R^n)\)).

\item {} 
\sphinxAtStartPar
Den Raum der \(k\)–Differentialformen schreiben wir ab jetzt zur Unterscheidung vom Raum der äußeren \(k\)–Formen mit dem Symbol \(\Omega\) statt \(\Lambda\).

\end{itemize}

\sphinxAtStartPar
Die \(dx_i\) sind durch ihre Wirkung auf ein Vektorfeld \(v:U\to
\R^n\) definiert, und \(dx_i(v)( y) := v_i( y)\).
\(1\)–Differentialformen machen also aus Vektorfeldern Funktionen, und für \(k\) Vektorfelder \(v^{(l)}:U\to\R^n\) ist für das \(\omega\) aus der Grundform
\begin{equation*}
\begin{split}\omega\left(v^{(1)},\ldots,v^{(k)}\right) := \sum_{1\leq i_1<\ldots<i_k\leq n}
\omega_{i_1\ldots i_k}\cdot\det\begin{pmatrix} dx_{i_1}(v^{(1)})&\ldots& dx_{i_k}(v^{(1)})\\
\vdots&&\vdots\\
dx_{i_1}(v^{(k)})&\ldots& dx_{i_k}(v^{(k)}) \end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
definiert. Das Ergebnis ist also eine reelle Funktion auf \(U\).\textbackslash{}
Die Rechenregeln übertragen sich von den äußeren Formen auf die Differentialformten.

\sphinxAtStartPar
Auf dem \(\R\)–Vektorraum
\begin{equation*}
\begin{split}\Omega^*(U) := \bigoplus_{k=0}^n\Omega^k(U)\end{split}
\end{equation*}
\sphinxAtStartPar
der Differentialformen betrachten wir jetzt
den \sphinxstyleemphasis{Differentialoperator} \(d\), der durch
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(df := \sum_{i=1}^n\frac{\partial f}{\partial x_i}dx_i\) für Funktionen
\(f\in C^\infty(U,\R) = \Omega^0(U)\)

\item {} 
\sphinxAtStartPar
und \(d\omega := \sum_{1\leq i_1<\ldots<i_k\leq n}d\omega_{i_1\ldots i_k}
\wedge dx_{i_1}\wedge\ldots\wedge dx_{i_k}\) für \(k\)–Formen \textbackslash{}linebreak
\(\omega = \sum_{1\leq i_1<\ldots<i_k\leq n}\omega_{i_1\ldots i_k}
dx_1\wedge\ldots\wedge dx_{i_k}\)

\end{itemize}

\sphinxAtStartPar
definiert ist. \(d\) verwandelt eine \(k\)–Form also in eine \((k+1)\)–Form.
\label{vektoranalysis/diffformen:aeussere Ableitung}
\begin{sphinxadmonition}{note}{Definition 3.41}



\sphinxAtStartPar
Die lineare Abbildung \(d:\Omega^*(U)\to\Omega^*(U)\) heißt \sphinxhref{https://de.wikipedia.org/wiki/\%C3\%84u\%C3\%9Fere\_Ableitung}{\sphinxstylestrong{äußere Ableitung}}.
\end{sphinxadmonition}
\label{vektoranalysis/diffformen:ex:10.14}
\begin{sphinxadmonition}{note}{Example 3.21 (Äußere Ableitung)}


\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Für \(\omega\in\Omega^0(\R^3)\) ist \(d\omega = \frac{\partial\omega}{\partial x_1}dx_1+
\frac{\partial\omega}{\partial x_2}dx_2+\frac{\partial\omega}{\partial x_3}dx_3\).

\item {} 
\sphinxAtStartPar
Für \(\omega = \omega_1dx_1+\omega_2dx_2+\omega_3dx_3\in\Omega^1(\R^3)\) ist

\end{enumerate}
\begin{equation*}
\begin{split}d\omega &=& (d\omega_1)\wedge dx_1+(d\omega_2)\wedge dx_2+(d\omega_3)\wedge
dx_3\\
&=& \left(\frac{\partial\omega_2}{\partial x_1}-\frac{\partial\omega_1}{\partial x_2}\right)
dx_1\wedge dx_2+ \left(\frac{\partial\omega_3}{\partial x_2}-\frac{\partial\omega_2}{\partial x_3}\right)
dx_2\wedge dx_3\\
&& + \left(\frac{\partial\omega_1}{\partial x_3}-\frac{\partial\omega_3}{\partial x_1}\right)
dx_3\wedge dx_1\end{split}
\end{equation*}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Für \(\omega = \omega_{12}dx_1\wedge dx_2+\omega_{23}dx_2\wedge dx_3
+\omega_{31}dx_3\wedge dx_1 \in\Omega^2(\R^3)\) ist

\end{enumerate}
\begin{equation*}
\begin{split}d\omega = \left(\frac{\partial\omega_{12}}{\partial x_3} + \frac{\partial\omega_{23}}{\partial x_1}
+ \frac{\partial\omega_{31}}{\partial x_2}\right)dx_1\wedge dx_2\wedge dx_3.\end{split}
\end{equation*}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Für \(\omega\in\Omega^3(\R^3)\) ist \(d\omega=0\).

\end{enumerate}
\end{sphinxadmonition}
\label{vektoranalysis/diffformen:Antiderivation}
\begin{sphinxadmonition}{note}{Theorem 3.6}



\sphinxAtStartPar
\(d\) ist eine \sphinxhref{https://de.wikipedia.org/wiki/Derivation\_(Mathematik)\#Antiderivationen}{\sphinxstylestrong{Antiderivation}}, d.h. für \(\alpha\in\Omega^k(U)\) und \(\beta\in\Omega^l(U)\) ist
\begin{equation*}
\begin{split}d(\alpha\wedge\beta) = (d\alpha)\wedge\beta+(-1)^k\alpha\wedge d\beta.\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. Wegen der Linearität von \(d\) genügt es, diese Gleichung für Monome
\begin{equation*}
\begin{split}\alpha := f\underbrace{dx_{i_1}\wedge\ldots\wedge dx_{i_k}}_{\tilde
{\alpha}},\ \beta := g\underbrace{dx_{j_1}\wedge\ldots\wedge dx_{j_l}}_
{\tilde{\beta}},\ f,g\in C^\infty(U,\R)\end{split}
\end{equation*}
\sphinxAtStartPar
zu beweisen.
Es gilt
\begin{equation*}
\begin{split}d(\alpha\wedge\beta) &=& d(f\cdot g)\tilde{\alpha}\wedge
\tilde{\beta} = \big((df)g+f(dg)\big)\,\tilde{\alpha}\wedge\tilde{\beta}\\
&=& (df)\tilde{\alpha}\wedge g\tilde{\beta}+ (-1)^kf\tilde{\alpha}\end{split}
\end{equation*}\end{sphinxadmonition}
\label{vektoranalysis/diffformen:thm:dd}
\begin{sphinxadmonition}{note}{Theorem 3.7}



\sphinxAtStartPar
Auf \(\Omega^*(U)\) gilt
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}
\sphinxAtStartPar
Proof. 1. Für \(f\in\Omega^0(U)\) ist
\begin{equation*}
\begin{split}ddf &=& d\left(\sum_{i=1}^n\frac{\partial f}
{\partial x_i}dx_i\right) = \sum_{i=1}^n\sum_{l=1}^n\frac{\partial^2f}{\partial x_l\partial x_i}
dx_l\wedge dx_i\\
& =& \sum_{1\leq r< s\leq n}\left(\frac{\partial^2 f}{\partial x_r
\partial x_s} - \frac{\partial^2f}{\partial x_s\partial x_r}\right)dx_r\wedge dx_s = 0,\end{split}
\end{equation*}
\sphinxAtStartPar
da wir wegen der Glattheit von \(f\) die partiellen Ableitungen vertauschen
können.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Für \(\omega = \sum\omega_{i_1\ldots i_k}dx_{i_1}\wedge\ldots\wedge dx_{i_k}
\in\Omega^k(U)\) ist\textbackslash{}

\end{enumerate}
\begin{equation*}
\begin{split}dd\omega = \sum(\underbrace{dd\omega_{i_1\ldots i_k}}_0)
\wedge dx_{i_1}\wedge\ldots\wedge dx_{i_k} = 0,\end{split}
\end{equation*}
\sphinxAtStartPar
denn gemäß Satz {\hyperref[\detokenize{vektoranalysis/diffformen:Antiderivation}]{\sphinxcrossref{Theorem 3.6}}} wird die äußere Ableitung auf die
1\sphinxhyphen{}Formen \(d\omega_{i_1\ldots i_k}\) und \(dx_{i_l}\) angewandt, und nach Teil 1.
ist das Ergebnis Null.
\end{sphinxadmonition}
\label{vektoranalysis/diffformen:geschlossen:exakt}
\begin{sphinxadmonition}{note}{Definition 3.42}



\sphinxAtStartPar
Eine Differentialform \(v\in\Omega^*(U)\) heißt
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{geschlossen}, wenn \(dv=0\), *\sphinxstylestrong{exakt}, wenn \(v=d\psi\) für ein \(\psi\in\Omega^*(U)\) gilt.

\end{itemize}

\sphinxAtStartPar
Nach Satz {\hyperref[\detokenize{vektoranalysis/diffformen:thm:dd}]{\sphinxcrossref{Theorem 3.7}}} sind exakte Differentialformen geschlossen.\textbackslash{} Für \(k\)–Formen auf konvexen offenen Teimengen \(U\subseteq \R^n\) gilt für \(k\ge 1\)auch die Umkehrung (sog.
\sphinxhref{https://de.wikipedia.org/wiki/Poincar\%c3\%a9-Lemma}{\sphinxstylestrong{Poincaré\sphinxhyphen{}Lemma}} ),  siehe Kapitel \sphinxcode{\sphinxupquote{sect:Poinca}}).
\end{sphinxadmonition}


\chapter{Bibliography}
\label{\detokenize{references:bibliography}}\label{\detokenize{references::doc}}
\sphinxAtStartPar


\begin{sphinxthebibliography}{Janich03}
\bibitem[AF13]{references:id13}
\sphinxAtStartPar
Ilka Agricola and Thomas Friedrich. \sphinxstyleemphasis{Globale Analysis \sphinxhyphen{} Differentialformen in Analysis, Geometrie und Physik}. Springer\sphinxhyphen{}Verlag, Berlin Heidelberg New York, edition, 2013. ISBN 978\sphinxhyphen{}3\sphinxhyphen{}322\sphinxhyphen{}92903\sphinxhyphen{}7.
\bibitem[Bur20]{references:id2}
\sphinxAtStartPar
Martin Burger. \sphinxstyleemphasis{Skript zur Vorlesung "Mathematik für Data Science 1 / Physikstudierende A"}. 2020.
\bibitem[For17]{references:id4}
\sphinxAtStartPar
Otto Forster. \sphinxstyleemphasis{Analysis 2}. Springer, 2017.
\bibitem[Janich03]{references:id14}
\sphinxAtStartPar
Klaus Jänich. \sphinxstyleemphasis{Der Tangentialraum}. Springer Berlin Heidelberg, 2003. URL: \sphinxurl{https://doi.org/10.1007/978-3-662-10750-8\_2}, \sphinxhref{https://doi.org/10.1007/978-3-662-10750-8\_2}{doi:10.1007/978\sphinxhyphen{}3\sphinxhyphen{}662\sphinxhyphen{}10750\sphinxhyphen{}8\_2}.
\bibitem[Kna13]{references:id5}
\sphinxAtStartPar
Peter Knabner. \sphinxstyleemphasis{Skript zur Vorlesung "Gewöhnliche Differentialgleichungen"}. 2013.
\bibitem[Kna17]{references:id8}
\sphinxAtStartPar
Andreas Knauf. \sphinxstyleemphasis{Mathematische Physik: Klassische Mechanik}. Springer Berlin Heidelberg, 2017. \sphinxhref{https://doi.org/10.1007/978-3-662-55776-1}{doi:10.1007/978\sphinxhyphen{}3\sphinxhyphen{}662\sphinxhyphen{}55776\sphinxhyphen{}1}.
\bibitem[Kna20]{references:id7}
\sphinxAtStartPar
Andreas Knauf. \sphinxstyleemphasis{Skript zur Vorlesung "Mathematik für Physikstudierende 3"}. 2020.
\bibitem[Lee03]{references:id15}
\sphinxAtStartPar
John Lee. \sphinxstyleemphasis{Introduction to smooth manifolds}. Springer, New York, 2003. ISBN 0\sphinxhyphen{}387\sphinxhyphen{}95448\sphinxhyphen{}1.
\bibitem[Nol11]{references:id9}
\sphinxAtStartPar
Wolfgang Nolting. \sphinxstyleemphasis{Grundkurs Theoretische Physik 2 \sphinxhyphen{} Analytische Mechanik}. Springer Berlin Heidelberg, 2011. \sphinxhref{https://doi.org/10.1007/978-3-642-12950-6}{doi:10.1007/978\sphinxhyphen{}3\sphinxhyphen{}642\sphinxhyphen{}12950\sphinxhyphen{}6}.
\bibitem[SB18]{references:id10}
\sphinxAtStartPar
Herman Schulz\sphinxhyphen{}Baldes. \sphinxstyleemphasis{Skript zur Vorlesung "Mathematik für Physiker 3"}. 2018.
\bibitem[Ten21]{references:id12}
\sphinxAtStartPar
Daniel Tenbrinck. \sphinxstyleemphasis{Skript zur Vorlesung "Mathematik für Data Science 2"}. 2021. URL: \sphinxurl{https://fau-ammn.github.io/MathDataScience2}.
\end{sphinxthebibliography}






\renewcommand{\indexname}{Proof Index}
\begin{sphinxtheindex}
\let\bigletter\sphinxstyleindexlettergroup
\bigletter{Antiderivation}
\item\relax\sphinxstyleindexentry{Antiderivation}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{Antiderivation}}
\indexspace
\bigletter{aeussere Ableitung}
\item\relax\sphinxstyleindexentry{aeussere Ableitung}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{aeussere Ableitung}}
\indexspace
\bigletter{cor:eindeutigkeitlinear}
\item\relax\sphinxstyleindexentry{cor:eindeutigkeitlinear}\sphinxstyleindexextra{ode/repetition}\sphinxstyleindexpageref{ode/repetition:\detokenize{cor:eindeutigkeitlinear}}
\indexspace
\bigletter{cor:isomorphieEndlichDimensional}
\item\relax\sphinxstyleindexentry{cor:isomorphieEndlichDimensional}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{cor:isomorphieEndlichDimensional}}
\indexspace
\bigletter{cor:tensorMultilinearform}
\item\relax\sphinxstyleindexentry{cor:tensorMultilinearform}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{cor:tensorMultilinearform}}
\indexspace
\bigletter{cor:tensorenLinearformen}
\item\relax\sphinxstyleindexentry{cor:tensorenLinearformen}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{cor:tensorenLinearformen}}
\indexspace
\bigletter{corollary\sphinxhyphen{}55}
\item\relax\sphinxstyleindexentry{corollary\sphinxhyphen{}55}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{corollary-55}}
\indexspace
\bigletter{corollary\sphinxhyphen{}57}
\item\relax\sphinxstyleindexentry{corollary\sphinxhyphen{}57}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{corollary-57}}
\indexspace
\bigletter{corollary\sphinxhyphen{}6}
\item\relax\sphinxstyleindexentry{corollary\sphinxhyphen{}6}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{corollary-6}}
\indexspace
\bigletter{def:DGL}
\item\relax\sphinxstyleindexentry{def:DGL}\sphinxstyleindexextra{ode/repetition}\sphinxstyleindexpageref{ode/repetition:\detokenize{def:DGL}}
\indexspace
\bigletter{def:Fluss}
\item\relax\sphinxstyleindexentry{def:Fluss}\sphinxstyleindexextra{ode/fluesse}\sphinxstyleindexpageref{ode/fluesse:\detokenize{def:Fluss}}
\indexspace
\bigletter{def:LokFluss}
\item\relax\sphinxstyleindexentry{def:LokFluss}\sphinxstyleindexextra{ode/fluesse}\sphinxstyleindexpageref{ode/fluesse:\detokenize{def:LokFluss}}
\indexspace
\bigletter{def:Stabilitaet}
\item\relax\sphinxstyleindexentry{def:Stabilitaet}\sphinxstyleindexextra{odestability/stabilitaetsbegriffe}\sphinxstyleindexpageref{odestability/stabilitaetsbegriffe:\detokenize{def:Stabilitaet}}
\indexspace
\bigletter{def:aeusseresProdukt}
\item\relax\sphinxstyleindexentry{def:aeusseresProdukt}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{def:aeusseresProdukt}}
\indexspace
\bigletter{def:aeusseresProduktTensoren}
\item\relax\sphinxstyleindexentry{def:aeusseresProduktTensoren}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{def:aeusseresProduktTensoren}}
\indexspace
\bigletter{def:algebraischerDualraum}
\item\relax\sphinxstyleindexentry{def:algebraischerDualraum}\sphinxstyleindexextra{vektoranalysis/multilinear}\sphinxstyleindexpageref{vektoranalysis/multilinear:\detokenize{def:algebraischerDualraum}}
\indexspace
\bigletter{def:anfangswertproblem}
\item\relax\sphinxstyleindexentry{def:anfangswertproblem}\sphinxstyleindexextra{ode/repetition}\sphinxstyleindexpageref{ode/repetition:\detokenize{def:anfangswertproblem}}
\indexspace
\bigletter{def:direcdiv}
\item\relax\sphinxstyleindexentry{def:direcdiv}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{def:direcdiv}}
\indexspace
\bigletter{def:fermionischeProjektion}
\item\relax\sphinxstyleindexentry{def:fermionischeProjektion}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{def:fermionischeProjektion}}
\indexspace
\bigletter{def:gemischteTensoren}
\item\relax\sphinxstyleindexentry{def:gemischteTensoren}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{def:gemischteTensoren}}
\indexspace
\bigletter{def:hamiltonsch}
\item\relax\sphinxstyleindexentry{def:hamiltonsch}\sphinxstyleindexextra{ode/hamilton}\sphinxstyleindexpageref{ode/hamilton:\detokenize{def:hamiltonsch}}
\indexspace
\bigletter{def:linearisierung}
\item\relax\sphinxstyleindexentry{def:linearisierung}\sphinxstyleindexextra{odestability/ruhelagen}\sphinxstyleindexpageref{odestability/ruhelagen:\detokenize{def:linearisierung}}
\indexspace
\bigletter{def:multilinear}
\item\relax\sphinxstyleindexentry{def:multilinear}\sphinxstyleindexextra{vektoranalysis/multilinear}\sphinxstyleindexpageref{vektoranalysis/multilinear:\detokenize{def:multilinear}}
\indexspace
\bigletter{def:signumPermutation}
\item\relax\sphinxstyleindexentry{def:signumPermutation}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{def:signumPermutation}}
\indexspace
\bigletter{def:stetigkeitTopologie}
\item\relax\sphinxstyleindexentry{def:stetigkeitTopologie}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{def:stetigkeitTopologie}}
\indexspace
\bigletter{def:symmetrieTensor}
\item\relax\sphinxstyleindexentry{def:symmetrieTensor}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{def:symmetrieTensor}}
\indexspace
\bigletter{def:tensor}
\item\relax\sphinxstyleindexentry{def:tensor}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{def:tensor}}
\indexspace
\bigletter{def:topologischerDualraum}
\item\relax\sphinxstyleindexentry{def:topologischerDualraum}\sphinxstyleindexextra{vektoranalysis/multilinear}\sphinxstyleindexpageref{vektoranalysis/multilinear:\detokenize{def:topologischerDualraum}}
\indexspace
\bigletter{definition\sphinxhyphen{}0}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}0}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-0}}
\indexspace
\bigletter{definition\sphinxhyphen{}10}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}10}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-10}}
\indexspace
\bigletter{definition\sphinxhyphen{}11}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}11}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-11}}
\indexspace
\bigletter{definition\sphinxhyphen{}12}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}12}\sphinxstyleindexextra{ode/repetition}\sphinxstyleindexpageref{ode/repetition:\detokenize{definition-12}}
\indexspace
\bigletter{definition\sphinxhyphen{}13}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}13}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-13}}
\indexspace
\bigletter{definition\sphinxhyphen{}14}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}14}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-14}}
\indexspace
\bigletter{definition\sphinxhyphen{}18}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}18}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-18}}
\indexspace
\bigletter{definition\sphinxhyphen{}2}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}2}\sphinxstyleindexextra{ode/hamilton}\sphinxstyleindexpageref{ode/hamilton:\detokenize{definition-2}}
\indexspace
\bigletter{definition\sphinxhyphen{}22}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}22}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-22}}
\indexspace
\bigletter{definition\sphinxhyphen{}25}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}25}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-25}}
\indexspace
\bigletter{definition\sphinxhyphen{}29}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}29}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-29}}
\indexspace
\bigletter{definition\sphinxhyphen{}3}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}3}\sphinxstyleindexextra{ode/repetition}\sphinxstyleindexpageref{ode/repetition:\detokenize{definition-3}}
\indexspace
\bigletter{definition\sphinxhyphen{}32}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}32}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-32}}
\indexspace
\bigletter{definition\sphinxhyphen{}34}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}34}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-34}}
\indexspace
\bigletter{definition\sphinxhyphen{}37}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}37}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-37}}
\indexspace
\bigletter{definition\sphinxhyphen{}39}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}39}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-39}}
\indexspace
\bigletter{definition\sphinxhyphen{}4}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}4}\sphinxstyleindexextra{ode/fluesse}\sphinxstyleindexpageref{ode/fluesse:\detokenize{definition-4}}
\indexspace
\bigletter{definition\sphinxhyphen{}41}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}41}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-41}}
\indexspace
\bigletter{definition\sphinxhyphen{}46}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}46}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-46}}
\indexspace
\bigletter{definition\sphinxhyphen{}47}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}47}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-47}}
\indexspace
\bigletter{definition\sphinxhyphen{}48}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}48}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-48}}
\indexspace
\bigletter{definition\sphinxhyphen{}49}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}49}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-49}}
\indexspace
\bigletter{definition\sphinxhyphen{}5}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}5}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-5}}
\indexspace
\bigletter{definition\sphinxhyphen{}51}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}51}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-51}}
\indexspace
\bigletter{definition\sphinxhyphen{}54}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}54}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-54}}
\indexspace
\bigletter{definition\sphinxhyphen{}56}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}56}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-56}}
\indexspace
\bigletter{definition\sphinxhyphen{}59}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}59}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-59}}
\indexspace
\bigletter{definition\sphinxhyphen{}6}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}6}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-6}}
\indexspace
\bigletter{definition\sphinxhyphen{}61}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}61}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-61}}
\indexspace
\bigletter{definition\sphinxhyphen{}7}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}7}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-7}}
\indexspace
\bigletter{definition\sphinxhyphen{}8}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}8}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-8}}
\indexspace
\bigletter{definition\sphinxhyphen{}9}
\item\relax\sphinxstyleindexentry{definition\sphinxhyphen{}9}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{definition-9}}
\indexspace
\bigletter{ex:10.14}
\item\relax\sphinxstyleindexentry{ex:10.14}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{ex:10.14}}
\indexspace
\bigletter{ex:bacteria}
\item\relax\sphinxstyleindexentry{ex:bacteria}\sphinxstyleindexextra{ode/dynamicSystems}\sphinxstyleindexpageref{ode/dynamicSystems:\detokenize{ex:bacteria}}
\indexspace
\bigletter{ex:diskreteTopologie}
\item\relax\sphinxstyleindexentry{ex:diskreteTopologie}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{ex:diskreteTopologie}}
\indexspace
\bigletter{ex:freefall}
\item\relax\sphinxstyleindexentry{ex:freefall}\sphinxstyleindexextra{ode/dynamicSystems}\sphinxstyleindexpageref{ode/dynamicSystems:\detokenize{ex:freefall}}
\indexspace
\bigletter{ex:multilinear}
\item\relax\sphinxstyleindexentry{ex:multilinear}\sphinxstyleindexextra{vektoranalysis/multilinear}\sphinxstyleindexpageref{vektoranalysis/multilinear:\detokenize{ex:multilinear}}
\indexspace
\bigletter{ex:nonho}
\item\relax\sphinxstyleindexentry{ex:nonho}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{ex:nonho}}
\indexspace
\bigletter{ex:oscillations}
\item\relax\sphinxstyleindexentry{ex:oscillations}\sphinxstyleindexextra{ode/fluesse}\sphinxstyleindexpageref{ode/fluesse:\detokenize{ex:oscillations}}
\indexspace
\bigletter{ex:tangentialS1}
\item\relax\sphinxstyleindexentry{ex:tangentialS1}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{ex:tangentialS1}}
\indexspace
\bigletter{ex:tensorproduktVarianten}
\item\relax\sphinxstyleindexentry{ex:tensorproduktVarianten}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{ex:tensorproduktVarianten}}
\indexspace
\bigletter{ex:universelleEigenschaft}
\item\relax\sphinxstyleindexentry{ex:universelleEigenschaft}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{ex:universelleEigenschaft}}
\indexspace
\bigletter{example\sphinxhyphen{}1}
\item\relax\sphinxstyleindexentry{example\sphinxhyphen{}1}\sphinxstyleindexextra{odestability/stabilitaetsbegriffe}\sphinxstyleindexpageref{odestability/stabilitaetsbegriffe:\detokenize{example-1}}
\indexspace
\bigletter{example\sphinxhyphen{}12}
\item\relax\sphinxstyleindexentry{example\sphinxhyphen{}12}\sphinxstyleindexextra{vektoranalysis/multilinear}\sphinxstyleindexpageref{vektoranalysis/multilinear:\detokenize{example-12}}
\indexspace
\bigletter{example\sphinxhyphen{}17}
\item\relax\sphinxstyleindexentry{example\sphinxhyphen{}17}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{example-17}}
\indexspace
\bigletter{example\sphinxhyphen{}19}
\item\relax\sphinxstyleindexentry{example\sphinxhyphen{}19}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{example-19}}
\indexspace
\bigletter{example\sphinxhyphen{}2}
\item\relax\sphinxstyleindexentry{example\sphinxhyphen{}2}\sphinxstyleindexextra{vektoranalysis/multilinear}\sphinxstyleindexpageref{vektoranalysis/multilinear:\detokenize{example-2}}
\indexspace
\bigletter{example\sphinxhyphen{}21}
\item\relax\sphinxstyleindexentry{example\sphinxhyphen{}21}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{example-21}}
\indexspace
\bigletter{example\sphinxhyphen{}22}
\item\relax\sphinxstyleindexentry{example\sphinxhyphen{}22}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{example-22}}
\indexspace
\bigletter{example\sphinxhyphen{}23}
\item\relax\sphinxstyleindexentry{example\sphinxhyphen{}23}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{example-23}}
\indexspace
\bigletter{example\sphinxhyphen{}24}
\item\relax\sphinxstyleindexentry{example\sphinxhyphen{}24}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{example-24}}
\indexspace
\bigletter{example\sphinxhyphen{}27}
\item\relax\sphinxstyleindexentry{example\sphinxhyphen{}27}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{example-27}}
\indexspace
\bigletter{example\sphinxhyphen{}29}
\item\relax\sphinxstyleindexentry{example\sphinxhyphen{}29}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{example-29}}
\indexspace
\bigletter{example\sphinxhyphen{}3}
\item\relax\sphinxstyleindexentry{example\sphinxhyphen{}3}\sphinxstyleindexextra{ode/hamilton}\sphinxstyleindexpageref{ode/hamilton:\detokenize{example-3}}
\indexspace
\bigletter{example\sphinxhyphen{}38}
\item\relax\sphinxstyleindexentry{example\sphinxhyphen{}38}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{example-38}}
\indexspace
\bigletter{example\sphinxhyphen{}4}
\item\relax\sphinxstyleindexentry{example\sphinxhyphen{}4}\sphinxstyleindexextra{ode/repetition}\sphinxstyleindexpageref{ode/repetition:\detokenize{example-4}}
\indexspace
\bigletter{example\sphinxhyphen{}43}
\item\relax\sphinxstyleindexentry{example\sphinxhyphen{}43}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{example-43}}
\indexspace
\bigletter{example\sphinxhyphen{}5}
\item\relax\sphinxstyleindexentry{example\sphinxhyphen{}5}\sphinxstyleindexextra{vektoranalysis/multilinear}\sphinxstyleindexpageref{vektoranalysis/multilinear:\detokenize{example-5}}
\indexspace
\bigletter{example\sphinxhyphen{}6}
\item\relax\sphinxstyleindexentry{example\sphinxhyphen{}6}\sphinxstyleindexextra{ode/repetition}\sphinxstyleindexpageref{ode/repetition:\detokenize{example-6}}
\indexspace
\bigletter{example\sphinxhyphen{}7}
\item\relax\sphinxstyleindexentry{example\sphinxhyphen{}7}\sphinxstyleindexextra{ode/repetition}\sphinxstyleindexpageref{ode/repetition:\detokenize{example-7}}
\indexspace
\bigletter{example\sphinxhyphen{}8}
\item\relax\sphinxstyleindexentry{example\sphinxhyphen{}8}\sphinxstyleindexextra{odestability/ruhelagen}\sphinxstyleindexpageref{odestability/ruhelagen:\detokenize{example-8}}
\indexspace
\bigletter{example\sphinxhyphen{}9}
\item\relax\sphinxstyleindexentry{example\sphinxhyphen{}9}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{example-9}}
\indexspace
\bigletter{geschlossen:exakt}
\item\relax\sphinxstyleindexentry{geschlossen:exakt}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{geschlossen:exakt}}
\indexspace
\bigletter{lem:LISO}
\item\relax\sphinxstyleindexentry{lem:LISO}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{lem:LISO}}
\indexspace
\bigletter{lem:constder}
\item\relax\sphinxstyleindexentry{lem:constder}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{lem:constder}}
\indexspace
\bigletter{lem:differenzierbarkeitKartenunabhaengig}
\item\relax\sphinxstyleindexentry{lem:differenzierbarkeitKartenunabhaengig}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{lem:differenzierbarkeitKartenunabhaengig}}
\indexspace
\bigletter{lem:dualeBasis}
\item\relax\sphinxstyleindexentry{lem:dualeBasis}\sphinxstyleindexextra{vektoranalysis/multilinear}\sphinxstyleindexpageref{vektoranalysis/multilinear:\detokenize{lem:dualeBasis}}
\indexspace
\bigletter{lem:intexpglgn}
\item\relax\sphinxstyleindexentry{lem:intexpglgn}\sphinxstyleindexextra{odestability/ruhelagen}\sphinxstyleindexpageref{odestability/ruhelagen:\detokenize{lem:intexpglgn}}
\indexspace
\bigletter{lem:isomorphieKartesischesProdukt}
\item\relax\sphinxstyleindexentry{lem:isomorphieKartesischesProdukt}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{lem:isomorphieKartesischesProdukt}}
\indexspace
\bigletter{lem:isomorphismusTensorproduktraum}
\item\relax\sphinxstyleindexentry{lem:isomorphismusTensorproduktraum}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{lem:isomorphismusTensorproduktraum}}
\indexspace
\bigletter{lem:localsections}
\item\relax\sphinxstyleindexentry{lem:localsections}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{lem:localsections}}
\indexspace
\bigletter{lem:mpotew}
\item\relax\sphinxstyleindexentry{lem:mpotew}\sphinxstyleindexextra{ode/repetition}\sphinxstyleindexpageref{ode/repetition:\detokenize{lem:mpotew}}
\indexspace
\bigletter{lem:natISO}
\item\relax\sphinxstyleindexentry{lem:natISO}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{lem:natISO}}
\indexspace
\bigletter{lem:partderkron}
\item\relax\sphinxstyleindexentry{lem:partderkron}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{lem:partderkron}}
\indexspace
\bigletter{lem:tanman}
\item\relax\sphinxstyleindexentry{lem:tanman}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{lem:tanman}}
\indexspace
\bigletter{lem:tensorStufe}
\item\relax\sphinxstyleindexentry{lem:tensorStufe}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{lem:tensorStufe}}
\indexspace
\bigletter{lem:tensorbundle}
\item\relax\sphinxstyleindexentry{lem:tensorbundle}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{lem:tensorbundle}}
\indexspace
\bigletter{lemma\sphinxhyphen{}15}
\item\relax\sphinxstyleindexentry{lemma\sphinxhyphen{}15}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{lemma-15}}
\indexspace
\bigletter{lemma\sphinxhyphen{}24}
\item\relax\sphinxstyleindexentry{lemma\sphinxhyphen{}24}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{lemma-24}}
\indexspace
\bigletter{lemma\sphinxhyphen{}26}
\item\relax\sphinxstyleindexentry{lemma\sphinxhyphen{}26}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{lemma-26}}
\indexspace
\bigletter{lemma\sphinxhyphen{}3}
\item\relax\sphinxstyleindexentry{lemma\sphinxhyphen{}3}\sphinxstyleindexextra{ode/fluesse}\sphinxstyleindexpageref{ode/fluesse:\detokenize{lemma-3}}
\indexspace
\bigletter{lemma\sphinxhyphen{}30}
\item\relax\sphinxstyleindexentry{lemma\sphinxhyphen{}30}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{lemma-30}}
\indexspace
\bigletter{lemma\sphinxhyphen{}35}
\item\relax\sphinxstyleindexentry{lemma\sphinxhyphen{}35}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{lemma-35}}
\indexspace
\bigletter{lemma\sphinxhyphen{}4}
\item\relax\sphinxstyleindexentry{lemma\sphinxhyphen{}4}\sphinxstyleindexextra{vektoranalysis/multilinear}\sphinxstyleindexpageref{vektoranalysis/multilinear:\detokenize{lemma-4}}
\indexspace
\bigletter{lemma\sphinxhyphen{}45}
\item\relax\sphinxstyleindexentry{lemma\sphinxhyphen{}45}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{lemma-45}}
\indexspace
\bigletter{lemma\sphinxhyphen{}52}
\item\relax\sphinxstyleindexentry{lemma\sphinxhyphen{}52}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{lemma-52}}
\indexspace
\bigletter{lemma\sphinxhyphen{}58}
\item\relax\sphinxstyleindexentry{lemma\sphinxhyphen{}58}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{lemma-58}}
\indexspace
\bigletter{lemma\sphinxhyphen{}60}
\item\relax\sphinxstyleindexentry{lemma\sphinxhyphen{}60}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{lemma-60}}
\indexspace
\bigletter{lemma\sphinxhyphen{}9}
\item\relax\sphinxstyleindexentry{lemma\sphinxhyphen{}9}\sphinxstyleindexextra{vektoranalysis/multilinear}\sphinxstyleindexpageref{vektoranalysis/multilinear:\detokenize{lemma-9}}
\indexspace
\bigletter{lemma:Gronwall}
\item\relax\sphinxstyleindexentry{lemma:Gronwall}\sphinxstyleindexextra{odestability/ruhelagen}\sphinxstyleindexpageref{odestability/ruhelagen:\detokenize{lemma:Gronwall}}
\indexspace
\bigletter{rem:doubledual}
\item\relax\sphinxstyleindexentry{rem:doubledual}\sphinxstyleindexextra{vektoranalysis/multilinear}\sphinxstyleindexpageref{vektoranalysis/multilinear:\detokenize{rem:doubledual}}
\indexspace
\bigletter{rem:kfachesTensorprodukt}
\item\relax\sphinxstyleindexentry{rem:kfachesTensorprodukt}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{rem:kfachesTensorprodukt}}
\indexspace
\bigletter{rem:matrixexponentialregeln}
\item\relax\sphinxstyleindexentry{rem:matrixexponentialregeln}\sphinxstyleindexextra{ode/repetition}\sphinxstyleindexpageref{ode/repetition:\detokenize{rem:matrixexponentialregeln}}
\indexspace
\bigletter{rem:tang}
\item\relax\sphinxstyleindexentry{rem:tang}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{rem:tang}}
\indexspace
\bigletter{remark\sphinxhyphen{}0}
\item\relax\sphinxstyleindexentry{remark\sphinxhyphen{}0}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{remark-0}}
\indexspace
\bigletter{remark\sphinxhyphen{}1}
\item\relax\sphinxstyleindexentry{remark\sphinxhyphen{}1}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{remark-1}}
\indexspace
\bigletter{remark\sphinxhyphen{}11}
\item\relax\sphinxstyleindexentry{remark\sphinxhyphen{}11}\sphinxstyleindexextra{vektoranalysis/multilinear}\sphinxstyleindexpageref{vektoranalysis/multilinear:\detokenize{remark-11}}
\indexspace
\bigletter{remark\sphinxhyphen{}12}
\item\relax\sphinxstyleindexentry{remark\sphinxhyphen{}12}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{remark-12}}
\indexspace
\bigletter{remark\sphinxhyphen{}14}
\item\relax\sphinxstyleindexentry{remark\sphinxhyphen{}14}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{remark-14}}
\indexspace
\bigletter{remark\sphinxhyphen{}16}
\item\relax\sphinxstyleindexentry{remark\sphinxhyphen{}16}\sphinxstyleindexextra{ode/repetition}\sphinxstyleindexpageref{ode/repetition:\detokenize{remark-16}}
\indexspace
\bigletter{remark\sphinxhyphen{}2}
\item\relax\sphinxstyleindexentry{remark\sphinxhyphen{}2}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{remark-2}}
\indexspace
\bigletter{remark\sphinxhyphen{}20}
\item\relax\sphinxstyleindexentry{remark\sphinxhyphen{}20}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{remark-20}}
\indexspace
\bigletter{remark\sphinxhyphen{}23}
\item\relax\sphinxstyleindexentry{remark\sphinxhyphen{}23}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{remark-23}}
\indexspace
\bigletter{remark\sphinxhyphen{}26}
\item\relax\sphinxstyleindexentry{remark\sphinxhyphen{}26}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{remark-26}}
\indexspace
\bigletter{remark\sphinxhyphen{}3}
\item\relax\sphinxstyleindexentry{remark\sphinxhyphen{}3}\sphinxstyleindexextra{vektoranalysis/multilinear}\sphinxstyleindexpageref{vektoranalysis/multilinear:\detokenize{remark-3}}
\indexspace
\bigletter{remark\sphinxhyphen{}33}
\item\relax\sphinxstyleindexentry{remark\sphinxhyphen{}33}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{remark-33}}
\indexspace
\bigletter{remark\sphinxhyphen{}36}
\item\relax\sphinxstyleindexentry{remark\sphinxhyphen{}36}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{remark-36}}
\indexspace
\bigletter{remark\sphinxhyphen{}39}
\item\relax\sphinxstyleindexentry{remark\sphinxhyphen{}39}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{remark-39}}
\indexspace
\bigletter{remark\sphinxhyphen{}4}
\item\relax\sphinxstyleindexentry{remark\sphinxhyphen{}4}\sphinxstyleindexextra{odestability/ruhelagen}\sphinxstyleindexpageref{odestability/ruhelagen:\detokenize{remark-4}}
\indexspace
\bigletter{remark\sphinxhyphen{}40}
\item\relax\sphinxstyleindexentry{remark\sphinxhyphen{}40}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{remark-40}}
\indexspace
\bigletter{remark\sphinxhyphen{}42}
\item\relax\sphinxstyleindexentry{remark\sphinxhyphen{}42}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{remark-42}}
\indexspace
\bigletter{remark\sphinxhyphen{}6}
\item\relax\sphinxstyleindexentry{remark\sphinxhyphen{}6}\sphinxstyleindexextra{odestability/ruhelagen}\sphinxstyleindexpageref{odestability/ruhelagen:\detokenize{remark-6}}
\indexspace
\bigletter{remark\sphinxhyphen{}7}
\item\relax\sphinxstyleindexentry{remark\sphinxhyphen{}7}\sphinxstyleindexextra{vektoranalysis/multilinear}\sphinxstyleindexpageref{vektoranalysis/multilinear:\detokenize{remark-7}}
\indexspace
\bigletter{satz:picardlindeloef}
\item\relax\sphinxstyleindexentry{satz:picardlindeloef}\sphinxstyleindexextra{ode/repetition}\sphinxstyleindexpageref{ode/repetition:\detokenize{satz:picardlindeloef}}
\indexspace
\bigletter{theorem\sphinxhyphen{}28}
\item\relax\sphinxstyleindexentry{theorem\sphinxhyphen{}28}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{theorem-28}}
\indexspace
\bigletter{theorem\sphinxhyphen{}37}
\item\relax\sphinxstyleindexentry{theorem\sphinxhyphen{}37}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{theorem-37}}
\indexspace
\bigletter{thm:dd}
\item\relax\sphinxstyleindexentry{thm:dd}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{thm:dd}}
\indexspace
\bigletter{thm:existenzTensorprodukt}
\item\relax\sphinxstyleindexentry{thm:existenzTensorprodukt}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{thm:existenzTensorprodukt}}
\indexspace
\bigletter{thm:hamconst}
\item\relax\sphinxstyleindexentry{thm:hamconst}\sphinxstyleindexextra{ode/hamilton}\sphinxstyleindexpageref{ode/hamilton:\detokenize{thm:hamconst}}
\indexspace
\bigletter{thm:pIsomorphismus}
\item\relax\sphinxstyleindexentry{thm:pIsomorphismus}\sphinxstyleindexextra{vektoranalysis/tensor}\sphinxstyleindexpageref{vektoranalysis/tensor:\detokenize{thm:pIsomorphismus}}
\indexspace
\bigletter{thm:piclindlokal}
\item\relax\sphinxstyleindexentry{thm:piclindlokal}\sphinxstyleindexextra{ode/repetition}\sphinxstyleindexpageref{ode/repetition:\detokenize{thm:piclindlokal}}
\indexspace
\bigletter{thm:stabasymallg}
\item\relax\sphinxstyleindexentry{thm:stabasymallg}\sphinxstyleindexextra{odestability/ruhelagen}\sphinxstyleindexpageref{odestability/ruhelagen:\detokenize{thm:stabasymallg}}
\indexspace
\bigletter{thm:stablin}
\item\relax\sphinxstyleindexentry{thm:stablin}\sphinxstyleindexextra{odestability/ruhelagen}\sphinxstyleindexpageref{odestability/ruhelagen:\detokenize{thm:stablin}}
\indexspace
\bigletter{thm:stablyaplinear}
\item\relax\sphinxstyleindexentry{thm:stablyaplinear}\sphinxstyleindexextra{odestability/ruhelagen}\sphinxstyleindexpageref{odestability/ruhelagen:\detokenize{thm:stablyaplinear}}
\indexspace
\bigletter{thm:tanbasis}
\item\relax\sphinxstyleindexentry{thm:tanbasis}\sphinxstyleindexextra{vektoranalysis/diffformen}\sphinxstyleindexpageref{vektoranalysis/diffformen:\detokenize{thm:tanbasis}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}